{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76855fd7",
   "metadata": {},
   "source": [
    "# Measure Graphical Structure in Bridge matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c09944",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO : faire un graph réellement random avec autant d'arrêtes et de noeuds (simplement mélanger les valeurs de la matrice d'adjacence) :\n",
    "- quelle entropie pour erdos alors ?\n",
    "- pour NBM ? Gain comparable ou significativement plus faible comparé au graph de base ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af6ff245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "from graph_tool.spectral import laplacian\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9612ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"./checkpoints/\"\n",
    "DATASET = \"laion\"\n",
    "UseTOPK = False\n",
    "CENTER_DATASET = False\n",
    "expansion_factor = 8\n",
    "top_k = 20\n",
    "\n",
    "alpha = 0.1 if UseTOPK else 0.0\n",
    "beta = 0\n",
    "\n",
    "alpha_name = str(alpha).replace('.', '')\n",
    "beta_name = str(beta).replace('.', '')\n",
    "bridge_name = f\"{DATASET}_{\"batchtopk\" if UseTOPK else \"MP\"}_centered_{CENTER_DATASET}_{expansion_factor}_L0_{top_k}_alpha\" + alpha_name + \"beta\" + beta_name + \"_bridge.npy\"\n",
    "null_C = f\"{DATASET}_{\"batchtopk\" if UseTOPK else \"MP\"}_centered_{CENTER_DATASET}_{expansion_factor}_L0_{top_k}_alpha\" + alpha_name + \"beta\" + beta_name + \"_bridge_null_C.npy\"\n",
    "null_D = f\"{DATASET}_{\"batchtopk\" if UseTOPK else \"MP\"}_centered_{CENTER_DATASET}_{expansion_factor}_L0_{top_k}_alpha\" + alpha_name + \"beta\" + beta_name + \"_bridge_null_D.npy\"\n",
    "null = f\"{DATASET}_{\"batchtopk\" if UseTOPK else \"MP\"}_centered_{CENTER_DATASET}_{expansion_factor}_L0_{top_k}_alpha\" + alpha_name + \"beta\" + beta_name + \"_bridge_null.npy\"\n",
    "\n",
    "bridge = np.load(path + bridge_name, allow_pickle=True)\n",
    "null_C = np.load(path + null_C, allow_pickle=True)\n",
    "null_D = np.load(path + null_D, allow_pickle=True)\n",
    "null = np.load(path + null, allow_pickle=True)\n",
    "energy = np.load(path + bridge_name.replace(\"bridge\", \"energy\"), allow_pickle=True)\n",
    "\n",
    "# threshold bridges with 99th percentile of null :\n",
    "threshold = np.quantile(null, 0.999)\n",
    "print(f\"Threshold for bridge: {threshold:.2e}\")\n",
    "bridge[np.abs(bridge) < threshold] = 0\n",
    "null_C[np.abs(null_C) < threshold] = 0\n",
    "null_D[np.abs(null_D) < threshold] = 0\n",
    "null[np.abs(null) < threshold] = 0\n",
    "\n",
    "SQUARE = True\n",
    "rec_types=[\"real-normal\"]\n",
    "if SQUARE:\n",
    "    # square the matrix\n",
    "    bridge = bridge ** 2\n",
    "    null_C = null_C ** 2\n",
    "    null_D = null_D ** 2\n",
    "    null = null ** 2\n",
    "    rec_types=[\"real-exponential\"]\n",
    "\n",
    "bridge_null = bridge.flatten()[np.random.permutation(len(bridge.flatten()))].reshape(bridge.shape)\n",
    "\n",
    "print(bridge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f386769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distribution of edge weights :\n",
    "edge_weights = bridge[bridge != 0].flatten()\n",
    "\n",
    "# sort the edge weights\n",
    "edge_weights = np.sort(np.abs(edge_weights))\n",
    "\n",
    "# cumulative distribution function :\n",
    "cumulative_distribution = np.cumsum(edge_weights) / np.sum(edge_weights)\n",
    "cumulative_distribution = cumulative_distribution[::-1]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find the smallest index where the cumulative distribution is less than 0.99, 0.95, and 0.5\n",
    "idx_999 = np.argmax(cumulative_distribution < 0.001)\n",
    "idx_99 = np.argmax(cumulative_distribution < 0.01)\n",
    "idx_95 = np.argmax(cumulative_distribution < 0.05)\n",
    "idx_90 = np.argmax(cumulative_distribution < 0.1)\n",
    "idx_50 = np.argmax(cumulative_distribution < 0.5)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"% of weight above 1e-{i}: {np.sum(edge_weights[edge_weights > 10**-i]) / np.sum(edge_weights)}\")\n",
    "\n",
    "p50 = edge_weights[len(edge_weights) - idx_50]\n",
    "p90 = edge_weights[len(edge_weights) - idx_90]\n",
    "p95 = edge_weights[len(edge_weights) - idx_95]\n",
    "p99 = edge_weights[len(edge_weights) - idx_99]\n",
    "p999 = edge_weights[len(edge_weights) - idx_999]\n",
    "print(\"50th percentile:\", p50)\n",
    "print(\"90th percentile:\", p90)\n",
    "print(\"95th percentile:\", p95)\n",
    "print(\"99th percentile:\", p99)\n",
    "print(\"99.9th percentile:\", p999)\n",
    "\n",
    "\n",
    "print(\"50th percentile:\", idx_50, \"%:\", idx_50 / len(cumulative_distribution))\n",
    "print(\"90th percentile:\", idx_90, \"%:\", idx_90 / len(cumulative_distribution))\n",
    "print(\"95th percentile:\", idx_95, \"%:\", idx_95 / len(cumulative_distribution))\n",
    "print(\"99th percentile:\", idx_99, \"%:\", idx_99 / len(cumulative_distribution))\n",
    "print(\"99.9th percentile:\", idx_999, \"%:\", idx_999 / len(cumulative_distribution))\n",
    "\n",
    "plt.plot(cumulative_distribution[:idx_95])\n",
    "plt.axvline(idx_50, color='r', linestyle='dashed', linewidth=1, label='50th percentile')\n",
    "plt.axvline(idx_90, color='m', linestyle='dashed', linewidth=1, label='90th percentile')\n",
    "plt.axvline(idx_95, color='g', linestyle='dashed', linewidth=1, label='95th percentile')\n",
    "plt.axvline(idx_99, color='b', linestyle='dashed', linewidth=1, label='99th percentile')\n",
    "plt.axvline(idx_999, color='y', linestyle='dashed', linewidth=1, label='99.9th percentile')\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('cumulative distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5d5f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(bridge, energy, threshold=0): # 8.27e-8): -> already thresholded using the null distribution\n",
    "    A = bridge\n",
    "    num_nodes = A.shape[0]\n",
    "\n",
    "    # Build directed graph from adjacency matrix (no symmetrization)\n",
    "    g = gt.Graph(directed=True)\n",
    "    g.add_vertex(num_nodes)\n",
    "\n",
    "    # Create edge weights for the graph\n",
    "    weights = g.new_edge_property(\"double\")\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if np.abs(A[i, j]) > threshold:\n",
    "                e = g.add_edge(i, j)\n",
    "                weights[e] = A[i, j]\n",
    "    g.edge_properties[\"weight\"] = weights\n",
    "\n",
    "    # state = gt.NestedBlockState(g)\n",
    "\n",
    "    # dS, nmoves = 0, 0\n",
    "        \n",
    "    # for i in range(100):\n",
    "    #     ret = state.multiflip_mcmc_sweep(niter=10)\n",
    "    #     dS += ret[0]\n",
    "    #     nmoves += ret[1]\n",
    "\n",
    "    # print(\"Change in description length:\", dS)\n",
    "    # print(\"Number of accepted vertex moves:\", nmoves)\n",
    "    return g\n",
    "    # Run nested SBM inference on the directed graph\n",
    "    state = gt.minimize_nested_blockmodel_dl(g, state_args=dict(recs=[weights], rec_types=rec_types))\n",
    "    return state\n",
    "    blocks = state.get_bs()[0]  # Block assignments for top-level blocks\n",
    "\n",
    "    # Sort vertices by block and by energy within each block\n",
    "    blocks = np.array(blocks)\n",
    "    idx_by_block = []\n",
    "    for b in np.unique(blocks):\n",
    "        idxs = np.where(blocks == b)[0]\n",
    "        idxs_tensor = torch.tensor(idxs)\n",
    "        sorted_in_block = idxs_tensor[torch.argsort(energy[idxs_tensor], descending=True)]\n",
    "        idx_by_block.append(sorted_in_block)\n",
    "    \n",
    "    ordered_indices = torch.cat(idx_by_block)\n",
    "    sorted_bridge = bridge[ordered_indices][:, ordered_indices]\n",
    "    \n",
    "    return sorted_bridge, ordered_indices, blocks\n",
    "\n",
    "g_bridge = create_graph(bridge, energy)\n",
    "print(f\"Graph created, with {g_bridge.num_edges()} edges and {g_bridge.num_vertices()} vertices. Average degree: {g_bridge.num_edges() / g_bridge.num_vertices()}\")\n",
    "g_bridge_null = create_graph(bridge_null, energy)\n",
    "print(f\"Graph created, with {g_bridge_null.num_edges()} edges and {g_bridge_null.num_vertices()} vertices. Average degree: {g_bridge_null.num_edges() / g_bridge_null.num_vertices()}\")\n",
    "g_null_C = create_graph(null_C, energy)\n",
    "print(f\"Graph created, with {g_null_C.num_edges()} edges and {g_null_C.num_vertices()} vertices. Average degree: {g_null_C.num_edges() / g_null_C.num_vertices()}\")\n",
    "g_null_D = create_graph(null_D, energy)\n",
    "print(f\"Graph created, with {g_null_D.num_edges()} edges and {g_null_D.num_vertices()} vertices. Average degree: {g_null_D.num_edges() / g_null_D.num_vertices()}\")\n",
    "g_null = create_graph(null, energy)\n",
    "print(f\"Graph created, with {g_null.num_edges()} edges and {g_null.num_vertices()} vertices. Average degree: {g_null.num_edges() / g_null.num_vertices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba1d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a weighted erdos-renyi model that fits the graph. Just use a SBM with 1 block :\n",
    "\n",
    "# for g in [g_bridge, g_null_D, g_null_C, g_null]:\n",
    "#     state_erdos = gt.BlockState(\n",
    "#         g,\n",
    "#         B=1,\n",
    "#         recs=[g.ep.weight],\n",
    "#         rec_types=rec_types,\n",
    "#     )\n",
    "\n",
    "#     print(f\"log-likelihood of the graph: {state_erdos.entropy():.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec615efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sbm():\n",
    "    res = {}\n",
    "    for g, title in [(g_bridge, \"bridge\"), (g_bridge_null, \"bridge_null\"), (g_null_D, \"null_D\"), (g_null_C, \"null_C\"), (g_null, \"null\")]:\n",
    "        print(\"\\n\")\n",
    "        state = gt.NestedBlockState(\n",
    "            g,\n",
    "            # B=1,\n",
    "            recs=[g.ep.weight],\n",
    "            rec_types=rec_types,\n",
    "        )\n",
    "\n",
    "        print(f\"'Erdos' description length: {state.entropy():.2e}\")\n",
    "\n",
    "        dS, nmoves = 0, 0\n",
    "\n",
    "        for i in range(10):\n",
    "            # print(\"#\", end=\"\")\n",
    "            ret = state.multilevel_mcmc_sweep(niter=1)\n",
    "            dS += ret[0]\n",
    "            nmoves += ret[1]\n",
    "            print(f\"entropy : {state.entropy():.2e}, S : {dS:.2e}\", f\"dS: {ret[0]:.2e}, nmoves: {ret[1]}, number of blocks at layer 0: {len(state.get_bs()[0])}, 1: {len(state.get_bs()[1])}, 2: {len(state.get_bs()[2])}\")\n",
    "        print(\"\")\n",
    "        print(f\"Change in description length: {dS:.2e}\")\n",
    "        print(f\"final description length: {state.entropy():.2e}\")\n",
    "\n",
    "        res[g] = {\n",
    "            \"entropy\": state.entropy(),\n",
    "            \"dS\": dS,\n",
    "            \"nmoves\": nmoves,\n",
    "            \"state\": state,\n",
    "        }\n",
    "        # print(\"Number of accepted vertex moves:\", nmoves)\n",
    "\n",
    "        # print(\"Block sizes:\", state.get_bs())\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b425c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = run_sbm() # multilevel_mcmc_sweep, not B = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08501b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = run_sbm() # multilevel_mcmc_sweep, B = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ba4fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state)\n",
    "print(f\"{state.entropy():.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223697cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_state = state.project_level(1)\n",
    "\n",
    "print(f\"Projected state entropy: {projected_state.entropy():.2e}\")\n",
    "\n",
    "state1 = state.get_levels()[0]\n",
    "print(f\"Number of nodes in state 1: {state1.get_N()}\")\n",
    "print(state1)\n",
    "\n",
    "block_array = state1.get_blocks()\n",
    "i = 0\n",
    "for v in g_bridge.vertices():\n",
    "    i += 1\n",
    "\n",
    "block_array = np.zeros(i)\n",
    "for v in g_bridge.vertices():\n",
    "    block_array[state1.get_blocks()[v]] += 1\n",
    "\n",
    "nonempty_blocks = []\n",
    "nonempty_idx = []\n",
    "for i, b in enumerate(block_array):\n",
    "    if b > 0:\n",
    "        nonempty_blocks.append(b.item())\n",
    "        nonempty_idx.append(i)\n",
    "\n",
    "print(\"Nodes per block:\", nonempty_blocks)\n",
    "\n",
    "mat = state1.get_matrix()\n",
    "print(\"Matrix shape:\", mat.shape)\n",
    "nonempty_matrix = mat[nonempty_idx][:, nonempty_idx].toarray()\n",
    "#print(\"Matrix:\", nonempty_matrix)\n",
    "\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "plt.imshow(nonempty_matrix, cmap='hot', interpolation='nearest', norm=LogNorm())\n",
    "plt.colorbar()\n",
    "plt.title(\"Matrix of block sizes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = laplacian(g_bridge, weight=g_bridge.ep.weight)\n",
    "eigenvalues, eigenvectors = eigs(L, k=100, which='LM', return_eigenvectors=True)\n",
    "eigenvalues = np.real(eigenvalues)\n",
    "eigenvectors = np.real(eigenvectors)\n",
    "\n",
    "n_clusters = 1000\n",
    "kmeans = KMeans(n_clusters=n_clusters).fit(eigenvectors)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "# # print number of nodes in each cluster\n",
    "# for i in range(n_clusters):\n",
    "#     print(f\"Cluster {i}: {np.sum(clusters == i)} nodes\")\n",
    "\n",
    "# Plot the clusters\n",
    "plt.imshow(L.toarray()[:512, :512], cmap='berlin', interpolation='nearest', vmin=-np.abs(L.toarray()).max(), vmax=np.abs(L.toarray()).max())\n",
    "plt.colorbar()\n",
    "plt.title('Laplacian Matrix')\n",
    "plt.show()\n",
    "\n",
    "# sort L by cluster :\n",
    "perm = np.argsort(clusters)\n",
    "L_sorted = L[perm][:, perm].toarray()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(L_sorted[:512, :512], cmap='berlin', interpolation='nearest', vmin=-np.abs(L_sorted).max(), vmax=np.abs(L_sorted).max())\n",
    "plt.colorbar()\n",
    "plt.title('Laplacian Matrix sorted by clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be690f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = g_bridge.new_vertex_property(\"int\")\n",
    "for i, cluster in enumerate(clusters):\n",
    "    B[g_bridge.vertex(i)] = cluster  # Assign each vertex to its cluster\n",
    "\n",
    "state_laplacian = gt.BlockState(\n",
    "    g_bridge,\n",
    "    b=B,\n",
    "    recs=[g_bridge.ep.weight],\n",
    "    rec_types=rec_types,\n",
    ")\n",
    "print(f\"log-likelihood of the graph: {state_laplacian.entropy():.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c1311de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the state\n",
    "with open(path + bridge_name.replace(\"bridge\", \"state\"), \"wb\") as f:\n",
    "    pickle.dump(state, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3da968b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + bridge_name.replace(\"bridge\", \"state\"), \"rb\") as f:\n",
    "    loaded_state = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded state log-likelihood of the graph: {loaded_state.entropy():.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ad03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt.collection.data.keys())\n",
    "\n",
    "g_bridge = gt.collection.data[\"cond-mat\"]\n",
    "print(f\"Graph created, with {g_bridge.num_edges()} edges and {g_bridge.num_vertices()} vertices. Average degree: {g_bridge.num_edges() / g_bridge.num_vertices()}\")\n",
    "\n",
    "state_erdos = gt.BlockState(\n",
    "    g_bridge,\n",
    "    B=1,\n",
    ")\n",
    "print(f\"log-likelihood of the graph: {state_erdos.entropy():.2e}\")\n",
    "state = gt.NestedBlockState(\n",
    "    g_bridge,\n",
    "    B=1,\n",
    ")\n",
    "print(f\"log-likelihood of the graph: {state.entropy():.2e}\")\n",
    "dS, nmoves = 0, 0\n",
    "for i in range(100):\n",
    "    ret = state.multiflip_mcmc_sweep(niter=10)\n",
    "    dS += ret[0]\n",
    "    nmoves += ret[1]\n",
    "    print(f\"entropy : {state.entropy():.2e}, S : {dS:.2e}\", f\"dS: {ret[0]:.2e}, nmoves: {ret[1]}, number of blocks at layer 0: {len(state.get_bs()[0])}, 1: {len(state.get_bs()[1])}, 2: {len(state.get_bs()[2])}\")\n",
    "print(\"Change in description length:\", dS)\n",
    "print(\"Number of accepted vertex moves:\", nmoves)\n",
    "print(\"Block sizes:\", state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8ec06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
