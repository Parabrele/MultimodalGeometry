{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO :\n",
    "it is not clear which SAE is best, as they all have pretty similar performance, some being worse on some metrics but better on others.\n",
    "We chose BatchTopK as they seem to be generally good across all metrics and align with assumptions on the atoms, while MP, though about as good across al metrics, and significantly better in sparse reconstruction, has an encoder that does not align with how atoms are used for subsequent tasks (cosim comparison, linear operations, etc).\n",
    "\n",
    "Changement de plan : ne pas changer de plan. Batchtopk c'est pourris. La compétition dans topk fait que le dict ne peut tout simplement pas apprendre plusieurs atomes géométriquement proches, faute de quoi ils seraient tous actifs en même temps. Donc si t'as un biais pour le texte et un pour l'image, qui ont une cosim non nulle, le topk sera obligé d'apprendre un terme commun et deux termes quasi orthogonaux. Du coup ça règle la question des features bimodal-divergent, elles ne peuvent juste plus exister dans un batchtopk. C'est stupide.\n",
    "\n",
    "Du coup, changement de plan, dire \"nos assumptions sont IsoE, encoder assumption, linear represenation, superposition, ...\", puis \"on sépare les features en trois catégories : bimodal aligned, bimodal divergent, modality specific\" -> les deux derniers sont indistinguables dans un SAE normal mais pas dans un crosscodeur. Cependant, encodeur assumption => pas de bimodal divergent. Cependant, s'il y en a, on veut les trouver quand même, et un batchtopk ne peut pas. Donc on fait MP, parce que de toute façon, c'est pas plus non linéaire que BatchTopK. Il y a que vanilla ReLU SAE qui colle à l'assumption de linéarité mais personne ne les utilises parce que c'est pourri.\n",
    "\n",
    "We find that modality gap useless, bimodal <3 <3 <3, but still, unimodal has a little bit of information.\n",
    "This suggests a violation of our core assumptions, either the IsoE assumption is false, or CLIP violates the encoder assumption (give it a cool name, the assumption that CLIP's towers reverse the DGP that went from c to instances of image and texts, and so that SAEs are only meant for disentangling these representations, not actually reverse the DGP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model : CLIP (default)\n",
    "CLIP (Contrastive Language-Image Pretraining) is a model developed by OpenAI that learns to associate images and text. It can be used for various tasks such as zero-shot classification, image generation, and more. CLIP uses a transformer architecture to process both images and text, allowing it to learn rich multimodal representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "\n",
    "# Parameters\n",
    "fs = 44100\n",
    "duration = 1.0\n",
    "f0 = 440  # Hz\n",
    "\n",
    "t = np.linspace(0, duration, int(fs*duration), endpoint=False)\n",
    "\n",
    "# ADSR envelope\n",
    "attack, decay, sustain, release = 0.1, 0.1, 0.7, 0.2\n",
    "sustain_time = duration - (attack + decay + release)\n",
    "\n",
    "env = np.zeros_like(t)\n",
    "A = int(attack*fs)\n",
    "D = int(decay*fs)\n",
    "S = int(sustain_time*fs)\n",
    "R = int(release*fs)\n",
    "\n",
    "env[:A] = np.linspace(0, 1, A, endpoint=False)\n",
    "env[A:A+D] = np.linspace(1, sustain, D, endpoint=False)\n",
    "env[A+D:A+D+S] = sustain\n",
    "env[A+D+S:] = np.linspace(sustain, 0, R, endpoint=False)\n",
    "\n",
    "# Messy violin-like signal: harmonics + vibrato + slight noise\n",
    "vibrato = 5*np.sin(2*np.pi*6*t)  # 6 Hz vibrato, ±5 Hz\n",
    "phase = 2*np.pi*(f0*t + np.cumsum(vibrato)/fs)\n",
    "\n",
    "signal = env * (\n",
    "    np.sin(phase) +\n",
    "    0.5*np.sin(2*phase) +\n",
    "    0.3*np.sin(3*phase) +\n",
    "    0.2*np.sin(4*phase)\n",
    ")\n",
    "\n",
    "# add small random noise for realism\n",
    "signal += 0.02*np.random.randn(len(t))\n",
    "\n",
    "# Plot time-domain waveform\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(t, signal, lw=0.7)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Violin-like note (time domain, messy waveform)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Frequency spectrum\n",
    "N = len(signal)\n",
    "yf = np.abs(rfft(signal)) / N\n",
    "xf = rfftfreq(N, 1/fs)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.stem(xf, yf, basefmt=\" \")\n",
    "plt.xlim(0, 5000)\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Violin-like note (frequency domain)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import overcomplete\n",
    "\n",
    "from src import losses, train, metrics\n",
    "from src.utils import (\n",
    "    get_coco, get_laion, get_imagenet,\n",
    "    _train,\n",
    "    measure_everything, measure_bridge, get_bridge_norms,\n",
    "    get_rho,\n",
    ")\n",
    "from src.utils import (\n",
    "    plot_energy, plot_energy_cdf, plot_E_vs_E_B,\n",
    "    plot_modality_energy, mu_vs_mu_B,\n",
    "    plot_bridges,\n",
    ")\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "use_model = \"clip\"  # openclip or siglip\n",
    "\n",
    "if use_model == \"clip\":\n",
    "    model_name = \"openai/clip-vit-base-patch32\"\n",
    "    d_model = 512\n",
    "    beta = 4e-4\n",
    "elif use_model == \"clip-L\":\n",
    "    model_name = \"openai/clip-vit-large-patch14\"\n",
    "    d_model = 768\n",
    "    beta = 1e-4\n",
    "elif use_model == \"openclip\":\n",
    "    model_name=\"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\"\n",
    "    d_model = 512\n",
    "    beta = 4e-4\n",
    "elif use_model == \"openclip-L\":\n",
    "    model_name=\"laion/CLIP-ViT-L-14-laion2B-s32B-b82K\"\n",
    "    d_model = 768\n",
    "    beta = 2e-4\n",
    "elif use_model == \"siglip\":\n",
    "    model_name = \"google/siglip-base-patch16-224\"\n",
    "    d_model = 768\n",
    "    beta = 1e-4\n",
    "elif use_model == \"siglip2\":\n",
    "    model_name = \"google/siglip2-base-patch16-224\"\n",
    "    d_model = 768\n",
    "    beta = 7e-5\n",
    "else:\n",
    "    raise NotImplementedError(f\"Model {use_model} not recognized.\")\n",
    "\n",
    "laion_loader = get_laion(device=device, model_name=model_name)\n",
    "# coco_loader = get_coco(device=device)\n",
    "# imagenet_test_loader, class_embeddings = get_imagenet(batch_size=512, model_name=model_name, device=device)\n",
    "# imagenet_train_loader, class_embeddings = get_imagenet(batch_size=512, model_name=model_name, device=device, split=\"train\")\n",
    "\n",
    "train_loader = laion_loader\n",
    "modality_threshold = 0.05\n",
    "\n",
    "betas = torch.logspace(-5, -2, 100, device=device)  # beta values to try\n",
    "l2s, r2s, Es_in_degenerate, Es_in_bimodal, Es_tot = [], [], [], [], []\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def wtf(beta):\n",
    "#     ASAE, ASAE_name, _ = _train(beta=beta, train_loader=train_loader, model_name=model_name, d_model=d_model, UseTOPK=False, device=device) #, force_retrain=True, save_quand_meme=True) # Aligned SAE\n",
    "#     ASAE.metrics = measure_everything(ASAE, train_loader, device, return_sqr=True)\n",
    "#     l2, r2 = metrics.l2_r2(ASAE, train_loader)\n",
    "    \n",
    "#     E = ASAE.metrics.E\n",
    "#     f = ASAE.metrics.f\n",
    "#     mu = ASAE.metrics.mu\n",
    "#     degenerate_mask = (f > 0.9)\n",
    "#     bimodal_mask = (mu > modality_threshold) & (mu < (1 - modality_threshold))\n",
    "    \n",
    "#     E_in_degenerate = E[degenerate_mask].sum().item()\n",
    "#     E_in_bimodal = E[bimodal_mask & ~degenerate_mask].sum().item()\n",
    "#     E_tot = E.sum().item()\n",
    "\n",
    "#     return l2, r2, E_in_degenerate, E_in_bimodal, E_tot\n",
    "\n",
    "# for beta in tqdm(betas):\n",
    "#     l2, r2, E_in_degenerate, E_in_bimodal, E_tot = wtf(beta.item())\n",
    "\n",
    "#     print(f\"Beta: {beta:.6f}, L2: {l2:.4f}, R2: {r2:.4f}, E_in_degenerate: {E_in_degenerate:.4f}, E_in_bimodal: {E_in_bimodal:.4f}, E_tot: {E_tot:.4f}\")\n",
    "#     l2s.append(l2)\n",
    "#     r2s.append(r2.item())\n",
    "#     Es_in_degenerate.append(E_in_degenerate / E_tot)\n",
    "#     Es_in_bimodal.append(E_in_bimodal / E_tot)\n",
    "#     Es_tot.append(E_tot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2s = [0.8471270799636841, 0.8477537035942078, 0.8474643230438232, 0.8472068905830383, 0.8475709557533264, 0.847588837146759, 0.8474730849266052, 0.847104012966156, 0.8470807671546936, 0.8477079272270203, 0.8470604419708252, 0.8473597764968872, 0.8469316363334656, 0.8480101823806763, 0.8480943441390991, 0.8476691246032715, 0.8475169539451599, 0.8472616672515869, 0.8474118709564209, 0.8473469018936157, 0.8474711775779724, 0.8469681739807129, 0.8466691374778748, 0.847098171710968, 0.847135603427887, 0.8471106290817261, 0.8468508720397949, 0.8469724059104919, 0.8464853167533875, 0.8460384011268616, 0.8462086915969849, 0.8461043238639832, 0.845971941947937, 0.8457302451133728, 0.8456987142562866, 0.8448388576507568, 0.8443150520324707, 0.8444170951843262, 0.8386593461036682, 0.8424999713897705, 0.841633141040802, 0.8407778739929199, 0.8404752612113953, 0.8403682112693787, 0.8386974334716797, 0.8353956341743469, 0.8361472487449646, 0.8363955616950989, 0.8357362151145935, 0.8341480493545532, 0.8323978781700134, 0.8298661708831787, 0.821643054485321, 0.8270752429962158, 0.8242298364639282, 0.8244916200637817, 0.8241608738899231, 0.8218496441841125, 0.8202092051506042, 0.8213890790939331, 0.8169975280761719, 0.80110764503479, 0.779854953289032, 0.7974963188171387, 0.7336429357528687, 0.7288471460342407, 0.7546337842941284, 0.7429816722869873, 0.7112916707992554, 0.6983168125152588, 0.6960105895996094, 0.6613096594810486, 0.641830563545227, 0.6298071146011353, 0.5898458361625671, 0.5714426636695862, 0.5319939255714417, 0.35821810364723206, 0.345608651638031, 0.34735584259033203, 0.32399606704711914, 0.3207992911338806, 0.29147595167160034, 0.3034614622592926, 0.28855839371681213, 0.28426653146743774, 0.290071040391922, 0.29245632886886597, 0.2676733434200287, 0.28811293840408325, 0.24682894349098206, 0.2725927233695984, 0.26762112975120544, 0.25793737173080444, 0.27988436818122864, 0.2779000997543335, 0.31128180027008057, 0.28164151310920715, 0.29129403829574585, 0.2870906889438629]\n",
    "l2s = [0.15286938533330408, 0.15224318892046665, 0.15253203936695034, 0.15278984544552757, 0.15242620526723433, 0.1524078126150247, 0.15252439731400824, 0.15289238146727954, 0.1529156966076579, 0.1522889219692905, 0.15293670671042744, 0.1526369882576147, 0.15306491494331298, 0.15198655828123458, 0.15190236236477045, 0.152327117091673, 0.15247982050819203, 0.15273450172941047, 0.152584720694547, 0.1526492706918377, 0.15252555536727166, 0.15302784066025893, 0.15332804651875193, 0.1528991094875631, 0.15286142426191746, 0.15288580638952545, 0.15314667915042374, 0.15302405330213692, 0.15351139228122773, 0.1539579382402792, 0.15378751139287158, 0.1538923883643353, 0.15402468997419755, 0.15426656561065447, 0.15429803579206133, 0.15515817045314526, 0.15568217853174812, 0.15557940669909517, 0.1613363983837233, 0.15749622268929256, 0.15836381350557113, 0.1592189510612954, 0.15952131037690798, 0.15962883563950855, 0.1612990745629988, 0.16459954433717958, 0.16384875097578014, 0.16360057636303715, 0.16426033429172124, 0.16584767118407762, 0.16759936518039112, 0.17012962216669875, 0.17835134841991238, 0.17292023112753613, 0.175764979279299, 0.17550300343376118, 0.17583434381370777, 0.17814412718001282, 0.17978545812306124, 0.1786057345600743, 0.18299688840798678, 0.1988869497796315, 0.220139156055733, 0.2024978810752018, 0.26635042231032985, 0.27114674262522676, 0.24535959933475174, 0.2570118544056171, 0.2887034458116922, 0.30168051423468617, 0.3039869844475971, 0.3386869344872608, 0.3581656570742193, 0.3701886712946863, 0.4101486517022645, 0.4285513778822374, 0.46799837037201464, 0.6417855868561854, 0.6543897325554965, 0.652643958064784, 0.6760020798584029, 0.6792016564139308, 0.7085371184326047, 0.6965386608494725, 0.7114448601951925, 0.7157360116181362, 0.7099310279323339, 0.7075484033899196, 0.7323288948929975, 0.711890027323364, 0.7531706445125991, 0.7274143595083139, 0.7323849247549222, 0.7420714045858573, 0.7201271717276873, 0.7221099101573107, 0.6887323904118824, 0.718367292821125, 0.7087201779184498, 0.7129216845604077]\n",
    "Es_in_degenerate = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25959705802115446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27226849322022256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15741910566189574, 0.2513232412854947, 0.0, 0.24499231098397647, 0.23483869994328177, 0.0, 0.0, 0.0, 0.0, 0.4745973940360938, 0.6573640649700063, 0.4808152547344781, 0.8224089447025716, 0.8333885152342984, 0.7575605223379728, 0.7857557576704108, 0.8593726591522545, 0.8694006327483957, 0.8712143595763083, 0.8789431222039618, 0.8829776980130783, 0.8865836340282149, 0.8950623881093239, 0.8991387111450867, 0.9038383389560609, 0.9341428329999175, 0.9378026423642712, 0.9390313287359725, 0.9451222755770702, 0.9495898515273906, 0.9960121443433746, 0.9563202772313331, 0.966600622864906, 0.9695309212471561, 0.9644047419005354, 0.9678104158936472, 0.987660191159391, 0.973167356758933, 0.9885628612833419, 0.9928619036340316, 0.9939286809293985, 0.9975405184027062, 0.9977101456811727, 0.9984801046417172, 0.9961143289998017, 0.9990889805874419, 0.998109468097601, 0.998993555480274]\n",
    "Es_in_bimodal = [0.28056837325001266, 0.2791806923769942, 0.2830089257627494, 0.28124897603186805, 0.28090208147506174, 0.2831744600809655, 0.29006049094491376, 0.2872127887582236, 0.2791614607134614, 0.28550153695829344, 0.2857420326548741, 0.28828113094444807, 0.2828630079638485, 0.2830982384762928, 0.28645304675943806, 0.2963123448047671, 0.2936925080550728, 0.2910731141079016, 0.2962508180576517, 0.2956354953224143, 0.2905085813243365, 0.29743937156472156, 0.3036051407390845, 0.30426776258428073, 0.3025420033923383, 0.3045520605464526, 0.31258648282844725, 0.30936505353149174, 0.31330395516068793, 0.3212161871398127, 0.32254171311857155, 0.3267352317949248, 0.33026604735200177, 0.33258094430182317, 0.3377788189351328, 0.3511810018810298, 0.3541530433717741, 0.3534827067821889, 0.30708496601375834, 0.40691200335984995, 0.4071046018942464, 0.43606577045698025, 0.42003259319184116, 0.4364762862567092, 0.46682953957621054, 0.34520978613793335, 0.4343756997258249, 0.4477808948286244, 0.48154161415041713, 0.4743911555398545, 0.46275439338771035, 0.49307684925826617, 0.45602931594685675, 0.4313914253054964, 0.6026343865812198, 0.43258769501214783, 0.45629202591125007, 0.6707088137460079, 0.6948313411441596, 0.6923687647341309, 0.7177604380037602, 0.30697514145311733, 0.20257364907140765, 0.3156055419852461, 0.06047494606413658, 0.06200362262253669, 0.15029854962603273, 0.13337246554581247, 0.04524669693037746, 0.026475075206497205, 0.032929738705043954, 0.0240644653312398, 0.027017774753220848, 0.025496257295700785, 0.02333846665964243, 0.02147445082258719, 0.022709746695593055, 0.054535002770823425, 0.04519382770106961, 0.05467140107887884, 0.05298883613142839, 0.048926941033538396, 0.003968089667603372, 0.04314398893102642, 0.0333860652592096, 0.030458024129735976, 0.035587377549412345, 0.03217252623500613, 0.012328079214585856, 0.026826435673041743, 0.01142290903133892, 0.007134234362986226, 0.006066983936903304, 0.002454568488430711, 0.002275146540028688, 0.001515947317531605, 0.003868772279813372, 0.0008781744283922075, 0.0018853443691432541, 0.001004370291531495]\n",
    "Es_tot = [0.8477544784545898, 0.848163366317749, 0.847916305065155, 0.8476754426956177, 0.8479911088943481, 0.8482930064201355, 0.8480300903320312, 0.8476519584655762, 0.8475362062454224, 0.8481579422950745, 0.8475993871688843, 0.847968578338623, 0.8474289178848267, 0.848482608795166, 0.848540186882019, 0.8481056690216064, 0.8483318090438843, 0.8478139638900757, 0.8479219675064087, 0.8478422164916992, 0.8478667736053467, 0.8474538326263428, 0.8471779227256775, 0.8476243615150452, 0.8475947380065918, 0.8475282788276672, 0.847251832485199, 0.847458004951477, 0.8470689058303833, 0.8465664386749268, 0.8469842672348022, 0.8476683497428894, 0.8466296195983887, 0.8462467193603516, 0.8475314974784851, 0.8454155921936035, 0.8449605703353882, 0.8451530933380127, 0.873070478439331, 0.8458560705184937, 0.8426194787025452, 0.841567873954773, 0.8414056897163391, 0.841474175453186, 0.8410202860832214, 0.8782918453216553, 0.8374539613723755, 0.8380166292190552, 0.8402600288391113, 0.836012065410614, 0.8348323106765747, 0.8360180854797363, 0.8840599060058594, 0.8779496550559998, 0.8719735145568848, 0.8793391585350037, 0.8710829615592957, 0.8716825246810913, 0.8615025281906128, 0.8709375262260437, 0.8850370049476624, 1.0625784397125244, 1.443810224533081, 1.1098324060440063, 1.8603291511535645, 1.9219441413879395, 1.8525278568267822, 2.0379889011383057, 2.065673351287842, 2.1329803466796875, 2.1310999393463135, 2.1144330501556396, 2.095106363296509, 2.0991156101226807, 2.0523765087127686, 2.0400235652923584, 1.9595680236816406, 1.5165627002716064, 1.5186126232147217, 1.5108684301376343, 1.4633742570877075, 1.4669060707092285, 1.5931816101074219, 1.4436969757080078, 1.4344964027404785, 1.4328787326812744, 1.438012957572937, 1.4675893783569336, 1.476189374923706, 1.4798977375030518, 1.0706192255020142, 1.5370910167694092, 1.527235984802246, 1.5297387838363647, 1.5772027969360352, 1.1928024291992188, 1.5661733150482178, 1.1944228410720825, 1.504199743270874, 1.499762773513794]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2s)\n",
    "print(l2s)\n",
    "print(Es_in_degenerate)\n",
    "print(Es_in_bimodal)\n",
    "print(Es_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "nthbeta = 60\n",
    "threshold = betas[nthbeta].item()\n",
    "\n",
    "plt.plot(betas.cpu().numpy(), l2s, label='L2')\n",
    "plt.plot(betas.cpu().numpy(), r2s, label='R2')\n",
    "plt.axvline(threshold, color='red', linestyle='--', label=f'Beta = {threshold:.1e}')\n",
    "plt.xscale('log')\n",
    "# plt.xlabel('Beta')\n",
    "# plt.ylabel('Metric Value')\n",
    "# plt.title('L2 and R2 vs Beta')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"l2_r2_vs_beta.png\")\n",
    "plt.figure()\n",
    "\n",
    "####\n",
    "# V1\n",
    "####\n",
    "\n",
    "# stackplot, normalize Es_in_degenerate and Es_in_bimodal\n",
    "Es_in_degenerate_array = np.array(Es_in_degenerate)\n",
    "Es_in_bimodal_array = np.array(Es_in_bimodal)\n",
    "plt.stackplot(betas.cpu().numpy(), Es_in_bimodal_array, Es_in_degenerate_array, labels=['Es_in_bimodal', 'E_in_degenerate'])\n",
    "plt.axvline(threshold, color='red', linestyle='--', label=f'Beta = {threshold:.1e}')\n",
    "plt.xscale('log')\n",
    "# plt.xlabel('Beta')\n",
    "# plt.ylabel('Energy Fraction')\n",
    "# plt.title('Energy in Degenerate and Bimodal Regions vs Beta')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"energy_vs_beta.png\")\n",
    "plt.figure()\n",
    "\n",
    "####\n",
    "# V2\n",
    "####\n",
    "\"\"\"\n",
    "def smooth(y, window=5):\n",
    "    return np.convolve(y, np.ones(window)/window, mode='same')\n",
    "\n",
    "Es_in_degenerate_smooth = smooth(Es_in_degenerate_array, window=5)\n",
    "Es_in_bimodal_smooth    = smooth(Es_in_bimodal_array, window=5)\n",
    "\n",
    "plt.stackplot(betas.cpu().numpy(), Es_in_bimodal_smooth, Es_in_degenerate_smooth, labels=['E_in_bimodal', 'E_in_degenerate'])\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"energy_vs_beta_smooth.png\")\n",
    "plt.figure()\n",
    "\n",
    "####\n",
    "# V3\n",
    "####\n",
    "\n",
    "plt.stackplot(betas.cpu().numpy(), Es_in_bimodal_array, Es_in_degenerate_array,\n",
    "              labels=['bimodal', 'degenerate'], alpha=0.2)\n",
    "\n",
    "# Smoothed curves in bold\n",
    "plt.plot(betas.cpu().numpy(), Es_in_bimodal_smooth, color='C0', lw=2)\n",
    "plt.plot(betas.cpu().numpy(), Es_in_degenerate_smooth + Es_in_bimodal_smooth, color='C1', lw=2)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"energy_vs_beta_overlay.png\")\n",
    "plt.figure()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# siglip :\n",
    "img_highE = [\n",
    "    366, 3160, 5780, 5626, 3146, 4824, 4712, 4042, 6143\n",
    "]\n",
    "img_lowE = [\n",
    "    5523, 4028, 6017, 4064, 274, 1756, 3415\n",
    "]\n",
    "txt_highE = [\n",
    "    1112, 3855, 3122, 5581,\n",
    "]\n",
    "txt_lowE = [\n",
    "    5353, 6065, 4036, 3983, 2412, 5831, 697, 3138, 5895,\n",
    "]\n",
    "bi_idxs_highE = [\n",
    "    1195, 2465, 991, 273, 2739, 1793, 4774, 5806, 2811, 4477, 858, 5899, 5163\n",
    "]\n",
    "bi_idxs_lowE = [\n",
    "    3554, 352, 48, 4717, 3597, 5425, 3507, 5602, 2830, 1173, 2387, 4338, 4933, 229, 5797, 4182, 3525\n",
    "]\n",
    "\n",
    "def plot_app_pacc(D, I, T, Z_I, Z_T):\n",
    "    print(I.shape)\n",
    "    \n",
    "    for i, idx in enumerate(bi_idxs_highE + bi_idxs_lowE):\n",
    "        D_i = D[idx].unsqueeze(0)  # Shape (1, d_model)\n",
    "        Ii = I @ D_i.T  # Shape (n_samples, 1)\n",
    "        Ti = T @ D_i.T  # Shape (n_samples, 1)\n",
    "        # concatenate to 2*n_samples, shape (2*n_samples, 1)\n",
    "        Ai = torch.cat([Ii, Ti], dim=0).cpu().detach()\n",
    "        Z_I_i, Z_T_i = Z_I[:, i], Z_T[:, i]  # Shape (n_samples,)\n",
    "        active_idxs = (Z_I_i != 0) | (Z_T_i != 0)  # Shape (n_samples,)\n",
    "        print(f\"Feature {i} - active samples: {active_idxs.sum()}/{len(active_idxs)}\")\n",
    "         \n",
    "        bins = np.linspace(Ai.min(), Ai.max(), 100)\n",
    "        bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "        digitized = np.digitize(Ai, bins) - 1 # shape (n_samples,) : contains the bin index for each sample\n",
    "        weights = np.ones_like(Ai) / len(Ai)  # Uniform weights for density plot\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for b in range(len(bins) - 1):\n",
    "            b_idx = np.where(digitized == b)[0]\n",
    "            if len(b_idx) == 0:\n",
    "                continue\n",
    "            \n",
    "            bottom = 0\n",
    "            \n",
    "            for zgzfeg in [0, 1]:  # 0 for active, 1 for inactive\n",
    "                for aerzg in [0, 1]:  # 0 for I, 1 for T\n",
    "                    if aerzg == 0 and zgzfeg == 0:\n",
    "                        continue\n",
    "                    elif aerzg == 1 and zgzfeg == 0:\n",
    "                        continue\n",
    "                    elif aerzg == 0 and zgzfeg == 1:\n",
    "                        color = np.array([128/255, 230/255, 255/255]) # Light blue\n",
    "                        retained_indices = b_idx[b_idx < len(I)]\n",
    "                        retained_indices = retained_indices[~active_idxs[retained_indices]]\n",
    "                    elif aerzg == 1 and zgzfeg == 1:\n",
    "                        color = np.array([255/255, 205/255, 102/255])  # Light orange\n",
    "                        retained_indices = b_idx[b_idx >= len(I)] - len(I)\n",
    "                        retained_indices = retained_indices[~active_idxs[retained_indices]]\n",
    "                    height = weights[retained_indices].sum()\n",
    "                    plt.bar(bin_centers[b], height, width=(bins[1] - bins[0]), bottom=bottom, color=color, edgecolor='none')\n",
    "                    bottom += height\n",
    "        plt.title(f\"Distribution of {['High', 'Low'][i >= len(bi_idxs_highE)]} Energy Feature {idx}'s Activations\")\n",
    "        plt.xlabel(\"Activation Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        # plt.yscale('log')\n",
    "        plt.show()\n",
    "        \n",
    "        max_height = 0\n",
    "        for b in range(len(bins) - 1):\n",
    "            b_idx = np.where(digitized == b)[0]\n",
    "            bin_height = weights[b_idx].sum()\n",
    "            if bin_height > max_height:\n",
    "                max_height = bin_height\n",
    "        print(f\"Max height: {max_height}\")\n",
    "        max_height *= 0.1\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for b in range(len(bins) - 1):\n",
    "            b_idx = np.where(digitized == b)[0]\n",
    "            if len(b_idx) == 0:\n",
    "                continue\n",
    "            \n",
    "            bottom = 0\n",
    "            \n",
    "            for zgzfeg in [0, 1]:  # 0 for active, 1 for inactive\n",
    "                for aerzg in [0, 1]:  # 0 for I, 1 for T\n",
    "                    if aerzg == 0 and zgzfeg == 0:\n",
    "                        color = np.array([0/255, 145/255, 181/255])  # Dark blue\n",
    "                        retained_indices = b_idx[b_idx < len(I)]\n",
    "                        retained_indices = retained_indices[active_idxs[retained_indices]]\n",
    "                    elif aerzg == 1 and zgzfeg == 0:\n",
    "                        color = np.array([208/255, 140/255, 0/255])  # Dark orange\n",
    "                        retained_indices = b_idx[b_idx >= len(I)] - len(I)\n",
    "                        retained_indices = retained_indices[active_idxs[retained_indices]]\n",
    "                    elif aerzg == 0 and zgzfeg == 1:\n",
    "                        color = np.array([128/255, 230/255, 255/255]) # Light blue\n",
    "                        retained_indices = b_idx[b_idx < len(I)]\n",
    "                        retained_indices = retained_indices[~active_idxs[retained_indices]]\n",
    "                    elif aerzg == 1 and zgzfeg == 1:\n",
    "                        color = np.array([255/255, 205/255, 102/255])  # Light orange\n",
    "                        retained_indices = b_idx[b_idx >= len(I)] - len(I)\n",
    "                        retained_indices = retained_indices[~active_idxs[retained_indices]]\n",
    "                    height = weights[retained_indices].sum()\n",
    "                    if height+bottom > max_height: height = max_height - bottom\n",
    "                    plt.bar(bin_centers[b], height, width=(bins[1] - bins[0]), bottom=bottom, color=color, edgecolor='none')\n",
    "                    bottom += height\n",
    "                    if bottom >= max_height:\n",
    "                        bottom = max_height\n",
    "        plt.title(f\"Distribution of {['High', 'Low'][i >= len(bi_idxs_highE)]} Energy Feature {idx}'s Activations\")\n",
    "        plt.xlabel(\"Activation Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        # plt.yscale('log')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for b in range(len(bins) - 1):\n",
    "            b_idx = np.where(digitized == b)[0]\n",
    "            if len(b_idx) == 0:\n",
    "                continue\n",
    "            \n",
    "            bottom = 0\n",
    "            \n",
    "            for zgzfeg in [0, 1]:  # 0 for active, 1 for inactive\n",
    "                for aerzg in [0, 1]:  # 0 for I, 1 for T\n",
    "                    if aerzg == 0 and zgzfeg == 0:\n",
    "                        color = np.array([0/255, 145/255, 181/255])  # Dark blue\n",
    "                        retained_indices = b_idx[b_idx < len(I)]\n",
    "                        retained_indices = retained_indices[active_idxs[retained_indices]]\n",
    "                    elif aerzg == 1 and zgzfeg == 0:\n",
    "                        color = np.array([208/255, 140/255, 0/255])  # Dark orange\n",
    "                        retained_indices = b_idx[b_idx >= len(I)] - len(I)\n",
    "                        retained_indices = retained_indices[active_idxs[retained_indices]]\n",
    "                    elif aerzg == 0 and zgzfeg == 1:\n",
    "                        color = np.array([128/255, 230/255, 255/255]) # Light blue\n",
    "                        retained_indices = b_idx[b_idx < len(I)]\n",
    "                        retained_indices = retained_indices[~active_idxs[retained_indices]]\n",
    "                    elif aerzg == 1 and zgzfeg == 1:\n",
    "                        color = np.array([255/255, 205/255, 102/255])  # Light orange\n",
    "                        retained_indices = b_idx[b_idx >= len(I)] - len(I)\n",
    "                        retained_indices = retained_indices[~active_idxs[retained_indices]]\n",
    "                    height = weights[retained_indices].sum()\n",
    "                    plt.bar(bin_centers[b], height, width=(bins[1] - bins[0]), bottom=bottom, color=color, edgecolor='none')\n",
    "                    bottom += height\n",
    "        plt.title(f\"Distribution of {['High', 'Low'][i >= len(bi_idxs_highE)]} Energy Feature {idx}'s Activations\")\n",
    "        plt.xlabel(\"Activation Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        # plt.yscale('log')\n",
    "        plt.show()\n",
    "\n",
    "# for all features in bi_idxs_highE:\n",
    "\n",
    "# Make the following plots :\n",
    "# 1. Histogram of A * D_i, the dot products between the embeddings and the feature.\n",
    "# 2. Same, but restrict A to image-caption pairs where Z_i is not zero.\n",
    "\n",
    "# Get D_i, Z_i and A_i.\n",
    "D = ASAE.dictionary._fused_dictionary.cpu().detach()\n",
    "I, T = train_loader.dataset.tensors[0].cpu().detach(), train_loader.dataset.tensors[1].cpu().detach()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_Zi(i):\n",
    "    Z_I_i = []\n",
    "    Z_T_i = []\n",
    "    for img, txt in tqdm(train_loader, desc=f\"Computing Z_{i}\"):\n",
    "        img = img.to(device)\n",
    "        txt = txt.to(device)\n",
    "        _, z_img, _ = ASAE(img) # Shape (b, K)\n",
    "        _, z_txt, _ = ASAE(txt) # Shape (b, K)\n",
    "        \n",
    "        Z_I_i.append(z_img[:, i].cpu().numpy())  # Shape (b,)\n",
    "        Z_T_i.append(z_txt[:, i].cpu().numpy()) # Shape (b,)\n",
    "    Z_I_i = np.concatenate(Z_I_i)  # Shape (n_samples,)\n",
    "    Z_T_i = np.concatenate(Z_T_i) # Shape (n_samples,)\n",
    "    return Z_I_i, Z_T_i\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_Zis(idxs):\n",
    "    Z_I_i = []\n",
    "    Z_T_i = []\n",
    "    for img, txt in tqdm(train_loader, desc=f\"Computing Z\"):\n",
    "        img = img.to(device)\n",
    "        txt = txt.to(device)\n",
    "        _, z_img, _ = ASAE(img) # Shape (b, K)\n",
    "        _, z_txt, _ = ASAE(txt) # Shape (b, K)\n",
    "        \n",
    "        Z_I_i.append(z_img[:, idxs].cpu().numpy())  # Shape (b, k)\n",
    "        Z_T_i.append(z_txt[:, idxs].cpu().numpy()) # Shape (b, k)\n",
    "    Z_I_i = np.concatenate(Z_I_i)  # Shape (n_samples, k)\n",
    "    Z_T_i = np.concatenate(Z_T_i) # Shape (n_samples, k)\n",
    "    return Z_I_i, Z_T_i\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from seaborn import histplot\n",
    "\n",
    "# Z_I, Z_T = get_Zis(bi_idxs_highE + bi_idxs_lowE)  # Shape (n_samples, k)\n",
    "print(f\"Z_I shape: {Z_I.shape}, Z_T shape: {Z_T.shape}\")\n",
    "\n",
    "plot_app_pacc(D, I, T, Z_I, Z_T)\n",
    "\n",
    "\"\"\"\n",
    "# for i, idx in enumerate(bi_idxs_highE + bi_idxs_lowE):\n",
    "    # D_i = D[idx].unsqueeze(0)  # Shape (1, d_model)\n",
    "    # Ii = I @ D_i.T  # Shape (n_samples, 1)\n",
    "    # Ti = T @ D_i.T  # Shape (n_samples, 1)\n",
    "    # #Z_I_i, Z_T_i = get_Zi(i)  # Shape (n_samples,)\n",
    "    # Z_I_i, Z_T_i = Z_I[:, i], Z_T[:, i]  # Shape (n_samples,)\n",
    "    # active_idxs = (Z_I_i != 0) | (Z_T_i != 0)  # Shape (n_samples,)\n",
    "    # print(f\"Feature {i} - active samples: {active_idxs.sum()}/{len(active_idxs)}\")\n",
    "    \n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # histplot(Ii, bins=100, kde=True, label=\"Image\", stat=\"density\")\n",
    "    # histplot(Ti, bins=100, kde=True, label=\"Text\", stat=\"density\")\n",
    "    # plt.title(f\"Dot products A * D_{i} - All samples\")\n",
    "    # plt.xlabel(\"Dot product value\")\n",
    "    # plt.ylabel(\"Density\")\n",
    "    # plt.legend()\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # histplot(Ii[active_idxs], bins=100, kde=True, label=\"Image\", stat=\"density\")\n",
    "    # histplot(Ti[active_idxs], bins=100, kde=True, label=\"Text\", stat=\"density\")\n",
    "    # plt.title(f\"Dot products A * D_{i} - Active samples (Z_{i} != 0)\")\n",
    "    # plt.xlabel(\"Dot product value\")\n",
    "    # plt.ylabel(\"Density\")\n",
    "    # plt.legend()\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    # break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def parse_latex_table(table_str):\n",
    "    rows = []\n",
    "    for line in table_str.strip().splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or not line.endswith(r\"\\\\\"):\n",
    "            continue\n",
    "        parts = [x.strip() for x in line[:-2].split(\"&\")]\n",
    "        label = parts[0]\n",
    "        try:\n",
    "            values = [float(x) for x in parts[1:] if x.replace(\".\", \"\", 1).isdigit()]\n",
    "        except ValueError:\n",
    "            values = []\n",
    "        rows.append((label, values))\n",
    "    return rows\n",
    "\n",
    "def compute_differences(rows):\n",
    "    ref_values = np.array(rows[0][1])\n",
    "    new_rows = []\n",
    "    for label, values in rows:\n",
    "        values = np.array(values)\n",
    "        if len(values) != len(ref_values):\n",
    "            delta = \"...\"\n",
    "        else:\n",
    "            delta = round(np.mean(np.abs(values - ref_values)), 3)\n",
    "        new_row = f\"{label} & \" + \" & \".join(map(str, values)) + f\" & {delta} \\\\\\\\\"\n",
    "        new_rows.append(new_row)\n",
    "    return new_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table =r\"\"\"\\quad $(\\widehat{I}, \\widehat{T})$ & 0.882 & 0.909 & 0.952 & 0.964 & 0.907 & 0.307 & ... \\\\\n",
    "        \\quad $(I_{\\mathrm{center}}, T_{\\mathrm{center}})$ & 0.898 & 0.917 & 0.951 & 0.966 & 0.921 & 0.330 & ... \\\\\n",
    "        \\quad $(\\widetilde{I}, \\widetilde{T})$ & 0.760 & 0.891 & 0.933 & 0.964 & 0.901 & 0.313 & ... \\\\\n",
    "        \\quad $(I_{\\mathrm{rand}}, I_{\\mathrm{rand}})$ & 0.745 & 0.830 & 0.924 & 0.943 & 0.856 & 0.251 & ... \\\\\n",
    "        \\quad $(I_{\\mathrm{shift}}, I_{\\mathrm{shift}})$ & 0.704 & 0.798 & 0.913 & 0.935 & 0.827 & 0.238 & ... \\\\\n",
    "\"\"\"\n",
    "\n",
    "# Extract numeric rows\n",
    "rows = []\n",
    "for line in latex_table.strip().splitlines():\n",
    "    numbers = re.findall(r\"\\d+\\.\\d+\", line)\n",
    "    rows.append([float(x) for x in numbers])\n",
    "\n",
    "print(rows)\n",
    "# Compute and print average absolute differences\n",
    "ref = np.array(rows[0])\n",
    "for i, row in enumerate(rows):\n",
    "    diff = (np.array(row) - ref).mean()\n",
    "    print(f\"Row {i}: Δ = {diff:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "latex_table = r\"\"\"\\\\quad MSE ($\\\\downarrow$)     & 0.141 $\\\\mid$ 0.163 & 0.207 $\\\\mid$ 0.213 & 0.246 $\\\\mid$ 0.257 & 0.244 $\\\\mid$ 0.253 & 0.212 $\\\\mid$ 0.214 & 0.115 $\\\\mid$ 0.115 \\\\\n",
    "        \\\\quad $R^2$ ($\\\\uparrow$)   & 0.859 $\\\\mid$ 0.837 & 0.793 $\\\\mid$ 0.787 & 0.754 $\\\\mid$ 0.742 & 0.755 $\\\\mid$ 0.747 & 0.788 $\\\\mid$ 0.784 & 0.884 $\\\\mid$ 0.885 \\\\\n",
    "        \\\\quad $\\\\ell_0$ ($\\downarrow$)   & 20 $\\\\mid$ 20 & 20 $\\\\mid$ 20 & 20 $\\\\mid$ 20 & 20 $\\\\mid$ 20 & 20 $\\\\mid$ 20 & 20 $\\\\mid$ 20 \\\\\n",
    "        \\\\quad $\\\\ell_1$ ($\\downarrow$)     & 2.941 $\\\\mid$ 3.092 & 2.986 $\\\\mid$ 2.996 & 3.155 $\\\\mid$ 3.164 & 3.137 $\\\\mid$ 3.151 & 2.996 $\\\\mid$ 2.950 & 2.726 $\\\\mid$ 2.474 \\\\\n",
    "        \\\\quad $\\\\rho$ ($\\\\uparrow$)   & 0.327 $\\\\mid$ 4.232 & 1.566 $\\\\mid$ 4.086 & 4.072 $\\\\mid$ 16.02 & 8.737 $\\\\mid$ 16.58 & 1.370 $\\\\mid$ 2.182 & 0.713 $\\\\mid$ 1.475 \\\\\n",
    "        \\\\quad $\\delta_{\\\\mathrm{r@1}}$ ($\\downarrow$)   & -0.224 $\\\\mid$ -0.125 & -0.039 $\\\\mid$ -0.021 & -0.037 $\\\\mid$ -0.018 & -0.001 $\\\\mid$ +0.000 & -0.023 $\\\\mid$ -0.006 & -0.007 $\\\\mid$ +0.006 \\\\\n",
    "        \\\\quad $\\\\mathrm{FDA}$ ($\\\\uparrow$)   & 2.630 $\\\\mid$ 4.559 & 3.914 $\\\\mid$ 4.800 & 4.369 $\\\\mid$ 8.160 & 9.787 $\\\\mid$ 16.49 & 8.831 $\\\\mid$ 34.95 & 8.246 $\\\\mid$ 18.24 \\\\\n",
    "        \\\\quad $p_{\\\\mathrm{acc}}$ ($\\\\uparrow$)   & 0.847 $\\\\mid$ 0.915 & 0.843 $\\\\mid$ 0.868 & 0.849 $\\\\mid$ 0.880 & 0.845 $\\\\mid$ 0.873 & 0.897 $\\\\mid$ 0.899 & 0.886 $\\\\mid$ 0.903 \\\\\"\"\"\n",
    "\n",
    "for line in latex_table.strip().splitlines():\n",
    "    numbers = re.findall(r\"\\d+\\.\\d+\", line)\n",
    "    pairs = []\n",
    "    for i in range(0, len(numbers), 2):\n",
    "        if i + 1 < len(numbers):\n",
    "            pairs.append((numbers[i], numbers[i + 1]))\n",
    "            \n",
    "    if not pairs:\n",
    "        continue\n",
    "    left_vals = np.array([float(l) for l, _ in pairs])\n",
    "    right_vals = np.array([float(r) for _, r in pairs])\n",
    "    mean_left = np.mean(left_vals)\n",
    "    std_left = np.std(left_vals)\n",
    "    mean_right = np.mean(right_vals)\n",
    "    std_right = np.std(right_vals)\n",
    "    print(f\"Left: {mean_left:.3f} +- {std_left:.3f}, Right: {mean_right:.3f} +- {std_right:.3f}\")\n",
    "    mean_diff = np.mean(right_vals - left_vals)\n",
    "    std_diff = np.std(right_vals - left_vals)\n",
    "    mean_ratio = np.mean(right_vals / left_vals)\n",
    "    std_ratio = np.std(right_vals / left_vals)\n",
    "    print(f\"Δ = {mean_diff:.3f} +- {std_diff:.3f}, Ratio = {mean_ratio:.3f} +- {std_ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "u = np.linspace(0, 2*np.pi, 2000)\n",
    "v = np.linspace(0, np.pi, 1000)\n",
    "R = 1\n",
    "\n",
    "# Sphere surface\n",
    "x = R * np.outer(np.cos(u), np.sin(v))\n",
    "y = R * np.outer(np.sin(u), np.sin(v))\n",
    "z = R * np.outer(np.ones_like(u), np.cos(v))\n",
    "\n",
    "# ax.plot_surface(x, y, z, color='lightblue', alpha=0.3, edgecolor='none')\n",
    "\n",
    "def draw_circle(axis, fixed_val, ax, linestyle_front='-', linestyle_back=':'):\n",
    "    t = np.linspace(0, 2*np.pi, 400)\n",
    "    r = np.sqrt(1 - fixed_val**2)\n",
    "\n",
    "    # Circle coordinates depending on axis\n",
    "    if axis == 'x':\n",
    "        fx = np.full_like(t, fixed_val)\n",
    "        fy = r * np.cos(t)\n",
    "        fz = r * np.sin(t)\n",
    "    elif axis == 'y':\n",
    "        fx = r * np.cos(t)\n",
    "        fy = np.full_like(t, fixed_val)\n",
    "        fz = r * np.sin(t)\n",
    "    elif axis == 'z':\n",
    "        fx = r * np.cos(t)\n",
    "        fy = r * np.sin(t)\n",
    "        fz = np.full_like(t, fixed_val)\n",
    "\n",
    "    # Get camera direction from view_init\n",
    "    elev, azim = np.radians(ax.elev), np.radians(ax.azim)\n",
    "    cam_dir = np.array([\n",
    "        np.cos(elev) * np.cos(azim),\n",
    "        np.cos(elev) * np.sin(azim),\n",
    "        np.sin(elev)\n",
    "    ])\n",
    "\n",
    "    # Points on circle\n",
    "    pts = np.vstack((fx, fy, fz)).T\n",
    "    dots = pts @ cam_dir  # dot product with camera direction\n",
    "\n",
    "    front = dots >= 0\n",
    "    \n",
    "    # Helper: plot continuous segments\n",
    "    def plot_segments(mask, style):\n",
    "        idx = np.where(mask[:-1] != mask[1:])[0] + 1\n",
    "        split_fx = np.split(fx, idx)\n",
    "        split_fy = np.split(fy, idx)\n",
    "        split_fz = np.split(fz, idx)\n",
    "        split_mask = np.split(mask, idx)\n",
    "        for xseg, yseg, zseg, mseg in zip(split_fx, split_fy, split_fz, split_mask):\n",
    "            if np.all(mseg):  # all front or all back\n",
    "                ax.plot(xseg, yseg, zseg, 'k' + style, linewidth=0.3)\n",
    "\n",
    "    plot_segments(front, linestyle_front)\n",
    "    plot_segments(~front, linestyle_back)\n",
    "\n",
    "\n",
    "# --- Point cloud ---\n",
    "n_points = 500\n",
    "color_I = np.array([128/255, 230/255, 255/255])\n",
    "color_T = np.array([255/255, 205/255, 102/255])\n",
    "\n",
    "# Image points :\n",
    "mean = np.array([0, 0.5, 1])\n",
    "std_dev = 0.1\n",
    "points1 = mean + std_dev * np.random.randn(n_points, 3)\n",
    "mean = np.array([0, -0.5, 1])\n",
    "points2 = mean + std_dev * np.random.randn(n_points, 3)\n",
    "I = np.vstack((points1, points2))\n",
    "\n",
    "# Text points :\n",
    "mean = np.array([1, 0., 0.5])\n",
    "points3 = mean + std_dev * np.random.randn(n_points, 3)\n",
    "mean = np.array([1, -0., -0.5])\n",
    "points4 = mean + std_dev * np.random.randn(n_points, 3)\n",
    "T = np.vstack((points3, points4))\n",
    "\n",
    "\n",
    "def draw_raw(I, T):\n",
    "    fig = plt.figure(figsize=(10,10), facecolor=\"#FFE5DF00\")\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.view_init(elev=10, azim=-70)\n",
    "    draw_circle('x', 0, ax=ax)\n",
    "    draw_circle('y', 0, ax=ax)\n",
    "    draw_circle('z', 0, ax=ax)\n",
    "\n",
    "    # Tropics on xy-plane (z = ±2/3 R)\n",
    "    # draw_circle('z', 2/3*R, ax=ax)\n",
    "    # draw_circle('z', -2/3*R, ax=ax)\n",
    "    # draw_circle('y', 2/3*R, ax=ax)\n",
    "    # draw_circle('y', -2/3*R, ax=ax)\n",
    "    # draw_circle('x', 2/3*R, ax=ax)\n",
    "    # draw_circle('x', -2/3*R, ax=ax)\n",
    "\n",
    "    ax.scatter(I[:, 0], I[:, 1], I[:, 2], c=color_I, s=5, label='Image')\n",
    "    ax.scatter(T[:, 0], T[:, 1], T[:, 2], c=color_T, s=5, label='Text')\n",
    "\n",
    "    ax.set_box_aspect([1,1,1])\n",
    "    ax.axis('off')\n",
    "    plt.gca().set_facecolor(\"#FFE5DF00\")\n",
    "    plt.savefig('sphere_with_tropics.png', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "draw_raw(I, T)\n",
    "I = I / np.linalg.norm(I, axis=1, keepdims=True)\n",
    "T = T / np.linalg.norm(T, axis=1, keepdims=True)\n",
    "draw_raw(I, T)\n",
    "muI = I.mean(axis=0)\n",
    "muT = T.mean(axis=0)\n",
    "I -= muI\n",
    "T -= muT\n",
    "draw_raw(I, T)\n",
    "draw_raw(I / np.linalg.norm(I, axis=1, keepdims=True), T / np.linalg.norm(T, axis=1, keepdims=True))\n",
    "\n",
    "draw_raw(I + 0.5*(muI + muT), T + 0.5*(muI + muT))\n",
    "draw_raw((I + 0.5*(muI + muT)) / np.linalg.norm(I + 0.5*(muI + muT), axis=1, keepdims=True), (T + 0.5*(muI + muT)) / np.linalg.norm(T + 0.5*(muI + muT), axis=1, keepdims=True))\n",
    "\n",
    "r = np.random.randn(3)\n",
    "r /= np.linalg.norm(r)\n",
    "draw_raw(I + r, T + r)\n",
    "draw_raw((I + r) / np.linalg.norm(I + r, axis=1, keepdims=True), (T + r) / np.linalg.norm(T + r, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_ = I + muI\n",
    "T_ = T + muT\n",
    "muI1 = I_[:n_points].mean(axis=0) * 1\n",
    "muT1 = T_[:n_points].mean(axis=0) * 1\n",
    "muI2 = I_[n_points:].mean(axis=0) * 1\n",
    "muT2 = T_[n_points:].mean(axis=0) * 1\n",
    "I1 = I_[:n_points] - muI1\n",
    "T1 = T_[:n_points] - muT1\n",
    "I2 = I_[n_points:] - muI2\n",
    "T2 = T_[n_points:] - muT2\n",
    "I_ = np.zeros_like(I_)\n",
    "I_[:n_points] = I1\n",
    "I_[n_points:] = I2\n",
    "T_ = np.zeros_like(T_)\n",
    "T_[:n_points] = T1\n",
    "T_[n_points:] = T2\n",
    "\n",
    "I_ = I_\n",
    "T_ = T_\n",
    "\n",
    "print(I2.shape, T2.shape)\n",
    "\n",
    "draw_raw(I_, T_)\n",
    "draw_raw(I_ / np.linalg.norm(I_, axis=1, keepdims=True), T_ / np.linalg.norm(T_, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from src.utils import get_coco, get_laion, get_imagenet, get_fashionIQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fashionIQ(model_name=\"google/siglip-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_imagenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_laion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, zipfile, random\n",
    "import copy\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "# from nnsight.models.UnifiedTransformer import UnifiedTransformer\n",
    "import clip\n",
    "import nnsight\n",
    "\n",
    "import overcomplete\n",
    "from overcomplete.metrics import r2_score\n",
    "import losses\n",
    "import train\n",
    "\n",
    "import datasets\n",
    "\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from timm.data.dataset import ImageDataset\n",
    "from transformers import CLIPModel, CLIPProcessor, SiglipModel, SiglipProcessor, AutoProcessor, AutoModel\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import PathPatch, FancyArrowPatch, Circle\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.colors import LogNorm, LinearSegmentedColormap\n",
    "import colorsys\n",
    "\n",
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from src.utils.data import get_coco, get_laion, get_imagenet_clip_embeddings\n",
    "import metrics\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "COCO (Common Objects in Context) is a large-scale dataset for object detection, segmentation, and captioning. It contains over 100k images, each with ~ 5 captions\n",
    "\n",
    "LAION 400M is a large-scale dataset of image-text pairs, designed for training and evaluating multimodal models. It contains 400 million image-text pairs, curated using a CLIP-based filtering process. We only use the first 1M of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"laion\"\n",
    "batch_size = 512\n",
    "\n",
    "if DATASET == \"coco\":\n",
    "    train_loader = get_coco(batch_size=batch_size, device=device)\n",
    "elif DATASET == \"laion\":\n",
    "    train_loader = get_laion(batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. SAE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSAE, SSAE_name, _ = __train(beta=0, UseTOPK=False) # Standard SAE\n",
    "ASAE, ASAE_name, _ = __train(beta=4e-4, UseTOPK=False)#, force_retrain=True, save_quand_meme=True) # Aligned SAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Useful Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSAE.metrics = measure_everything(SSAE, train_loader, device, return_sqr=True)\n",
    "ASAE.metrics = measure_everything(ASAE, train_loader, device, return_sqr=True)\n",
    "print(f\"Energy per concept: {ASAE.metrics.E[torch.argsort(ASAE.metrics.E, descending=True)[:10]]}\")\n",
    "print(f\"Frequency per concept: {ASAE.metrics.f[torch.argsort(ASAE.metrics.E, descending=True)[:10]]}\")\n",
    "print(f\"Modality score per concept: {ASAE.metrics.mu[torch.argsort(ASAE.metrics.E, descending=True)[:10]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"SSAE metrics: {SSAE.metrics}\")\n",
    "print(f\"ASAE metrics: {ASAE.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSAE_bridge = {\n",
    "    \"bridge_sigma\" : measure_bridge_sigma(SSAE, train_loader, SSAE.metrics.E, SSAE.metrics.E_Img, SSAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False).cpu().detach(),\n",
    "    # \"bridge_sigma_null_C\" : measure_bridge_sigma(SSAE, train_loader, SSAE.metrics.E, SSAE.metrics.E_Img, SSAE.metrics.E_Txt, device, center=False, normalize=False, null_C=True, null_D=False).cpu().detach(),\n",
    "    # \"bridge_sigma_null_D\" : measure_bridge_sigma(SSAE, train_loader, SSAE.metrics.E, SSAE.metrics.E_Img, SSAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=True).cpu().detach(),\n",
    "    # \"bridge_sigma_null\" : measure_bridge_sigma(SSAE, train_loader, SSAE.metrics.E, SSAE.metrics.E_Img, SSAE.metrics.E_Txt, device, center=False, normalize=False, null_C=True, null_D=True).cpu().detach(),\n",
    "}\n",
    "# _prune_bridge(SSAE_bridge[\"bridge_sigma\"], SSAE_bridge[\"bridge_sigma_null\"])\n",
    "# _prune_bridge(SSAE_bridge[\"bridge_sigma_null_C\"], SSAE_bridge[\"bridge_sigma_null\"])\n",
    "# _prune_bridge(SSAE_bridge[\"bridge_sigma_null_D\"], SSAE_bridge[\"bridge_sigma_null\"])\n",
    "ASAE_bridge = {\n",
    "    \"bridge_sigma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False).cpu().detach(),\n",
    "    # \"bridge_sigma_null_C\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=True, null_D=False).cpu().detach(),\n",
    "    # \"bridge_sigma_null_D\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=True).cpu().detach(),\n",
    "    # \"bridge_sigma_null\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=True, null_D=True).cpu().detach(),\n",
    "}\n",
    "# _prune_bridge(ASAE_bridge[\"bridge_sigma\"], ASAE_bridge[\"bridge_sigma_null\"])\n",
    "# _prune_bridge(ASAE_bridge[\"bridge_sigma_null_C\"], ASAE_bridge[\"bridge_sigma_null\"])\n",
    "# _prune_bridge(ASAE_bridge[\"bridge_sigma_null_D\"], ASAE_bridge[\"bridge_sigma_null\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSAE_bridge_gamma = {\n",
    "    \"bridge_gamma\" : measure_bridge_sigma(SSAE, train_loader, SSAE.metrics.E, SSAE.metrics.E_Img, SSAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "    # \"bridge_gamma_null_C\" : measure_bridge_sigma(SSAE, train_loader, SSAE.metrics.E, SSAE.metrics.E_Img, SSAE.metrics.E_Txt, device, center=False, normalize=False, null_C=True, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "    # \"bridge_gamma_null_D\" : measure_bridge_sigma(SSAE, train_loader, SSAE.metrics.E, SSAE.metrics.E_Img, SSAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=True, weight_type=\"OT\").cpu().detach(),\n",
    "    # \"bridge_gamma_null\" : measure_bridge_sigma(SSAE, train_loader, SSAE.metrics.E, SSAE.metrics.E_Img, SSAE.metrics.E_Txt, device, center=False, normalize=False, null_C=True, null_D=True, weight_type=\"OT\").cpu().detach(),\n",
    "}\n",
    "# _prune_bridge(SSAE_bridge_gamma[\"bridge_gamma\"], SSAE_bridge_gamma[\"bridge_gamma_null\"])\n",
    "# _prune_bridge(SSAE_bridge_gamma[\"bridge_gamma_null_C\"], SSAE_bridge_gamma[\"bridge_gamma_null\"])\n",
    "# _prune_bridge(SSAE_bridge_gamma[\"bridge_gamma_null_D\"], SSAE_bridge_gamma[\"bridge_gamma_null\"])\n",
    "ASAE_bridge_gamma = {\n",
    "    \"bridge_gamma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "    # \"bridge_gamma_null_C\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=True, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "    # \"bridge_gamma_null_D\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=True, weight_type=\"OT\").cpu().detach(),\n",
    "    # \"bridge_gamma_null\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=True, null_D=True, weight_type=\"OT\").cpu().detach(),\n",
    "}\n",
    "# _prune_bridge(ASAE_bridge_gamma[\"bridge_gamma\"], ASAE_bridge_gamma[\"bridge_gamma_null\"])\n",
    "# _prune_bridge(ASAE_bridge_gamma[\"bridge_gamma_null_C\"], ASAE_bridge_gamma[\"bridge_gamma_null\"])\n",
    "# _prune_bridge(ASAE_bridge_gamma[\"bridge_gamma_null_D\"], ASAE_bridge_gamma[\"bridge_gamma_null\"])\n",
    "\n",
    "# fuse SSAE bridge and SSAE bridge_gamma\n",
    "for key in SSAE_bridge_gamma:\n",
    "    SSAE_bridge[key] = SSAE_bridge_gamma[key]\n",
    "for key in ASAE_bridge_gamma:\n",
    "    ASAE_bridge[key] = ASAE_bridge_gamma[key]\n",
    "\n",
    "torch.save(SSAE_bridge, f\"./checkpoints/{SSAE_name.replace('.pt', '_bridge.pt')}\")\n",
    "torch.save(ASAE_bridge, f\"./checkpoints/{ASAE_name.replace('.pt', '_bridge.pt')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bridge_norms(SSAE_bridge[\"bridge_sigma\"], SSAE.metrics.mu, SSAE.metrics.E, SSAE_name, SSAE)\n",
    "get_bridge_norms(ASAE_bridge[\"bridge_sigma\"], ASAE.metrics.mu, ASAE.metrics.E, ASAE_name, ASAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"SSAE metrics: {SSAE.metrics}\")\n",
    "print(f\"ASAE metrics: {ASAE.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_energy_per_concept(SSAE.metrics.E, SSAE.metrics.f, SSAE_name)\n",
    "plot_energy_per_concept(ASAE.metrics.E, ASAE.metrics.f, ASAE_name)\n",
    "plot_energy_cdf(SSAE.metrics.E, SSAE_name)\n",
    "plot_energy_cdf(ASAE.metrics.E, ASAE_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_E_vs_E_B(SSAE.metrics.E, SSAE.metrics.E_B, SSAE_name)\n",
    "plot_E_vs_E_B(ASAE.metrics.E, ASAE.metrics.E_B, ASAE_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. General Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO : store them all in a json file.\n",
    "Do not append the \"beta...\" at the end of the file name, but add it as a key in the json file. Also include other metrics that are not for one specific dict, e.g. transport between SSAE and ASAE, modality gap measures, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO : average all these metrics across many runs of SAE training for better statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics :\n",
    "\n",
    "def get_sparse_reconstruction_metrics(sae, train_loader):\n",
    "    l2, r2 = metrics.l2_r2(sae, train_loader)\n",
    "    print(f\"l2: {l2}, r2: {r2}\")\n",
    "    l0, l1 = metrics.l0_l1(sae, train_loader)\n",
    "    print(f\"l0: {l0}, l1: {l1}\")\n",
    "    dead = metrics.dead_features(sae, train_loader)\n",
    "    print(f\"Dead features ratio: {dead}\")\n",
    "    print(f\"Dead features %: {dead * 100}\")\n",
    "    sae.metrics._add_more({\n",
    "        \"l2\": l2,\n",
    "        \"r2\": r2,\n",
    "        \"l0\": l0,\n",
    "        \"l1\": l1,\n",
    "        \"dead\": dead,\n",
    "    }, save=True)\n",
    "\n",
    "def get_C_metrics(sae, train_loader, top_k):\n",
    "    # TODO : add mu_fidelity\n",
    "    C_insertion, curve = metrics.C_insertion(sae, train_loader, L0=top_k, return_curve=True, metric=\"l2\")\n",
    "    print(C_insertion)\n",
    "    my_own_C_insertion = 0\n",
    "    for i in range(1, len(curve)):\n",
    "        my_own_C_insertion += curve[i]\n",
    "    my_own_C_insertion /= len(curve)\n",
    "    print(my_own_C_insertion)\n",
    "    # plt.plot(curve[:])\n",
    "    # plt.title(\"C_insertion\")\n",
    "    # plt.xlabel(\"Number of concepts\")\n",
    "    # plt.ylabel(\"C_insertion\")\n",
    "    # plt.show()\n",
    "    C_deletion, deletion_curve = metrics.C_deletion(sae, train_loader, L0=top_k, return_curve=True, metric=\"l2\")\n",
    "    print(C_deletion)\n",
    "    my_own_C_deletion = 0\n",
    "    for i in range(1, len(deletion_curve)):\n",
    "        my_own_C_deletion += deletion_curve[i]\n",
    "    my_own_C_deletion /= len(deletion_curve)\n",
    "    print(my_own_C_deletion)\n",
    "    # plt.plot(deletion_curve[:])\n",
    "    # plt.title(\"C_deletion\")\n",
    "    # plt.xlabel(\"Number of concepts\")\n",
    "    # plt.ylabel(\"C_deletion\")\n",
    "    # plt.show()\n",
    "    sae.metrics._add_more({\n",
    "        \"C_insertion\": C_insertion,\n",
    "        \"C_deletion\": C_deletion,\n",
    "    }, save=True)\n",
    "\n",
    "def emd_alignment():\n",
    "    # OT between the two dictionaries\n",
    "    D0 = SSAE.dictionary._fused_dictionary\n",
    "    D05 = ASAE.dictionary._fused_dictionary\n",
    "    \n",
    "    a = SSAE.metrics.E.cpu().numpy() / SSAE.metrics.E.sum().cpu().numpy()\n",
    "    b = ASAE.metrics.E.cpu().numpy() / ASAE.metrics.E.sum().cpu().numpy()\n",
    "\n",
    "    c = metrics.Wasserstein(D0, D05, a, b, metric='cosim')\n",
    "    c_null = metrics.Wasserstein(D0, D05, a, b[np.random.permutation(len(b))], metric='cosim')\n",
    "    print(c)\n",
    "    print(c_null)\n",
    "    SSAE.metrics._add_more({\"Transport cost to Aligned SAE\": c, \"Transport cost null\": c_null}, save=True)\n",
    "    ASAE.metrics._add_more({\"Transport cost to Standard SAE\": c, \"Transport cost null\": c_null}, save=True)\n",
    "\n",
    "def get_stability_beta(train_loader, beta):\n",
    "    # OT between similarly trained dictionaries\n",
    "    T = 10\n",
    "    wasss = []\n",
    "    wasserstein_nulls = []\n",
    "    for i in range(T):\n",
    "        if UseTOPK:\n",
    "            top_k_individual = top_k * 2\n",
    "            sae1 = overcomplete.sae.BatchTopKSAE(d_model, nb_concepts=nb_concepts, top_k=top_k_individual*batch_size, device=device)\n",
    "            sae2 = overcomplete.sae.BatchTopKSAE(d_model, nb_concepts=nb_concepts, top_k=top_k_individual*batch_size, device=device)\n",
    "            criterion_1 = lambda *args, **kwargs: overcomplete.sae.losses.top_k_auxiliary_loss(*args, **kwargs, penalty=0.1)\n",
    "        else:\n",
    "            sae1 = overcomplete.sae.MpSAE(d_model, nb_concepts=nb_concepts, k=top_k, device=device)\n",
    "            sae2 = overcomplete.sae.MpSAE(d_model, nb_concepts=nb_concepts, k=top_k, device=device)\n",
    "            criterion_1 = lambda *args, **kwargs: overcomplete.sae.losses.mse_l1(*args, **kwargs, penalty=0.0)\n",
    "                \n",
    "        criterion_2 = lambda *args, **kwargs: losses.alignment_penalty(*args, **kwargs, penalty=beta, alignment_metric='cosim')\n",
    "        criterion = lambda *args, **kwargs: criterion_1(*args, **kwargs) + criterion_2(*args, **kwargs)\n",
    "\n",
    "        sae1.to(device)\n",
    "        sae2.to(device)\n",
    "        sae1.train()\n",
    "        sae2.train()\n",
    "        optimizer1 = torch.optim.Adam(sae1.parameters(), lr=5e-4)\n",
    "        optimizer2 = torch.optim.Adam(sae2.parameters(), lr=5e-4)\n",
    "\n",
    "        steps_per_epoch = len(train_loader)\n",
    "        scheduler1 = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer1, max_lr=lr, total_steps=epochs * steps_per_epoch,\n",
    "        )\n",
    "        scheduler2 = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer2, max_lr=lr, total_steps=epochs * steps_per_epoch,\n",
    "        )\n",
    "        logs1 = train.train_multimodal_sae(\n",
    "            sae1, train_loader, criterion, optimizer1, scheduler=scheduler1, nb_epochs=epochs, device=device,\n",
    "            monitoring=1, verbose=False,\n",
    "            checkpoint_path=None,\n",
    "        )\n",
    "        logs2 = train.train_multimodal_sae(\n",
    "            sae2, train_loader, criterion, optimizer2, scheduler=scheduler2, nb_epochs=epochs, device=device,\n",
    "            monitoring=1, verbose=False,\n",
    "            checkpoint_path=None,\n",
    "        )\n",
    "        metrics1 = measure_everything(sae1, train_loader, device, return_sqr=True)\n",
    "        metrics2 = measure_everything(sae2, train_loader, device, return_sqr=True)\n",
    "        E1 = metrics1.E\n",
    "        E2 = metrics2.E\n",
    "        a = E1.cpu().numpy() / np.sum(E1.cpu().numpy())\n",
    "        b = E2.cpu().numpy() / np.sum(E2.cpu().numpy())\n",
    "\n",
    "        D1 = sae1.dictionary._fused_dictionary\n",
    "        D2 = sae2.dictionary._fused_dictionary\n",
    "\n",
    "        wasserstein = metrics.Wasserstein(D1, D2, a, b, metric=\"cosim\")\n",
    "        wasserstein_null = metrics.Wasserstein(D1, D2, a, b[np.random.permutation(len(b))], metric=\"cosim\")\n",
    "        print(f\"Wasserstein distance: {wasserstein}\")\n",
    "        print(f\"Wasserstein distance null: {wasserstein_null}\")\n",
    "        wasss.append(wasserstein)\n",
    "        wasserstein_nulls.append(wasserstein_null)\n",
    "    wasss = np.array(wasss)\n",
    "    wasserstein_nulls = np.array(wasserstein_nulls)\n",
    "    return {\n",
    "        \"stability (mean, std)\": (wasss.mean(), wasss.std()),\n",
    "        \"stability null (mean, std)\": (wasserstein_nulls.mean(), wasserstein_nulls.std()),\n",
    "    }\n",
    "\n",
    "def get_D_structure_metrics(sae):\n",
    "    D = sae.dictionary._fused_dictionary\n",
    "    w = sae.metrics.E.unsqueeze(1)\n",
    "    \n",
    "    sae.metrics._add_more({\n",
    "        \"stable_rank\": metrics.stable_rank(D),\n",
    "        \"stable_rank_weighted\": metrics.stable_rank(D, w=w),\n",
    "        \"effective_rank\": metrics.effective_rank(D),\n",
    "        \"effective_rank_weighted\": metrics.effective_rank(D, w=w),\n",
    "        \"coherence\": metrics.coherence(D),\n",
    "    }, save=True)\n",
    "\n",
    "def get_Z_structure_metrics(sae, train_loader):\n",
    "    D = sae.dictionary._fused_dictionary\n",
    "    sae.metrics._add_more({\n",
    "        \"connectivity\": metrics.connectivity(sae, data_loader=train_loader),\n",
    "        \"negative_interference\": metrics.negative_interference(sae, data_loader=train_loader, D=D),\n",
    "    }, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparse_reconstruction_metrics(SSAE, train_loader)\n",
    "get_sparse_reconstruction_metrics(ASAE, train_loader)\n",
    "get_C_metrics(SSAE, train_loader)\n",
    "get_C_metrics(ASAE, train_loader)\n",
    "\n",
    "emd_alignment()\n",
    "# SSAE.metrics._add_more(get_stability_beta(train_loader, beta=0e-4), save=True)\n",
    "# ASAE.metrics._add_more(get_stability_beta(train_loader, beta=5e-4), save=True)\n",
    "\n",
    "get_D_structure_metrics(SSAE)\n",
    "get_D_structure_metrics(ASAE)\n",
    "\n",
    "get_Z_structure_metrics(SSAE, train_loader)\n",
    "get_Z_structure_metrics(ASAE, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Global C-insertion :\n",
    "\n",
    "# # compute the R^2 score for images, text, and both images and text.\n",
    "# # Do it by keeping only the topk most activated concepts.\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def compute_r2_score(sae, energy, data_loader, device, idxs):\n",
    "#     sae.eval()\n",
    "\n",
    "#     sae_dict = {}\n",
    "#     img_score = {}\n",
    "#     txt_score = {}\n",
    "#     total_score = {}\n",
    "\n",
    "#     for idx in idxs:\n",
    "#         sae_truncated = copy.deepcopy(sae)\n",
    "#         D = torch.zeros_like(sae.dictionary._fused_dictionary)\n",
    "#         D[idx] = sae.dictionary._fused_dictionary[idx]\n",
    "#         sae_truncated.dictionary._fused_dictionary = D\n",
    "#         sae_dict[idx] = sae_truncated\n",
    "\n",
    "#         img_score[idx] = 0\n",
    "#         txt_score[idx] = 0\n",
    "#         total_score[idx] = 0\n",
    "\n",
    "#     n_images = 0\n",
    "#     n_texts = 0\n",
    "#     n_inputs = 0\n",
    "\n",
    "#     for image_features, text_features in tqdm(data_loader):\n",
    "#         n_images += 1 # image_features.shape[0]\n",
    "#         n_texts += 1 # text_features.shape[0]\n",
    "\n",
    "#         image_features = image_features.to(device)\n",
    "#         text_features = text_features.to(device)\n",
    "\n",
    "#         for idx in idxs:\n",
    "#             # Forward pass through the model\n",
    "#             sae_truncated = sae_dict[idx]\n",
    "#             _, _, x_hat_image_truncated = sae_truncated(image_features)\n",
    "#             _, _, x_hat_text_truncated = sae_truncated(text_features)\n",
    "            \n",
    "#             # Compute the R^2 score for images and text\n",
    "#             img_score[idx] += r2_score(image_features, x_hat_image_truncated).item()\n",
    "#             txt_score[idx] += r2_score(text_features, x_hat_text_truncated).item()\n",
    "\n",
    "#     n_inputs = n_images + n_texts\n",
    "#     for idx in idxs:\n",
    "#         total_score[idx] = (img_score[idx] + txt_score[idx]) / (n_inputs)\n",
    "#         img_score[idx] /= n_images\n",
    "#         txt_score[idx] /= n_texts\n",
    "\n",
    "#     return img_score, txt_score, total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global C-insertion :\n",
    "\n",
    "# compute the R^2 score for images, text, and both images and text.\n",
    "# Do it by keeping only the topk most activated concepts.\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_r2_score(sae, data_loader, device, idxs):\n",
    "    sae.eval()\n",
    "\n",
    "    img_score = {idx: 0 for idx in idxs}\n",
    "    txt_score = {idx: 0 for idx in idxs}\n",
    "    total_score = {idx: 0 for idx in idxs}\n",
    "\n",
    "    n_images = 0\n",
    "    n_texts = 0\n",
    "\n",
    "    for image_features, text_features in tqdm(data_loader):\n",
    "        n_images += 1 # image_features.shape[0]\n",
    "        n_texts += 1 # text_features.shape[0]\n",
    "\n",
    "        image_features = image_features.to(device)\n",
    "        text_features = text_features.to(device)\n",
    "\n",
    "        _, image_codes = sae.encode(image_features)\n",
    "        _, text_codes = sae.encode(text_features)\n",
    "\n",
    "        for idx in idxs:\n",
    "            truncated_image_codes = image_codes.clone()\n",
    "            truncated_image_codes[:, ~idx] = 0\n",
    "            x_hat_image_truncated = sae.decode(truncated_image_codes)\n",
    "\n",
    "            truncated_text_codes = text_codes.clone()\n",
    "            truncated_text_codes[:, ~idx] = 0\n",
    "            x_hat_text_truncated = sae.decode(truncated_text_codes)\n",
    "            \n",
    "            # Compute the R^2 score for images and text\n",
    "            img_score[idx] += r2_score(image_features, x_hat_image_truncated).item()\n",
    "            txt_score[idx] += r2_score(text_features, x_hat_text_truncated).item()\n",
    "\n",
    "    n_inputs = n_images + n_texts\n",
    "    for idx in idxs:\n",
    "        total_score[idx] = (img_score[idx] + txt_score[idx]) / (n_inputs)\n",
    "        img_score[idx] /= n_images\n",
    "        txt_score[idx] /= n_texts\n",
    "\n",
    "    return img_score, txt_score, total_score\n",
    "\n",
    "def plot_r2_vs_energy(sae, sae_name, E):\n",
    "    # This is the global version of C-insertion.\n",
    "    idxs = []\n",
    "\n",
    "    energy_perm = torch.argsort(E, descending=True)\n",
    "    energy_perm_inv = torch.argsort(energy_perm)\n",
    "\n",
    "    thresholds = torch.linspace(E.min() + 1e-10, 1, steps=100)\n",
    "    # thresholds = torch.logspace(-6, 0, steps=60)\n",
    "\n",
    "    # plot energy vs index, cumulative sum vs index :\n",
    "    sorted_energy = E[energy_perm]\n",
    "    sorted_energy = sorted_energy / sorted_energy.sum()\n",
    "    cumsum_energy = 1 - sorted_energy.cumsum(dim=0)\n",
    "\n",
    "    # find thresholds index in cumsum_energy\n",
    "    thresholds_idx = []\n",
    "    for threshold in thresholds:\n",
    "        idx = (cumsum_energy < threshold).nonzero(as_tuple=True)[0][0]\n",
    "        thresholds_idx.append(idx.item())\n",
    "    thresholds_idx = torch.tensor(thresholds_idx)\n",
    "\n",
    "    img_score, txt_score, total_score = compute_r2_score(sae, train_loader, device, idxs)\n",
    "    id_line = torch.linspace(0, 1, steps=100)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(id_line.cpu().numpy(), id_line.cpu().numpy(), '--', color='black', label='y=x')\n",
    "    plt.plot(1 - thresholds.cpu().numpy(), torch.tensor([r2 for r2 in total_score.values()]).cpu().numpy(), label='R^2 Score', color='blue')\n",
    "    plt.xlabel('Energy mass')\n",
    "    plt.ylabel('R^2 Score')\n",
    "    plt.title('R^2 Score vs Energy mass (E) - most energetic concepts containing E of energy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/energy/r2_score.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/energy/r2_score.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(torch.arange(E.shape[0]) + 1, 1-cumsum_energy.cpu().numpy(), label='Cumulative Energy', color='blue')\n",
    "    plt.plot(torch.tensor(thresholds_idx) + 1, torch.tensor([r2 for r2 in total_score.values()]).cpu().numpy(), label='R^2 Score', color='red')\n",
    "    plt.xlabel('index')\n",
    "    plt.ylabel('Mass & R^2 Score')\n",
    "    plt.title('R^2 & Energy mass contained in most energetic concepts')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/energy/r2_energy_vs_index.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/energy/r2_energy_vs_index.pdf\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_r2_vs_energy(SSAE, SSAE_name, SSAE.metrics.E)\n",
    "# plot_r2_vs_energy(ASAE, ASAE_name, ASAE.metrics.E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modality specific Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Modality Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_modality_energy(SSAE, SSAE_name)\n",
    "# plot_modality_energy(SSAE, SSAE_name, mu_B=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_modality_energy(ASAE, ASAE_name)\n",
    "# plot_modality_energy(ASAE, ASAE_name, mu_B=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_vs_mu_B(SSAE, SSAE_name)\n",
    "mu_vs_mu_B(ASAE, ASAE_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modality vs R^2\n",
    "# compute the R^2 score for images, text, and both images and text.\n",
    "# Do it by keeping only the bimodal concepts ((modality-0.5).abs() < 0.5 - eps)\n",
    "\n",
    "def R2_vs_modality_score(sae, sae_name, E, mu):\n",
    "    # C-insertion like\n",
    "    idxs = []\n",
    "    epss = torch.linspace(0, 0.5, 20)\n",
    "\n",
    "    for i, eps in enumerate(epss):\n",
    "        bimodal_mask = (mu - 0.5).abs() < eps\n",
    "        bimodal_mask = bimodal_mask.cpu()\n",
    "        idxs.append(bimodal_mask)\n",
    "\n",
    "    img_score, txt_score, total_score = compute_r2_score(sae, train_loader, device, idxs)\n",
    "    # print(f\"Image R^2 score: {img_score}\")\n",
    "    # print(f\"Text R^2 score: {txt_score}\")\n",
    "    # print(f\"R^2 score: {total_score}\")\n",
    "\n",
    "    # compute AUC or that :\n",
    "    MAUC_insertion = 0\n",
    "    for i in range(len(epss)):\n",
    "        MAUC_insertion += (total_score[idxs[i]])\n",
    "    MAUC_insertion /= len(epss)\n",
    "    print(f\"mu_insertion: {MAUC_insertion}\")\n",
    "    sae.metrics._add_more({\n",
    "        \"mu_insertion\": MAUC_insertion,\n",
    "    }, save=True)\n",
    "\n",
    "    # plot r2 w.r.t. epsilon\n",
    "    id_line = torch.linspace(0, 1, steps=100)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # plt.plot(id_line.cpu().numpy(), id_line.cpu().numpy(), '--', color='black', label='y=x')\n",
    "    plt.plot(epss.cpu().numpy(), torch.tensor([r2 for r2 in total_score.values()]).cpu().numpy(), label='R^2 Score', color='blue')\n",
    "    plt.xlabel('Epsilon')\n",
    "    plt.ylabel('R^2 Score')\n",
    "    plt.title('R^2 Score vs Bimodal Threshold')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/modality/r2_modality_insertion.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/modality/r2_modality_insertion.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # C-deletion like\n",
    "    idxs = []\n",
    "    epss = torch.linspace(0, 0.5, 20)\n",
    "\n",
    "    for i, eps in enumerate(epss):\n",
    "        bimodal_mask = (mu - 0.5).abs() >= eps\n",
    "        bimodal_mask = bimodal_mask.cpu()\n",
    "        idxs.append(bimodal_mask)\n",
    "\n",
    "    img_score, txt_score, total_score = compute_r2_score(sae, train_loader, device, idxs)\n",
    "    # print(f\"Image R^2 score: {img_score}\")\n",
    "    # print(f\"Text R^2 score: {txt_score}\")\n",
    "    # print(f\"R^2 score: {total_score}\")\n",
    "\n",
    "    # compute AUC or that :\n",
    "    MAUC_deletion = 0\n",
    "    for i in range(len(epss)):\n",
    "        MAUC_deletion += (total_score[idxs[i]])\n",
    "    MAUC_deletion /= len(epss)\n",
    "    print(f\"mu_deletion: {MAUC_deletion}\")\n",
    "    sae.metrics._add_more({\n",
    "        \"mu_deletion\": MAUC_deletion,\n",
    "    }, save=True)\n",
    "\n",
    "    # plot r2 w.r.t. epsilon\n",
    "    id_line = torch.linspace(0, 1, steps=100)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # plt.plot(id_line.cpu().numpy(), id_line.cpu().numpy(), '--', color='black', label='y=x')\n",
    "    plt.plot(epss.cpu().numpy(), torch.tensor([r2 for r2 in total_score.values()]).cpu().numpy(), label='R^2 Score', color='blue')\n",
    "    plt.xlabel('Epsilon')\n",
    "    plt.ylabel('R^2 Score')\n",
    "    plt.title('R^2 Score vs Bimodal Threshold')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/modality/r2_modality_deletion.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/modality/r2_modality_deletion.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2_vs_modality_score(SSAE, SSAE_name, SSAE.metrics.E, SSAE.metrics.mu)\n",
    "# R2_vs_modality_score(ASAE, ASAE_name, ASAE.metrics.E, ASAE.metrics.mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bridges(SSAE_bridge, SSAE, SSAE_name, SSAE.metrics.mu)\n",
    "plot_bridges(ASAE_bridge, ASAE, ASAE_name, ASAE.metrics.mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rho(SSAE, SSAE.metrics.bridge_mass_vs_eps_gamma, normalize=True)\n",
    "get_rho(ASAE, ASAE.metrics.bridge_mass_vs_eps_gamma, normalize=True)\n",
    "\n",
    "get_rho(SSAE, SSAE.metrics.bridge_mass_vs_eps_sigma, normalize=False)\n",
    "get_rho(ASAE, ASAE.metrics.bridge_mass_vs_eps_sigma, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null models\n",
    "- Randomly shuffle C the correlation matrix\n",
    "    - during computation, shuffle z_image and z_text\n",
    "    - Are the observed co-activation patterns stronger than chance, given the same geometry?\n",
    "- Randomly shuffle D the features\n",
    "    - v1 : sample D' uniformly on the unit sphere - completely random and isotropic, losing all information about the geometry\n",
    "    - v2 : permute D - preserves the geometry but loses semantic information since not aligned with C anymore.\n",
    "    - Are observed geometric alignments meaningful, given activation behavior?\n",
    "- Randomly shuffle the features and the correlation matrix\n",
    "    - The complete absence of any structure — the fully unstructured baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geometric Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Cosim Histograms & Data Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_cosim_histogram(I, T, D, sae_name, subtitle=\"\"):\n",
    "    # Baseline (random isotropic Gaussian)\n",
    "    Rd = torch.randn_like(D)\n",
    "    Rd /= Rd.norm(dim=-1, keepdim=True)\n",
    "    J = Rd[torch.randperm(Rd.shape[0], device='cpu')]\n",
    "    Rd_baseline = torch.cosine_similarity(Rd, J, dim=1).cpu().numpy()\n",
    "\n",
    "    # means\n",
    "    mu_I = I.mean(dim=0)\n",
    "    mu_T = T.mean(dim=0)\n",
    "    mu_D = D.mean(dim=0)\n",
    "\n",
    "    def _aux_cosim(A, B, mu_A=0, mu_B=0):\n",
    "        A_rd = A[torch.randperm(A.shape[0], device='cpu')]\n",
    "        B_rd = B[torch.randperm(B.shape[0], device='cpu')]\n",
    "        AA = torch.cosine_similarity(A - mu_A, A_rd - mu_A, dim=1).cpu().numpy()\n",
    "        BB = torch.cosine_similarity(B - mu_B, B_rd - mu_B, dim=1).cpu().numpy()\n",
    "        AB_aligned = torch.cosine_similarity(A - mu_A, B - mu_B, dim=1).cpu().numpy()\n",
    "        AB_rd = torch.cosine_similarity(A - mu_A, B_rd - mu_B, dim=1).cpu().numpy()\n",
    "        return AA, BB, AB_aligned, AB_rd\n",
    "\n",
    "    II, TT, IT_aligned, IT_rd = _aux_cosim(I, T)\n",
    "    II_D, TT_D, IT_aligned_D, IT_rd_D = _aux_cosim(I, T, mu_A=mu_D, mu_B=mu_D)\n",
    "    II_m, TT_m, IT_aligned_m, IT_rd_m = _aux_cosim(I, T, mu_A=mu_I, mu_B=mu_T)\n",
    "\n",
    "    def plot_histograms(data_dict, title):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        all_data = np.concatenate(list(data_dict.values()))\n",
    "        bins = np.linspace(all_data.min(), all_data.max(), 1000)  # 50 bins\n",
    "        for label, data in data_dict.items():\n",
    "            plt.hist(data, bins=bins, alpha=0.6, label=label, density=True)\n",
    "        # plt.axvline(threshold, color='red', linestyle='--', linewidth=1, label='Threshold')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Cosine Similarity')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(f\"./figures/{sae_name.replace('.pt', '')}/geometry\", exist_ok=True)\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/{title.replace(' ', '_').lower()}_{subtitle.replace(' ', '_').lower()}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/{title.replace(' ', '_').lower()}_{subtitle.replace(' ', '_').lower()}.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "    plot_histograms({\n",
    "        \"Random (N(0,I))\": Rd_baseline,\n",
    "        \"I-I\": II,\n",
    "        \"I-T\": IT_rd,\n",
    "        \"T-T\": TT,\n",
    "        \"I-T (aligned)\": IT_aligned,\n",
    "    }, \"Uncentered Cosine Similarity Distributions\")\n",
    "\n",
    "    plot_histograms({\n",
    "        \"Random (N(0,I))\": Rd_baseline,\n",
    "        \"I-I\": II_D,\n",
    "        \"I-T\": IT_rd_D,\n",
    "        \"T-T\": TT_D,\n",
    "        \"I-T (aligned)\": IT_aligned_D,\n",
    "    }, \"Centered Cosine Similarity Distributions\")\n",
    "\n",
    "    plot_histograms({\n",
    "        \"Random (N(0,I))\": Rd_baseline,\n",
    "        \"I-I\": II_m,\n",
    "        \"I-T\": IT_rd_m,\n",
    "        \"T-T\": TT_m,\n",
    "        \"I-T (aligned)\": IT_aligned_m,\n",
    "    }, \"Modality-Centered Cosine Similarity Distributions\")\n",
    "\n",
    "    # Label ZOULOU_69 : threshold for\n",
    "    # COCO : 0.238\n",
    "    # CC3M : /\n",
    "    # LAION 400M : None - already thresholded at 0.3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = train_loader.dataset.tensors[0]\n",
    "T = train_loader.dataset.tensors[1]\n",
    "D_ict = torch.cat([I, T], dim=0)\n",
    "I_mu = I.mean(dim=0)\n",
    "T_mu = T.mean(dim=0)\n",
    "D_mu = D_ict.mean(dim=0)\n",
    "# plot_cosim_histogram(I, T, D_ict, SSAE_name)\n",
    "# plot_cosim_histogram(I, T, D_ict, ASAE_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(D, d1, d2, I_mu, T_mu, D_mu, title, save_title, sae_name):\n",
    "    modality_color = {\n",
    "        \"bimodal\": np.array([91/255, 40/255, 68/255]),\n",
    "        \"image\": np.array([128/255, 230/255, 255/255]),\n",
    "        \"text\": np.array([255/255, 205/255, 102/255]),\n",
    "    }\n",
    "    def make_alpha_cmap(base_color, name):\n",
    "        r, g, b = base_color\n",
    "        return LinearSegmentedColormap.from_list(\n",
    "            name,\n",
    "            [(r, g, b, 0.0), (r, g, b, 1.0)]\n",
    "        )\n",
    "\n",
    "    I_cmap = make_alpha_cmap(modality_color[\"image\"], \"I\")\n",
    "    T_cmap = make_alpha_cmap(modality_color[\"text\"], \"T\")\n",
    "    # Plot the projections, colored by modality (D[:N//2] = I, D[N//2:] = T)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.hexbin(D[:D.shape[0]//2].cpu().numpy() @ d1.reshape(-1, 1), D[:D.shape[0]//2].cpu().numpy() @ d2.reshape(-1, 1), gridsize=50, cmap=I_cmap, bins='log')\n",
    "    plt.colorbar(label='Image Counts')\n",
    "    plt.hexbin(D[D.shape[0]//2:].cpu().numpy() @ d1.reshape(-1, 1), D[D.shape[0]//2:].cpu().numpy() @ d2.reshape(-1, 1), gridsize=50, cmap=T_cmap, bins='log')\n",
    "    plt.colorbar(label='Text Counts')\n",
    "    plt.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "    plt.axvline(0, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Plot all the means of the modalities\n",
    "    plt.scatter(D_mu.cpu().numpy() @ d1.reshape(-1, 1), D_mu.cpu().numpy() @ d2.reshape(-1, 1), color='k', marker='x', s=100, label='mu_D, mu_I, mu_T')\n",
    "    plt.scatter(I_mu.cpu().numpy() @ d1.reshape(-1, 1), I_mu.cpu().numpy() @ d2.reshape(-1, 1), color='k', marker='x', s=100)\n",
    "    plt.scatter(T_mu.cpu().numpy() @ d1.reshape(-1, 1), T_mu.cpu().numpy() @ d2.reshape(-1, 1), color='k', marker='x', s=100)\n",
    "\n",
    "    plt.xlabel('d1')\n",
    "    plt.ylabel('d2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(f\"./figures/{sae_name.replace('.pt', '')}/geometry\", exist_ok=True)\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/{save_title}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/{save_title}.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def fit_and_plot_pca(I, T, D, sae_name, save_title='data_pca_pc1_pc2'):\n",
    "    # Fit PCA on D\n",
    "    D_np = D.cpu().numpy()\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(D_np)\n",
    "    mean = pca.mean_\n",
    "    d1 = pca.components_[0]\n",
    "    d2 = pca.components_[1]\n",
    "    D_pca = pca.transform(D_np)\n",
    "\n",
    "    I_mu = I.mean(dim=0)\n",
    "    T_mu = T.mean(dim=0)\n",
    "    D_mu = D.mean(dim=0)\n",
    "\n",
    "    plot_pca(D-mean, d1, d2, I_mu-mean, T_mu-mean, D_mu-mean, title='Projection of D on d1 = PC1 and d2 = PC2', save_title=save_title, sae_name=sae_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \"PCA\"s of D, but not on the top 2 PCs, instead on (1) D_mu, (2) I_mu - T_mu\n",
    "\n",
    "d1 = D_mu.cpu().numpy()\n",
    "d1 = d1 / np.linalg.norm(d1)\n",
    "d2 = I_mu.cpu().numpy() - T_mu.cpu().numpy()\n",
    "d2 = d2 / np.linalg.norm(d2)\n",
    "\n",
    "plot_pca(D_ict, d1, d2, I_mu, T_mu, D_mu, title='Projection of D on d1 = D_mu and d2 = I_mu - T_mu', save_title='data_pca_d1_d2', sae_name=SSAE_name)\n",
    "plot_pca(D_ict, d1, d2, I_mu, T_mu, D_mu, title='Projection of D on d1 = D_mu and d2 = I_mu - T_mu', save_title='data_pca_d1_d2', sae_name=ASAE_name)\n",
    "\n",
    "fit_and_plot_pca(I, T, D_ict, SSAE_name)\n",
    "fit_and_plot_pca(I, T, D_ict, ASAE_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unimodal concepts, then plot PCA similar to above : D_bimodal, I_bimodal, T_bimodal\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_bimodal_data(sae, train_loader, modality_score, device, complement=False, use_E_B=False, eps=0.05, tau=0.5):\n",
    "    I_bimodal = torch.zeros_like(train_loader.dataset.tensors[0])\n",
    "    T_bimodal = torch.zeros_like(train_loader.dataset.tensors[1])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sae.eval()\n",
    "\n",
    "        n_images = 0\n",
    "        n_texts = 0\n",
    "        \n",
    "        if not use_E_B:\n",
    "            mask = (modality_score >= eps) & (modality_score <= 1 - eps)\n",
    "        else:\n",
    "            E_B = sae.metrics.E_B\n",
    "            E = sae.metrics.E\n",
    "            ratio = E_B / (E + 1e-8)\n",
    "            mask = (ratio >= tau)\n",
    "        if complement:\n",
    "            mask = ~mask\n",
    "        idx = mask.cpu()\n",
    "\n",
    "        for image_features, text_features in tqdm(train_loader):\n",
    "            n_i = image_features.shape[0]\n",
    "            n_t = text_features.shape[0]\n",
    "\n",
    "            image_features = image_features.to(device)\n",
    "            _, image_codes = sae.encode(image_features)\n",
    "            truncated_image_codes = image_codes.clone()\n",
    "            truncated_image_codes[:, ~idx] = 0\n",
    "            x_hat_image_truncated = sae.decode(truncated_image_codes)\n",
    "\n",
    "            I_bimodal[n_images:n_images+n_i] = x_hat_image_truncated\n",
    "            \n",
    "            if text_features.dtype == image_features.dtype:\n",
    "                text_features = text_features.to(device)\n",
    "                _, text_codes = sae.encode(text_features)\n",
    "                truncated_text_codes = text_codes.clone()\n",
    "                truncated_text_codes[:, ~idx] = 0\n",
    "                x_hat_text_truncated = sae.decode(truncated_text_codes)\n",
    "                \n",
    "                T_bimodal[n_images:n_images+n_i] = x_hat_text_truncated\n",
    "\n",
    "            n_images += n_i\n",
    "            n_texts += n_t\n",
    "\n",
    "        n_inputs = n_images + n_texts\n",
    "    if text_features.dtype == image_features.dtype:\n",
    "        D_bimodal = torch.cat([I_bimodal, T_bimodal], dim=0)\n",
    "    else:\n",
    "        D_bimodal = None\n",
    "    return I_bimodal, T_bimodal, D_bimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_bi_S, T_bi_S, B_bi_S = get_bimodal_data(SSAE, train_loader, SSAE.metrics.mu, device)\n",
    "# plot_cosim_histogram(I_bi_S, T_bi_S, B_bi_S, SSAE_name, subtitle=\"Unimodal concepts removed\")\n",
    "I_bi_A, T_bi_A, B_bi_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device)\n",
    "# plot_cosim_histogram(I_bi_A, T_bi_A, B_bi_A, ASAE_name, subtitle=\"Unimodal concepts removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_plot_pca(I_bi_S, T_bi_S, B_bi_S, SSAE_name, save_title='data_proj_pca_pc1_pc2')\n",
    "fit_and_plot_pca(I_bi_A, T_bi_A, B_bi_A, ASAE_name, save_title='data_proj_pca_pc1_pc2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Dictionary Orthogonality - $E = D^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cosim between E^T_i and D_i (weighted and unweighted by energy)\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def compute_cosim(E, D, energy=None):\n",
    "#     dot_product = torch.einsum('ij,ji->i', E, D)  # Shape: (nb_concepts, d_model) * (d_model, nb_concepts) -> (nb_concepts,)\n",
    "#     norm_E = torch.norm(E, p=2, dim=1)  # Shape: (nb_concepts,)\n",
    "#     norm_D = torch.norm(D, p=2, dim=0)  # Shape: (nb_concepts,)\n",
    "#     cosim = dot_product / (norm_E * norm_D + 1e-6)  # Shape: (nb_concepts,)\n",
    "\n",
    "#     # print mean and std of dot product and cosim :\n",
    "#     dot_mean = dot_product.mean()\n",
    "#     dot_std = dot_product.std()\n",
    "#     print(f\"Unweighted dot product mean: {dot_product.mean()}, std: {dot_product.std()}\")\n",
    "#     print(f\"Unweighted cosim mean: {cosim.mean()}, std: {cosim.std()}\")\n",
    "#     weighted_dot_product = dot_product * energy\n",
    "#     weighted_dot_product_mean = weighted_dot_product.sum() / energy.sum()\n",
    "#     weighted_dot_product_std = torch.sqrt(((dot_product - weighted_dot_product_mean)**2 * energy).sum() / energy.sum())\n",
    "#     print(f\"\\n\\nWeighted dot product mean: {weighted_dot_product_mean}, {weighted_dot_product_std}\")\n",
    "#     weighted_cosim = cosim * energy\n",
    "#     weighted_cosim_mean = weighted_cosim.sum() / energy.sum()\n",
    "#     weighted_cosim_std = torch.sqrt(((cosim - weighted_cosim_mean)**2 * energy).sum() / energy.sum())\n",
    "#     print(f\"Weighted cosim mean: {weighted_cosim_mean}, {weighted_cosim_std}\")\n",
    "\n",
    "#     # plot histograms of dot product and cosim\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.hist(dot_product.cpu().numpy(), bins=100, range=(-1, 1), color='blue', alpha=0.7, label='Dot Product')\n",
    "#     plt.title(\"Distribution of Dot Product\")\n",
    "#     plt.xlabel(\"Dot Product\")\n",
    "#     plt.ylabel(\"count\")\n",
    "#     plt.yscale(\"log\")\n",
    "#     plt.grid(axis='y', alpha=0.75)\n",
    "#     plt.legend()\n",
    "#     # Add mean and std information to the plot\n",
    "#     plt.text(0.05, 0.95, f\"Mean: {dot_mean:.4f}\\nStd: {dot_std:.4f}\", transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5))\n",
    "#     plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/dot_product.png\", dpi=300, bbox_inches='tight')\n",
    "#     plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/dot_product.pdf\")\n",
    "#     plt.show()\n",
    "\n",
    "#     # weighted dot product\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.hist(dot_product.cpu().numpy(), bins=100, range=(-1, 1), color='blue', alpha=0.7, label='Weighted Dot Product', weights=energy.cpu().numpy())\n",
    "#     plt.title(\"Distribution of Weighted Dot Product\")\n",
    "#     plt.xlabel(\"Weighted Dot Product\")\n",
    "#     plt.ylabel(\"density\")\n",
    "#     plt.yscale(\"log\")\n",
    "#     plt.grid(axis='y', alpha=0.75)\n",
    "#     plt.legend()\n",
    "#     # Add mean and std information to the plot\n",
    "#     plt.text(0.05, 0.95, f\"Mean: {weighted_dot_product_mean:.4f}\\nStd: {weighted_dot_product_std:.4f}\", transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5))\n",
    "#     plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/dot_product_weighted.png\", dpi=300, bbox_inches='tight')\n",
    "#     plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/dot_product_weighted.pdf\")\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.hist(cosim.cpu().numpy(), bins=100, range=(-1, 1), color='blue', alpha=0.7, label='Cosine Similarity')\n",
    "#     plt.title(\"Distribution of Cosine Similarity\")\n",
    "#     plt.xlabel(\"Cosine Similarity\")\n",
    "#     plt.ylabel(\"count\")\n",
    "#     plt.yscale(\"log\")\n",
    "#     plt.grid(axis='y', alpha=0.75)\n",
    "#     plt.legend()\n",
    "#     # Add mean and std information to the plot\n",
    "#     plt.text(0.05, 0.95, f\"Mean: {cosim.mean():.4f}\\nStd: {cosim.std():.4f}\", transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5))\n",
    "#     plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/cosim.png\", dpi=300, bbox_inches='tight')\n",
    "#     plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/cosim.pdf\")\n",
    "#     plt.show()\n",
    "\n",
    "#     # weighted cosim\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.hist(cosim.cpu().numpy(), bins=100, range=(-1, 1), color='blue', alpha=0.7, label='Weighted Cosine Similarity', weights=energy.cpu().numpy())\n",
    "#     plt.title(\"Distribution of Weighted Cosine Similarity\")\n",
    "#     plt.xlabel(\"Weighted Cosine Similarity\")\n",
    "#     plt.ylabel(\"density\")\n",
    "#     plt.yscale(\"log\")\n",
    "#     plt.grid(axis='y', alpha=0.75)\n",
    "#     plt.legend()\n",
    "#     # Add mean and std information to the plot\n",
    "#     plt.text(0.05, 0.95, f\"Mean: {weighted_cosim_mean:.4f}\\nStd: {weighted_cosim_std:.4f}\", transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5))\n",
    "#     plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/cosim_weighted.png\", dpi=300, bbox_inches='tight')\n",
    "#     plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/cosim_weighted.pdf\")\n",
    "#     plt.show()\n",
    "\n",
    "# E = sae.encoder.final_block[0].weight\n",
    "# D = sae.dictionary._fused_dictionary.T\n",
    "# print(E.shape, D.shape)\n",
    "\n",
    "# compute_cosim(E, D, energy_per_concept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Dictionary Atoms Linear Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dictionary atoms :\n",
    "\n",
    "def generate_visualization(sae, sae_name, modality_score, energy_per_concept, frequency_per_concept, bridge):\n",
    "    # Create a UMAP of the concepts in D, colored by modality score and size by energy\n",
    "\n",
    "    non_dead_idx = (modality_score != -1).nonzero(as_tuple=True)[0].cpu().numpy()\n",
    "\n",
    "    D = sae.dictionary._fused_dictionary\n",
    "    D_np = D.detach().cpu().numpy()[non_dead_idx]\n",
    "    modality_np = modality_score.detach().cpu().numpy()[non_dead_idx]\n",
    "    energy_np = energy_per_concept.detach().cpu().numpy()[non_dead_idx]\n",
    "    frequency_np = frequency_per_concept.detach().cpu().numpy()[non_dead_idx]\n",
    "    bridge_matrix = bridge.numpy()[non_dead_idx][:, non_dead_idx] ** 2\n",
    "\n",
    "    non_stupid_mask = (frequency_np < 0.6)\n",
    "    D_np = D_np[non_stupid_mask]\n",
    "    modality_np = modality_np[non_stupid_mask]\n",
    "    energy_np = energy_np[non_stupid_mask]\n",
    "    bridge_matrix = bridge_matrix[non_stupid_mask][:, non_stupid_mask]\n",
    "\n",
    "    threshold = 2e-10\n",
    "    i_idx, j_idx = np.nonzero(bridge_matrix > threshold)\n",
    "    line_weights = bridge_matrix[i_idx, j_idx]\n",
    "\n",
    "    # UMAP embedding\n",
    "    embedding = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='cosine').fit_transform(D_np)\n",
    "\n",
    "    # Line segments from i to j in the UMAP space\n",
    "    lines = [ [embedding[i], embedding[j]] for i, j in zip(i_idx, j_idx) ]\n",
    "\n",
    "    print(f\"Number of lines: {len(lines)}\")\n",
    "\n",
    "    # PCA embedding\n",
    "    pca = PCA(n_components=2)\n",
    "    embedding_pca = pca.fit_transform(D_np)\n",
    "\n",
    "    # Line segments from i to j in the PCA space\n",
    "    lines_pca = [ [embedding_pca[i], embedding_pca[j]] for i, j in zip(i_idx, j_idx) ]\n",
    "\n",
    "    # Make a weighted PCA :\n",
    "    W = energy_np / energy_np.sum()\n",
    "    mu = np.average(D_np, axis=0, weights=W)\n",
    "    D_centered = D_np - mu\n",
    "    C = D_centered.T @ (D_centered * W[:, None])\n",
    "    eigvals, eigvecs = np.linalg.eigh(C)\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "    embedding_weighted_pca = D_centered @ eigvecs[:, :2]\n",
    "\n",
    "    # Line segments from i to j in the PCA space\n",
    "    lines_weighted_pca = [ [embedding_weighted_pca[i], embedding_weighted_pca[j]] for i, j in zip(i_idx, j_idx) ]\n",
    "\n",
    "\n",
    "    # Normalize energy for plotting size\n",
    "    LOG = False\n",
    "    if LOG:\n",
    "        # Log scale energy normalization\n",
    "        log_energy = np.log(energy_np)  # Log transform with offset to avoid log(0)\n",
    "        size = log_energy - log_energy.min()\n",
    "        size = 0.1 * (size) ** 2\n",
    "    else:\n",
    "        # Linear scale energy normalization\n",
    "        size = energy_np - energy_np.min()\n",
    "        size = 500 * np.sqrt((size / size[size<0.1].max()))\n",
    "\n",
    "\n",
    "    # Normalize weights for line width\n",
    "    # weights_norm = 10 * (line_weights - line_weights.min()) / (line_weights.max() - line_weights.min()) + 1e-2\n",
    "    weights_norm = np.clip(line_weights, 0, 100)\n",
    "    weights_norm = 0.05 * (np.log(weights_norm) - np.log(weights_norm.min()))\n",
    "\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], c=modality_np, s=size, cmap='managua')\n",
    "    plt.colorbar(label='Modality Score')\n",
    "    plt.title('UMAP of Dictionary Atoms')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/umap\" + (f\"_log\" if LOG else \"\") + \".png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/umap\" + (f\"_log\" if LOG else \"\") + \".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot\n",
    "    blackred_cmap = LinearSegmentedColormap.from_list('blackred', [(0, 0, 0, 0.1), (1, 0, 0, 1)], N=256)\n",
    "    blackred = np.zeros_like(modality_np)\n",
    "    # select randomly 20 points to be red, with probability given by weights\n",
    "    p = size / size.sum()\n",
    "    red_indices = np.random.choice(len(modality_np), size=int(20), p=p, replace=False)\n",
    "    blackred[red_indices] = 1  # Set selected indices to 1 for red color\n",
    "    plt.figure(figsize=(8, 6), facecolor='#FFE5DF')\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], c=blackred, s=size, cmap=blackred_cmap, vmin=0, vmax=1)\n",
    "    plt.colorbar(label='Modality Score')\n",
    "    plt.title('UMAP of Dictionary Atoms')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    # make the background of color FFC2B9 (light red)\n",
    "    plt.gca().set_facecolor('#FFE5DF')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/umap_black\" + (f\"_log\" if LOG else \"\") + \".png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/umap_black\" + (f\"_log\" if LOG else \"\") + \".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot\n",
    "    bi_idx = (modality_np > 0.2) & (modality_np < 0.8)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(embedding[bi_idx, 0], embedding[bi_idx, 1], c=modality_np[bi_idx], s=size[bi_idx], cmap='managua', vmin=0, vmax=1)\n",
    "    plt.colorbar(label='Modality Score')\n",
    "    plt.title('UMAP of Dictionary Atoms')\n",
    "    plt.axis('off')\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/umap_bi\" + (f\"_log\" if LOG else \"\") + \".png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/umap_bi\" + (f\"_log\" if LOG else \"\") + \".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], c=modality_np, s=size, cmap='managua')\n",
    "    plt.colorbar(label='Modality Score')\n",
    "    plt.title('UMAP of Dictionary Atoms')\n",
    "\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Self loops will be drawn as circles\n",
    "    def curved_edge(p1, p2, curvature=0.2):\n",
    "        # Midpoint and perpendicular vector for control point\n",
    "        midpoint = 0.5 * (p1 + p2)\n",
    "        delta = p2 - p1\n",
    "        norm = np.linalg.norm(delta)\n",
    "        if norm == 0:\n",
    "            return None  # Skip self-loops or overlapping points\n",
    "        perp = np.array([-delta[1], delta[0]]) / norm\n",
    "        control = midpoint + curvature * norm * perp\n",
    "\n",
    "        verts = [p1, control, p2]\n",
    "        codes = [Path.MOVETO, Path.CURVE3, Path.CURVE3]\n",
    "        return PathPatch(Path(verts, codes), facecolor='none', edgecolor='gray', lw=1, alpha=0.2)\n",
    "\n",
    "    # Add curved patches for each bridge above threshold\n",
    "    for k, (i, j, w) in enumerate(zip(i_idx, j_idx, line_weights)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        patch = curved_edge(embedding[i], embedding[j], curvature=0.15)\n",
    "        if patch:\n",
    "            patch.set_linewidth(weights_norm[k])\n",
    "            ax.add_patch(patch)\n",
    "\n",
    "    # Add self loops\n",
    "    def draw_self_loop(ax, center, radius, color, lw, n_points=100):\n",
    "        theta = np.linspace(0, 2 * np.pi, n_points)\n",
    "        x = center[0] + radius * np.cos(theta)\n",
    "        y = center[1] + radius * np.sin(theta) + radius  # upward offset by radius\n",
    "        ax.plot(x, y, color=color, lw=lw, alpha=0.2, zorder=0)\n",
    "\n",
    "    # Add self-loops using parametric circle\n",
    "    for k, (i, j, w) in enumerate(zip(i_idx, j_idx, line_weights)):\n",
    "        if i != j:\n",
    "            continue  # Only self-loops\n",
    "\n",
    "        center = embedding[i]\n",
    "        node_size = size[i] ** 0.5 / 100  # approximate radius from scatter size\n",
    "        loop_radius = node_size + weights_norm[k] * 0.5\n",
    "        loop_thickness = weights_norm[k]\n",
    "\n",
    "        draw_self_loop(ax, center, loop_radius, color='gray', lw=loop_thickness)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/umap_bridge\" + (f\"_log\" if LOG else \"\") + \".png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/umap_bridge\" + (f\"_log\" if LOG else \"\") + \".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(embedding_pca[:, 0], embedding_pca[:, 1], c=modality_np, s=size, cmap='managua')\n",
    "    plt.colorbar(label='Modality Score')\n",
    "    plt.title('PCA of Dictionary Atoms')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/pca\" + (f\"_log\" if LOG else \"\") + \".png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/pca\" + (f\"_log\" if LOG else \"\") + \".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(embedding_weighted_pca[:, 0], embedding_weighted_pca[:, 1], c=modality_np, s=size, cmap='managua')\n",
    "    plt.colorbar(label='Modality Score')\n",
    "    plt.title('Weighted PCA of Dictionary Atoms')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/weighted_pca\" + (f\"_log\" if LOG else \"\") + \".png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/weighted_pca\" + (f\"_log\" if LOG else \"\") + \".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # visualize an idealized version of \"linear separability\" :\n",
    "    # 1. Create dummy data : 2D unit vectors following three Von Mises distributions\n",
    "    # 2. assign a modality score to each point based on its angle + noise\n",
    "    # 2.5 assign an energy depending on the cosim with the center of the distribution\n",
    "    # 3. plot the points colored by modality score\n",
    "\n",
    "    def von_mises_2d(mu, kappa, size):\n",
    "        # Generate random angles from a von Mises distribution\n",
    "        angles = np.random.vonmises(mu, kappa, size)\n",
    "        # Convert angles to 2D unit vectors\n",
    "        x = np.cos(angles)\n",
    "        y = np.sin(angles)\n",
    "        return np.column_stack((x, y))\n",
    "\n",
    "    def generate_modality_score(points, noise=0.05):\n",
    "        # Calculate angles of points\n",
    "        angles = np.arctan2(points[:, 1], points[:, 0])\n",
    "        # Normalize angles to [0, 1]\n",
    "        normalized_angles = (1.5 * angles + np.pi) / (2 * np.pi)\n",
    "        # Add noise\n",
    "        noise = np.random.uniform(-noise, noise, size=normalized_angles.shape)\n",
    "        modality_scores = normalized_angles + noise\n",
    "        modality_scores = np.clip(modality_scores, 0, 1)\n",
    "        return modality_scores\n",
    "\n",
    "    def generate_energy(points, center, noise=5):\n",
    "        # Calculate angles of points\n",
    "        cosim = np.dot(points, center) / (np.linalg.norm(points, axis=1) * np.linalg.norm(center))\n",
    "        # Normalize angles to [0, 1]\n",
    "        normalized_cosim = (cosim + 1) / 2\n",
    "        # Add noise\n",
    "        noise = np.random.uniform(-noise, noise, size=normalized_cosim.shape)\n",
    "        energy_scores = normalized_cosim + noise\n",
    "        energy_scores -= energy_scores.min()\n",
    "        energy_scores /= energy_scores.max()\n",
    "        energy_scores = np.exp(energy_scores * 2) \n",
    "        return energy_scores\n",
    "\n",
    "    def plot_von_mises(points, energies, modality_scores, title):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.scatter(points[:, 0], points[:, 1], c=modality_scores, cmap='managua', s=energies * 30)\n",
    "        plt.colorbar(label='Modality Score')\n",
    "        plt.title(title)\n",
    "        plt.axis('equal')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/dummy_von_mises.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/dummy_von_mises.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "    points1 = von_mises_2d(mu=0, kappa=5, size=100)\n",
    "    energy1 = generate_energy(points1, np.array([1, 0]), noise=0.5)\n",
    "    points2 = von_mises_2d(mu=2 * np.pi/3, kappa=100, size=100)\n",
    "    energy2 = generate_energy(points2, np.array([-1, 0]), noise=0.5)\n",
    "    points3 = von_mises_2d(mu=4 * np.pi/3, kappa=100, size=100)\n",
    "    energy3 = generate_energy(points3, np.array([-1, 0]), noise=0.5)\n",
    "\n",
    "    points = np.vstack((points1, points2, points3))\n",
    "    energies = np.hstack((energy1, energy2, energy3))\n",
    "    plot_von_mises(points, energies, generate_modality_score(points), \"Von Mises Distribution with Modality Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_visualization(SSAE, SSAE_name, SSAE.metrics.mu, SSAE.metrics.E, SSAE.metrics.f, SSAE_bridge[\"bridge_sigma\"])\n",
    "generate_visualization(ASAE, ASAE_name, ASAE.metrics.mu, ASAE.metrics.E, ASAE.metrics.f, ASAE_bridge[\"bridge_sigma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.1. Features classifying features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO : projection onto 3D space defined by LR probes (maybe 2D with image & text probes is enough ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = modality_threshold\n",
    "def linear_separability(sae, sae_name, eps=eps):\n",
    "    D = sae.dictionary._fused_dictionary.cpu()\n",
    "    modality_score = sae.metrics.mu\n",
    "    energy_per_concept = sae.metrics.E\n",
    "    print(D.shape)\n",
    "    I_mask = (modality_score > 1 - eps).cpu()\n",
    "    T_mask = (modality_score < eps).cpu()\n",
    "    B_mask = (modality_score <= 1 - eps).cpu() & (modality_score >= eps).cpu()\n",
    "    print(f\"Number of unimodal concepts: {I_mask.sum()}, {T_mask.sum()}, {B_mask.sum()}\")\n",
    "\n",
    "    mu_weighted_I = (D[I_mask] * energy_per_concept[I_mask].unsqueeze(1).cpu()).sum(dim=0).cpu() / energy_per_concept[I_mask].sum().cpu()\n",
    "    mu_weighted_T = (D[T_mask] * energy_per_concept[T_mask].unsqueeze(1).cpu()).sum(dim=0).cpu() / energy_per_concept[T_mask].sum().cpu()\n",
    "    mu_weighted_B = (D[B_mask] * energy_per_concept[B_mask].unsqueeze(1).cpu()).sum(dim=0).cpu() / energy_per_concept[B_mask].sum().cpu()\n",
    "\n",
    "    d1 = (mu_weighted_B - mu_weighted_I).cpu().numpy()\n",
    "    d1 /= np.linalg.norm(d1)\n",
    "    d2 = (mu_weighted_B - mu_weighted_T).cpu().numpy()\n",
    "    d2 /= np.linalg.norm(d2)\n",
    "\n",
    "    mu_tout_court = D.mean(dim=0).cpu().numpy()\n",
    "    mu_weighted_tout_court = (D * energy_per_concept.unsqueeze(1).cpu()).sum(dim=0).cpu().numpy() / energy_per_concept.sum().cpu().numpy()\n",
    "\n",
    "    D1 = D.cpu().numpy() # shape (N, 512)\n",
    "    D1 = D1 @ d1.reshape(-1, 1) # shape (N, 1)\n",
    "    D2 = D.cpu().numpy() # shape (N, 512)\n",
    "    D2 = D2 @ d2.reshape(-1, 1) # shape (N, 1)\n",
    "    D_proj = np.concatenate([D1, D2], axis=1) # shape (N, 2)\n",
    "\n",
    "    modality_color = {\n",
    "        \"bimodal\": colorsys.rgb_to_hls(*np.array([91/255, 40/255, 68/255])),\n",
    "        \"image\": colorsys.rgb_to_hls(*np.array([128/255, 230/255, 255/255])),\n",
    "        \"text\": colorsys.rgb_to_hls(*np.array([255/255, 205/255, 102/255])),\n",
    "    }\n",
    "    \n",
    "    # Normalize energy for plotting size\n",
    "    energy_np = energy_per_concept.cpu().numpy()\n",
    "    LOG = False\n",
    "    if LOG:\n",
    "        # Log scale energy normalization\n",
    "        log_energy = np.log(energy_np)  # Log transform with offset to avoid log(0)\n",
    "        size = log_energy - log_energy.min()\n",
    "        size = 0.1 * (size) ** 2\n",
    "    else:\n",
    "        # Linear scale energy normalization\n",
    "        size = energy_np - energy_np.min()\n",
    "        size = 300 * (np.sqrt(size / size.max()))\n",
    "\n",
    "    def _plot_proj_mu():\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(D_proj[:, 0], D_proj[:, 1], c=modality_score.cpu().numpy(), s=size, cmap='managua')\n",
    "        plt.colorbar(label='Modality Score')\n",
    "        plt.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "        plt.axvline(0, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Plot all the means of the modalities\n",
    "        plt.scatter(mu_weighted_I.cpu().numpy() @ d1.reshape(-1, 1), mu_weighted_I.cpu().numpy() @ d2.reshape(-1, 1), color=colorsys.hls_to_rgb(modality_color[\"image\"][0], modality_color[\"image\"][1] * 0.3, modality_color[\"image\"][2]), marker='+', s=100, label='mu_I')\n",
    "        plt.scatter(mu_weighted_T.cpu().numpy() @ d1.reshape(-1, 1), mu_weighted_T.cpu().numpy() @ d2.reshape(-1, 1), color=colorsys.hls_to_rgb(modality_color[\"text\"][0], modality_color[\"text\"][1] * 0.3, modality_color[\"text\"][2]), marker='+', s=100, label='mu_T')\n",
    "        plt.scatter(mu_weighted_B.cpu().numpy() @ d1.reshape(-1, 1), mu_weighted_B.cpu().numpy() @ d2.reshape(-1, 1), color=colorsys.hls_to_rgb(modality_color[\"bimodal\"][0], modality_color[\"bimodal\"][1] * 0.3, modality_color[\"bimodal\"][2]), marker='+', s=100, label='mu_B')\n",
    "        plt.scatter(mu_weighted_tout_court @ d1.reshape(-1, 1), mu_weighted_tout_court @ d2.reshape(-1, 1), color='k', marker='+', s=100, label='barycenter')\n",
    "        plt.xlabel('Projection on mu_B - mu_I')\n",
    "        plt.ylabel('Projection on mu_B - mu_T')\n",
    "        plt.title('Projection of D on mu_B - mu_I and mu_B - mu_T')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(f\"./figures/{sae_name.replace('.pt', '')}/geometry\", exist_ok=True)\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/projection_mu_B.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/projection_mu_B.pdf\")\n",
    "        plt.show()\n",
    "    # _plot_proj_mu()\n",
    "\n",
    "    # Baseline 1 : mu_weighted_{I,T,B}, bias : mu_weighted_tout_court\n",
    "\n",
    "    def evaluate_custom_probe(weight, bias, trg_mask):\n",
    "        probe = torch.nn.Linear(D.shape[1], 1, bias=True)\n",
    "        probe.weight.data = weight\n",
    "        probe.bias.data = torch.tensor(bias)\n",
    "        probe.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = (D - probe.bias.unsqueeze(0)) @ probe.weight\n",
    "            \n",
    "            # print(f\"probe_I : {(probe_I > 0).float().mean().item():.4f}, probe_T : {(probe_T > 0).float().mean().item():.4f}, probe_B : {(probe_B > 0).float().mean().item():.4f}\")\n",
    "            acc = (((preds > 0) == trg_mask).float() * energy_per_concept.cpu()).sum() / energy_per_concept.sum()\n",
    "\n",
    "        return acc.item()\n",
    "    \n",
    "    acc_I = evaluate_custom_probe(mu_weighted_I, mu_weighted_tout_court, I_mask)\n",
    "    acc_T = evaluate_custom_probe(mu_weighted_T, mu_weighted_tout_court, T_mask)\n",
    "    acc_B = evaluate_custom_probe(mu_weighted_B, mu_weighted_tout_court, B_mask)\n",
    "    print(\"Probe 1 : mu_weighted_I\", acc_I)\n",
    "    print(\"Probe 2 : mu_weighted_T\", acc_T)\n",
    "    print(\"Probe 3 : mu_weighted_B\", acc_B)\n",
    "\n",
    "    # baseline 2 : fit scikit-learn linear regression for each region :\n",
    "\n",
    "    def evaluate_probe_sklearn(P, N1, N2, P_mask, N1_mask, N2_mask):\n",
    "        N = np.concatenate([N1, N2], axis=0)\n",
    "        N_mask = (N1_mask | N2_mask).cpu().numpy()\n",
    "        X = np.concatenate([P, N], axis=0)\n",
    "        y = np.concatenate([np.ones(P.shape[0]), np.zeros(N.shape[0])], axis=0)\n",
    "        \n",
    "        # Shuffle\n",
    "        perm = np.random.permutation(X.shape[0])\n",
    "        X, y = X[perm], y[perm]\n",
    "        energy_perm = energy_per_concept.cpu().numpy()[perm]\n",
    "        P_mask = P_mask.cpu().numpy()[perm]\n",
    "        N_mask = N_mask[perm]\n",
    "        \n",
    "        # Compute sample weights\n",
    "        energy_perm[P_mask] = energy_perm[P_mask] / energy_perm[P_mask].sum() / 2\n",
    "        energy_perm[N_mask] = energy_perm[N_mask] / energy_perm[N_mask].sum() / 2\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y, sample_weight=energy_perm)\n",
    "        y_pred = model.predict(X)\n",
    "        y_pred = (y_pred > 0.5).astype(int)\n",
    "        y_pred = (y_pred == y).astype(int)\n",
    "        return (y_pred * energy_perm).sum() / energy_perm.sum(), model\n",
    "    \n",
    "    acc_lr_B, lr_probe_B = evaluate_probe_sklearn(D[B_mask], D[I_mask], D[T_mask], B_mask, I_mask, T_mask)\n",
    "    acc_lr_I, lr_probe_I = evaluate_probe_sklearn(D[I_mask], D[B_mask], D[T_mask], I_mask, B_mask, T_mask)\n",
    "    acc_lr_T, lr_probe_T = evaluate_probe_sklearn(D[T_mask], D[I_mask], D[B_mask], T_mask, I_mask, B_mask)\n",
    "    print(\"Probe 4 : Linear Regression B\", acc_lr_B)\n",
    "    print(\"Probe 5 : Linear Regression I\", acc_lr_I)\n",
    "    print(\"Probe 6 : Linear Regression T\", acc_lr_T)\n",
    "    \n",
    "    # Plot projection on probe directions :\n",
    "    lr_d_B = lr_probe_B.coef_.reshape(-1)\n",
    "    d1 = lr_d_B / np.linalg.norm(lr_d_B)\n",
    "    lr_d_I = lr_probe_I.coef_.reshape(-1)\n",
    "    d2 = lr_d_I / np.linalg.norm(lr_d_I)\n",
    "    lr_d_T = lr_probe_T.coef_.reshape(-1)\n",
    "    d3 = lr_d_T / np.linalg.norm(lr_d_T)\n",
    "    \n",
    "    D_ = D.cpu().numpy()\n",
    "    x1 = D_ @ d1.reshape(-1, 1)  # projection on I\n",
    "    x2 = D_ @ d2.reshape(-1, 1)  # projection on T\n",
    "    x3 = D_ @ d3.reshape(-1, 1)  # projection on B*\n",
    "    \n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    import plotly.graph_objects as go\n",
    "    \n",
    "    def mpl_to_plotly(cmap_name, pl_entries=255, luminance_scale=1.0):\n",
    "        cmap = plt.cm.get_cmap(cmap_name, pl_entries)\n",
    "        h = 1.0 / (pl_entries - 1)\n",
    "        colorscale = []\n",
    "\n",
    "        for k in range(pl_entries):\n",
    "            r, g, b, _ = cmap(k)\n",
    "            hls = colorsys.rgb_to_hls(r, g, b)\n",
    "            l_scaled = max(0.0, min(1.0, hls[1] * luminance_scale))\n",
    "            r_new, g_new, b_new = colorsys.hls_to_rgb(hls[0], l_scaled, hls[2])\n",
    "            colorscale.append([\n",
    "                round(k * h, 4),\n",
    "                f'rgb({int(r_new * 255)}, {int(g_new * 255)}, {int(b_new * 255)})'\n",
    "            ])\n",
    "\n",
    "        return colorscale\n",
    "    \n",
    "    managua_plotly = mpl_to_plotly('managua')\n",
    "    dark_managua_plotly = mpl_to_plotly('managua', luminance_scale=0.5)\n",
    "\n",
    "    class_score = modality_score.cpu().numpy()\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(\n",
    "            x=x1.squeeze(), y=x2.squeeze(), z=x3.squeeze(),\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=np.power(size**2, 1/3) * 0.5,\n",
    "                color=class_score,\n",
    "                colorscale=managua_plotly,  # or 'managua' if you have a custom Plotly scale\n",
    "                colorbar=dict(title='Modality Score'),\n",
    "                opacity=0.8,\n",
    "                line=dict(width=0),\n",
    "            )\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(\n",
    "            x=x1.squeeze(), y=x2.squeeze(), z=np.zeros_like(x3.squeeze()) + min(x3),\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=np.power(size**2, 1/3) * 0.5,\n",
    "                color=class_score,\n",
    "                colorscale=dark_managua_plotly,  # or 'managua' if you have a custom Plotly scale\n",
    "                # colorbar=dict(title='Modality Score'),\n",
    "                opacity=0.1,\n",
    "                line=dict(width=0),\n",
    "                symbol='circle',\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def add_arrow(fig, origin, direction, color, name):\n",
    "        # Normalize and scale arrow length\n",
    "        norm_dir = direction / np.linalg.norm(direction)\n",
    "        length = np.linalg.norm(direction)\n",
    "        end = origin + norm_dir * length\n",
    "        # if color is a tuple of numpy arrays, convert it to a string RGB format\n",
    "        if isinstance(color, tuple) and all(isinstance(c, np.ndarray) for c in color):\n",
    "            color = f'rgb({int(color[0] * 255)}, {int(color[1] * 255)}, {int(color[2] * 255)})'\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[origin[0], end[0]],\n",
    "            y=[origin[1], end[1]],\n",
    "            z=[origin[2], end[2]],\n",
    "            mode='lines+markers',\n",
    "            name=name,\n",
    "            line=dict(color=[color, color], width=6),\n",
    "            marker=dict(size=5, color=[color, color], symbol='circle')\n",
    "        ))\n",
    "    \n",
    "    # Get mean vectors projected into the 3D space\n",
    "    mu_B = (mu_weighted_B.cpu().numpy() @ np.stack([d1, d2, d3], axis=1)).flatten()\n",
    "    mu_I = (mu_weighted_I.cpu().numpy() @ np.stack([d1, d2, d3], axis=1)).flatten()\n",
    "    mu_T = (mu_weighted_T.cpu().numpy() @ np.stack([d1, d2, d3], axis=1)).flatten()\n",
    "\n",
    "\n",
    "    # Add arrows from origin to means\n",
    "    add_arrow(fig, origin=np.zeros(3), direction=mu_I, color=colorsys.hls_to_rgb(modality_color[\"image\"][0], modality_color[\"image\"][1] * 0.3, modality_color[\"image\"][2]), name='μ_I')\n",
    "    add_arrow(fig, origin=np.zeros(3), direction=mu_T, color=colorsys.hls_to_rgb(modality_color[\"text\"][0], modality_color[\"text\"][1] * 0.3, modality_color[\"text\"][2]), name='μ_T')\n",
    "    add_arrow(fig, origin=np.zeros(3), direction=mu_B, color=colorsys.hls_to_rgb(modality_color[\"bimodal\"][0], modality_color[\"bimodal\"][1] * 0.3, modality_color[\"bimodal\"][2]), name='μ_B')\n",
    "    add_arrow(fig, origin=np.zeros(3), direction=mu_weighted_tout_court @ np.stack([d1, d2, d3], axis=1), color='black', name='μ')\n",
    "\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(\n",
    "                backgroundcolor='rgba(0,0,0,0)',\n",
    "                gridcolor='rgba(0,0,0,0)',\n",
    "                zeroline=False,\n",
    "                showbackground=False\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                backgroundcolor='rgba(0,0,0,0)',\n",
    "                gridcolor='rgba(0,0,0,0)',\n",
    "                zeroline=False,\n",
    "                showbackground=False\n",
    "            ),\n",
    "            zaxis=dict(\n",
    "                backgroundcolor='rgba(0.9,0.9,0.9,1)',\n",
    "                # gridcolor='rgba(1,1,1,1)',\n",
    "                # zeroline=False,\n",
    "                # showbackground=False\n",
    "            ),\n",
    "            xaxis_title=r'LR_B',\n",
    "            yaxis_title=r'LR_I',\n",
    "            zaxis_title=r'LR_T',\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=30),\n",
    "        title=\"3D Projection on Linear Regression Directions\",\n",
    "        scene_camera=dict(\n",
    "            eye=dict(x=1., y=2., z=0.6),\n",
    "        )\n",
    "    )\n",
    "    # save html and pdf fig :\n",
    "    fig.write_html(f\"./figures/{sae_name.replace('.pt', '')}/geometry/projection_lr.html\")\n",
    "    fig.write_image(f\"./figures/{sae_name.replace('.pt', '')}/geometry/projection_lr.pdf\")\n",
    "    fig.write_image(f\"./figures/{sae_name.replace('.pt', '')}/geometry/projection_lr.png\", scale=5)\n",
    "    fig.show()\n",
    "    \n",
    "    # Now, consider each D_i as a probe and measure it's accuracy :\n",
    "\n",
    "    accs = []\n",
    "    for i in range(D.shape[0]):\n",
    "        probe = D[i]\n",
    "        if B_mask[i]:\n",
    "            trg_mask = B_mask\n",
    "        elif I_mask[i]:\n",
    "            trg_mask = I_mask\n",
    "        elif T_mask[i]:\n",
    "            trg_mask = T_mask\n",
    "        else:\n",
    "            raise ValueError(\"Unknown modality\")\n",
    "        acc = evaluate_custom_probe(probe, mu_weighted_tout_court, trg_mask)\n",
    "        accs.append(acc)\n",
    "\n",
    "    print(f\"Mean acc : {np.mean(accs):.4f}, std : {np.std(accs):.4f}\")\n",
    "    e = energy_per_concept.cpu().numpy() / energy_per_concept.sum().item()\n",
    "    print(f\"Mean acc : {(np.array(accs) * e).sum():.4f}\")\n",
    "\n",
    "    def _plot_acc_hist():\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(accs, bins=100, range=(0, 1), color='blue', label='Probe Accuracy', weights=energy_per_concept.cpu().numpy() / energy_per_concept.sum().item())\n",
    "        plt.title(\"Distribution of Probe Accuracy\")\n",
    "        plt.xlabel(\"Probe Accuracy\")\n",
    "        plt.ylabel(\"density\")\n",
    "        #plt.yscale(\"log\")\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.legend()\n",
    "        # Add mean and std information to the plot\n",
    "        # plt.text(0.05, 0.95, f\"Mean: {np.mean(accs):.4f}\\nStd: {np.std(accs):.4f}\", transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5))\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/probe_accuracy.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/probe_accuracy.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "        # plot accuracy vs modality score :\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hexbin(modality_score.cpu().numpy(), accs, gridsize=30, cmap='magma_r', bins='log', C=energy_per_concept.cpu().numpy(), reduce_C_function=np.sum, norm=LogNorm(vmin=max(1e-4, energy_per_concept.cpu().numpy().min())))\n",
    "        plt.colorbar(label='density', extend='min')\n",
    "        plt.title(\"Probe Accuracy vs Modality Score\")\n",
    "        plt.xlabel(\"Modality Score\")\n",
    "        plt.ylabel(\"Probe Accuracy\")\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/probe_accuracy_vs_modality_score.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/probe_accuracy_vs_modality_score.pdf\")\n",
    "        plt.show()\n",
    "    _plot_acc_hist()\n",
    "\n",
    "    sae.metrics._add_more({\n",
    "        'linear_separability': {\n",
    "            'acc_I': acc_I,\n",
    "            'acc_T': acc_T,\n",
    "            'acc_B': acc_B,\n",
    "            'acc_lr_B': acc_lr_B,\n",
    "            'acc_lr_I': acc_lr_I,\n",
    "            'acc_lr_T': acc_lr_T,\n",
    "            'feature_probe': (np.array(accs) * energy_per_concept.cpu().numpy()).sum() / energy_per_concept.sum(),\n",
    "        }\n",
    "    }, save=True)\n",
    "    \n",
    "    def _plot_probe_accuracy_bar_colored_by_modality():\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        cmap = plt.get_cmap(\"managua\")\n",
    "        norm = plt.Normalize(vmin=0, vmax=1)\n",
    "        bins = np.linspace(0, 1, 101)  # 30 bins\n",
    "        bin_centers = 0.5 * (bins[:-1] + bins[1:])  # Bin centers for plotting\n",
    "        digitized = np.digitize(accs, bins) - 1\n",
    "        weights = energy_per_concept.cpu().numpy() / energy_per_concept.sum().item()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for b in range(len(bins) - 1):\n",
    "            b_idx = np.where(digitized == b)[0]\n",
    "            if len(b_idx) == 0:\n",
    "                continue\n",
    "            sorted_idx = b_idx[np.argsort(modality_score[b_idx].cpu().numpy())]\n",
    "            bottom = 0\n",
    "            for i in sorted_idx:\n",
    "                height = weights[i]\n",
    "                color = cmap(norm(modality_score[i].cpu().numpy()))  # modality -> color\n",
    "                plt.bar(bin_centers[b], height, width=(bins[1] - bins[0]), bottom=bottom, color=color, edgecolor='none')\n",
    "                bottom += height\n",
    "        sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "        sm.set_array([])  # Dummy array for ScalarMappable\n",
    "        cbar = plt.colorbar(sm, ax=plt.gca(), orientation='vertical', label='Modality Score') \n",
    "        plt.title(\"Distribution of Probe Accuracy\")\n",
    "        plt.xlabel(\"Probe Accuracy\")\n",
    "        plt.ylabel(\"density\")\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/probe_accuracy_bar_colored_by_modality.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/probe_accuracy_bar_colored_by_modality.pdf\")\n",
    "        plt.show()\n",
    "    _plot_probe_accuracy_bar_colored_by_modality()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_separability(SSAE, SSAE_name, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_separability(ASAE, ASAE_name, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SSAE.metrics)\n",
    "print(ASAE.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.2. Features classifying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = modality_threshold # Unimodality threshold\n",
    "@torch.no_grad()\n",
    "def data_classifiability(sae, sae_name, eps=eps, skip_plot=False):\n",
    "    I = train_loader.dataset.tensors[0]\n",
    "    I = I[torch.randperm(I.shape[0])[:int(1e4)]]\n",
    "    T = train_loader.dataset.tensors[1]\n",
    "    T = T[torch.randperm(T.shape[0])[:int(1e4)]]\n",
    "    D_ata = torch.cat([I, T], dim=0) # shape (N, 512)\n",
    "    D_ict = sae.dictionary._fused_dictionary.cpu() # shape (M, 512)\n",
    "    modality_score = sae.metrics.mu\n",
    "    energy_per_concept = sae.metrics.E\n",
    "    print(D_ict.shape)\n",
    "    I_mask = (modality_score > 1 - eps).cpu()\n",
    "    T_mask = (modality_score < eps).cpu()\n",
    "    B_mask = (modality_score <= 1 - eps).cpu() & (modality_score >= eps).cpu()\n",
    "    print(f\"Number of unimodal concepts: {I_mask.sum()}, {T_mask.sum()}, {B_mask.sum()}\")\n",
    "\n",
    "    mu_weighted_I = (D_ict[I_mask] * energy_per_concept[I_mask].unsqueeze(1).cpu()).sum(dim=0).cpu() / energy_per_concept[I_mask].sum().cpu()\n",
    "    mu_weighted_T = (D_ict[T_mask] * energy_per_concept[T_mask].unsqueeze(1).cpu()).sum(dim=0).cpu() / energy_per_concept[T_mask].sum().cpu()\n",
    "    mu_weighted_B = (D_ict[B_mask] * energy_per_concept[B_mask].unsqueeze(1).cpu()).sum(dim=0).cpu() / energy_per_concept[B_mask].sum().cpu()\n",
    "\n",
    "    mu_weighted_tout_court = (D_ict * energy_per_concept.unsqueeze(1).cpu()).sum(dim=0).cpu().numpy() / energy_per_concept.sum().cpu().numpy()\n",
    "\n",
    "    # Baseline 1 : mu_weighted_{I,T,B}, bias : mu_weighted_tout_court\n",
    "\n",
    "    def evaluate_custom_probe(weight, bias, trg_mask):\n",
    "        probe = torch.nn.Linear(D_ict.shape[1], 1, bias=True)\n",
    "        probe.weight.data = weight\n",
    "        probe.bias.data = torch.tensor(bias)\n",
    "        probe.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = (D_ata - probe.bias.unsqueeze(0)) @ probe.weight\n",
    "            \n",
    "            # print(f\"probe_I : {(probe_I > 0).float().mean().item():.4f}, probe_T : {(probe_T > 0).float().mean().item():.4f}, probe_B : {(probe_B > 0).float().mean().item():.4f}\")\n",
    "            acc = ((preds > 0) == trg_mask).float().mean()\n",
    "\n",
    "        return acc.item()\n",
    "    \n",
    "    Image_Data_Mask = torch.zeros(D_ata.shape[0], dtype=torch.bool)\n",
    "    Image_Data_Mask[:I.shape[0]] = True\n",
    "    Image_Data_Mask = Image_Data_Mask.cpu().numpy()\n",
    "    Text_Data_Mask = torch.zeros(D_ata.shape[0], dtype=torch.bool)\n",
    "    Text_Data_Mask[I.shape[0]:] = True\n",
    "    Text_Data_Mask = Text_Data_Mask.cpu().numpy()\n",
    "    acc_I = evaluate_custom_probe(mu_weighted_I, mu_weighted_tout_court, Image_Data_Mask) # Target accuracy : 1\n",
    "    acc_T = evaluate_custom_probe(mu_weighted_T, mu_weighted_tout_court, Text_Data_Mask) # Target accuracy : 1\n",
    "    acc_B = evaluate_custom_probe(mu_weighted_B, mu_weighted_tout_court, Image_Data_Mask) # Target accuracy : 0.5\n",
    "    acc_B = max(acc_B, 1-acc_B)\n",
    "    print(\"Probe 1 : mu_weighted_I\", acc_I)\n",
    "    print(\"Probe 2 : mu_weighted_T\", acc_T)\n",
    "    print(\"Probe 3 : mu_weighted_B\", acc_B)\n",
    "\n",
    "    # baseline 2 : fit scikit-learn linear regression for each region :\n",
    "\n",
    "    def evaluate_probe_sklearn(P, N1, N2, P_mask, N1_mask, N2_mask):\n",
    "        N = np.concatenate([N1, N2], axis=0)\n",
    "        N_mask = (N1_mask | N2_mask).cpu().numpy()\n",
    "        X = np.concatenate([P, N], axis=0)\n",
    "        y = np.concatenate([np.ones(P.shape[0]), np.zeros(N.shape[0])], axis=0)\n",
    "        \n",
    "        # Shuffle\n",
    "        perm = np.random.permutation(X.shape[0])\n",
    "        X, y = X[perm], y[perm]\n",
    "        energy_perm = energy_per_concept.cpu().numpy()[perm]\n",
    "        P_mask = P_mask.cpu().numpy()[perm]\n",
    "        N_mask = N_mask[perm]\n",
    "        \n",
    "        # Compute sample weights\n",
    "        energy_perm[P_mask] = energy_perm[P_mask] / energy_perm[P_mask].sum() / 2\n",
    "        energy_perm[N_mask] = energy_perm[N_mask] / energy_perm[N_mask].sum() / 2\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y, sample_weight=energy_perm)\n",
    "        y_pred = model.predict(D_ata.cpu().numpy())\n",
    "        y_pred = (y_pred > 0.5).astype(int)\n",
    "        y_pred = (y_pred == Image_Data_Mask).astype(int)\n",
    "        return y_pred.mean()\n",
    "    \n",
    "    acc_lr_B = evaluate_probe_sklearn(D_ict[B_mask], D_ict[I_mask], D_ict[T_mask], B_mask, I_mask, T_mask) # Target accuracy : 0.5\n",
    "    acc_lr_B = max(acc_lr_B, 1-acc_lr_B)\n",
    "    acc_lr_I = evaluate_probe_sklearn(D_ict[I_mask], D_ict[B_mask], D_ict[T_mask], I_mask, B_mask, T_mask) # Target accuracy : 1\n",
    "    acc_lr_T = evaluate_probe_sklearn(D_ict[T_mask], D_ict[I_mask], D_ict[B_mask], T_mask, I_mask, B_mask) # Target accuracy : 0\n",
    "    acc_lr_T = 1 - acc_lr_T # because we want to predict the text data\n",
    "    print(\"Probe 4 : Linear Regression B\", acc_lr_B)\n",
    "    print(\"Probe 5 : Linear Regression I\", acc_lr_I)\n",
    "    print(\"Probe 6 : Linear Regression T\", acc_lr_T)\n",
    "\n",
    "    # Now, consider each D_i as a probe and measure it's accuracy :\n",
    "\n",
    "    accs = []\n",
    "    accs_trg = []\n",
    "    for i in tqdm(range(D_ict.shape[0])):\n",
    "        probe = D_ict[i]\n",
    "        if B_mask[i]:\n",
    "            trg_mask = Image_Data_Mask\n",
    "        elif I_mask[i]:\n",
    "            trg_mask = Image_Data_Mask\n",
    "        elif T_mask[i]:\n",
    "            trg_mask = Text_Data_Mask\n",
    "        else:\n",
    "            raise ValueError(\"Unknown modality\")\n",
    "        acc = evaluate_custom_probe(probe, mu_weighted_tout_court, trg_mask)\n",
    "        if B_mask[i]:\n",
    "            acc = max(acc, 1 - acc)\n",
    "            accs.append(acc)\n",
    "            accs_trg.append(1.5 - acc)\n",
    "        else:\n",
    "            accs.append(acc)\n",
    "            accs_trg.append(acc)\n",
    "\n",
    "    print(f\"Mean unweighted acc : {np.mean(accs):.4f}, std : {np.std(accs):.4f}\")\n",
    "    print(f\"Mean acc : {(np.array(accs_trg) * energy_per_concept.cpu().numpy()).sum() / energy_per_concept.sum():.4f}\")\n",
    "\n",
    "    if not skip_plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(accs, bins=100, range=(0, 1), color='blue', label='Probe Accuracy', weights=energy_per_concept.cpu().numpy() / energy_per_concept.sum().item())\n",
    "        plt.title(\"Distribution of Probe Accuracy\")\n",
    "        plt.xlabel(\"Probe Accuracy\")\n",
    "        plt.ylabel(\"density\")\n",
    "        #plt.yscale(\"log\")\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.legend()\n",
    "        # Add mean and std information to the plot\n",
    "        # plt.text(0.05, 0.95, f\"Mean: {np.mean(accs):.4f}\\nStd: {np.std(accs):.4f}\", transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5))\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/data_probe_accuracy.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/data_probe_accuracy.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "        # plot accuracy vs modality score :\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hexbin(modality_score.cpu().numpy(), accs, gridsize=30, cmap='magma_r', bins='log', C=energy_per_concept.cpu().numpy(), reduce_C_function=np.sum, norm=LogNorm(vmin=max(1e-4, energy_per_concept.cpu().numpy().min())))\n",
    "        plt.colorbar(label='density', extend='min')\n",
    "        plt.title(\"Probe Accuracy vs Modality Score\")\n",
    "        plt.xlabel(\"Modality Score\")\n",
    "        plt.ylabel(\"Probe Accuracy\")\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/data_probe_accuracy_vs_modality_score.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/data_probe_accuracy_vs_modality_score.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "        modality_perm = torch.argsort(modality_score).cpu()\n",
    "\n",
    "        modality_sorted = modality_score[modality_perm]\n",
    "        accs_sorted = np.array(accs)[modality_perm.cpu().numpy()]\n",
    "\n",
    "        values = modality_sorted.cpu().numpy()\n",
    "        weights = (energy_per_concept[modality_perm].cpu().numpy())\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "        bins = np.linspace(0, 1, 31)\n",
    "        digitized = np.digitize(values, bins) - 1 # shape (N,), where N is the number of concepts. Each value is the index of the bin it belongs to.\n",
    "        digitized = np.clip(digitized, 0, len(bins) - 2)\n",
    "\n",
    "        # Weighted mean per bin\n",
    "        numerator = np.bincount(digitized, weights=accs_sorted * weights, minlength=len(bins)-1)\n",
    "        denominator = np.bincount(digitized, weights=weights, minlength=len(bins)-1)\n",
    "        mean_per_bin = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator != 0)\n",
    "        for b in range(len(mean_per_bin)):\n",
    "            b_idx = np.where(digitized == b)[0]\n",
    "            if len(b_idx) == 0:\n",
    "                mean_per_bin[b] = 0\n",
    "            else:\n",
    "                mean_per_bin[b] = np.sum(accs_sorted[b_idx] * weights[b_idx]) / np.sum(weights[b_idx]) if np.sum(weights[b_idx]) > 0 else 0\n",
    "\n",
    "        bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(bin_centers, mean_per_bin, color='blue')\n",
    "        plt.xlabel(\"Modality Score\")\n",
    "        plt.ylabel(\"Weighted Mean per Bin\")\n",
    "        plt.title(\"Histogram of Modality Score Means (Weighted)\")\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/data_probe_accuracy_vs_modality_score.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/data_probe_accuracy_vs_modality_score.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        cmap = plt.get_cmap(\"managua\")\n",
    "        norm = plt.Normalize(vmin=0, vmax=1)\n",
    "        bins = np.linspace(0, 1, 101)  # 30 bins\n",
    "        bin_centers = 0.5 * (bins[:-1] + bins[1:])  # Bin centers for plotting\n",
    "        digitized = np.digitize(accs_sorted, bins) - 1\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for b in range(len(bins) - 1):\n",
    "            b_idx = np.where(digitized == b)[0]\n",
    "            if len(b_idx) == 0:\n",
    "                continue\n",
    "            # Sort i_j by energy\n",
    "            sorted_idx = b_idx[np.argsort(values[b_idx])]\n",
    "            bottom = 0\n",
    "            for i in sorted_idx:\n",
    "                height = weights[i]\n",
    "                color = cmap(norm(values[i]))  # modality -> color\n",
    "                plt.bar(bin_centers[b], height, width=(bins[1] - bins[0]), bottom=bottom, color=color, edgecolor='none')\n",
    "                bottom += height\n",
    "        sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "        sm.set_array([])  # Dummy array for ScalarMappable\n",
    "        cbar = plt.colorbar(sm, ax=plt.gca(), orientation='vertical', label='Modality Score') \n",
    "        plt.title(\"Distribution of Probe Accuracy\")\n",
    "        plt.xlabel(\"Probe Accuracy\")\n",
    "        plt.ylabel(\"density\")\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.ylim(0, 0.2)\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/data_probe_accuracy_bar_colored_by_modality.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(f\"./figures/{sae_name.replace('.pt', '')}/geometry/data_probe_accuracy_bar_colored_by_modality.pdf\")\n",
    "        plt.show()\n",
    "        \n",
    "    sae.metrics._add_more({\n",
    "        'data_cassifiability': {\n",
    "            'acc_I': acc_I,\n",
    "            'acc_T': acc_T,\n",
    "            'acc_B': acc_B,\n",
    "            'acc_lr_B': acc_lr_B,\n",
    "            'acc_lr_I': acc_lr_I,\n",
    "            'acc_lr_T': acc_lr_T,\n",
    "            'feature_probe': (np.array(accs_trg) * energy_per_concept.cpu().numpy()).sum() / energy_per_concept.sum(),\n",
    "        }\n",
    "    }, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifiability(SSAE, SSAE_name, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifiability(ASAE, ASAE_name, eps=eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.3. Dictionary orthogonality : $D_I \\bot D_T \\bot D_B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_orthogonality(sae, modality_score):\n",
    "    D = sae.dictionary._fused_dictionary.cpu().numpy()\n",
    "    D = D / np.linalg.norm(D, axis=1, keepdims=True)  # Normalize each vector to unit length\n",
    "    orthogonality = (np.dot(D, D.T))\n",
    "    I_mask = (modality_score > 0.9).cpu().numpy()\n",
    "    T_mask = (modality_score < 0.1).cpu().numpy()\n",
    "    B_mask = (modality_score <= 0.9).cpu().numpy() & (modality_score >= 0.1).cpu().numpy()\n",
    "    sae.metrics._add_more({\n",
    "        'orthogonality': {\n",
    "            'I_ortho_T': orthogonality[I_mask][:, T_mask].mean(),\n",
    "            'I_ortho_B': orthogonality[I_mask][:, B_mask].mean(),\n",
    "            'T_ortho_B': orthogonality[T_mask][:, B_mask].mean(),\n",
    "            'I_ortho_I': orthogonality[I_mask][:, I_mask].mean(),\n",
    "            'T_ortho_T': orthogonality[T_mask][:, T_mask].mean(),\n",
    "            'B_ortho_B': orthogonality[B_mask][:, B_mask].mean(),\n",
    "        }\n",
    "    }, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dict_orthogonality(SSAE, SSAE.metrics.mu)\n",
    "get_dict_orthogonality(ASAE, ASAE.metrics.mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4. Modality Gap & Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_modality_gap(I, T, sae, data_name=\"default\"):\n",
    "    # Measure the modality gap :\n",
    "    # - norm of difference in mean image and text embeddings\n",
    "    # - wasserstein distance between the image and text embeddings distributions.\n",
    "    N_subsample = int(1e4) # dataset has 1e6 images and texts, subsample to 1e4 for speed.\n",
    "    # raise\n",
    "    # # TODO : try modality gap wasserstein without \n",
    "    p1 = torch.randperm(I.shape[0])[:N_subsample]\n",
    "    p2 = torch.randperm(T.shape[0])[:N_subsample]\n",
    "    T = I[p2].cpu()\n",
    "    I = I[p1].cpu() # shape (N_subsample, D)\n",
    "    I_mean = I.mean(axis=0) # shape (D,)\n",
    "    T_mean = T.mean(axis=0)\n",
    "    DiM = np.linalg.norm(I_mean - T_mean)\n",
    "    c = metrics.Wasserstein(I, T, metric='cosim')\n",
    "    sae.metrics._add_more({\n",
    "        f\"modality_gap_{data_name}\": {\n",
    "            \"DiM\": DiM,\n",
    "            \"Wasserstein\": c,\n",
    "        }\n",
    "    }, save=True)\n",
    "\n",
    "def get_contrastive_loss(I, T, sae, data_name=\"default\"):\n",
    "    # Track Contrastive Loss & accuracy for Image-Text pairs\n",
    "    # TODO : retrain the logit_scale parameter to fit the data\n",
    "    batch_size = 256\n",
    "    num_batches = I.shape[0] // batch_size\n",
    "\n",
    "    class LogitScale(torch.nn.Module):\n",
    "        def __init__(self, initial_value=4.6052):\n",
    "            super(LogitScale, self).__init__()\n",
    "            self.logit_scale = torch.nn.Parameter(torch.tensor(initial_value))\n",
    "\n",
    "        def forward(self, x):\n",
    "            return torch.exp(self.logit_scale) * x\n",
    "    logit_scale = LogitScale()\n",
    "    optimizer = torch.optim.Adam(logit_scale.parameters(), lr=1e-3)\n",
    "\n",
    "    for ep in range(1, 3):\n",
    "        contrastive_loss = 0.0\n",
    "        correct_pairs = 0\n",
    "        total_pairs = 0\n",
    "        p = 0\n",
    "        for i in tqdm(range(num_batches)):\n",
    "            I_batch = I[i * batch_size:(i + 1) * batch_size]\n",
    "            T_batch = T[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "            # Compute cosine similarity\n",
    "            I_batch = I_batch / (I_batch.norm(dim=1, keepdim=True) + 1e-8)\n",
    "            T_batch = T_batch / (T_batch.norm(dim=1, keepdim=True) + 1e-8)\n",
    "            logits_per_image = I_batch @ T_batch.T\n",
    "            logits_per_text = T_batch @ I_batch.T\n",
    "\n",
    "            # logit_scale = torch.exp(torch.tensor(4.6052)) # from CLIP ViT-B/32\n",
    "\n",
    "            logits_per_image = logit_scale(logits_per_image)\n",
    "            logits_per_text = logit_scale(logits_per_text)\n",
    "\n",
    "            labels = torch.arange(batch_size, device=I_batch.device)\n",
    "            loss_image = F.cross_entropy(logits_per_image, labels)\n",
    "            loss_text = F.cross_entropy(logits_per_text, labels)\n",
    "            loss = (loss_image + loss_text) / 2\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            contrastive_loss += loss.item()\n",
    "\n",
    "            acc_image = (logits_per_image.argmax(dim=1) == labels).sum().item()\n",
    "            acc_text = (logits_per_text.argmax(dim=1) == labels).sum().item()\n",
    "            correct_pairs += (acc_image + acc_text) / 2\n",
    "            total_pairs += batch_size\n",
    "\n",
    "            # p : probability of correct labels\n",
    "            p_image = torch.softmax(logits_per_image, dim=1)\n",
    "            p_image = p_image[torch.arange(batch_size, device=I_batch.device), labels].mean().item()\n",
    "            p_text = torch.softmax(logits_per_text, dim=1)\n",
    "            p_text = p_text[torch.arange(batch_size, device=I_batch.device), labels].mean().item()\n",
    "            p += (p_image + p_text) / 2\n",
    "        contrastive_loss /= num_batches\n",
    "        accuracy = correct_pairs / total_pairs\n",
    "        print(f\"Contrastive Loss: {contrastive_loss:.4f}, Accuracy: {accuracy:.4f}, Probability: {p / num_batches:.4f}\")\n",
    "    sae.metrics._add_more({\n",
    "        f\"contrastive_loss_{data_name}\": {\n",
    "            \"loss\": contrastive_loss,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"probability\": p / num_batches,\n",
    "        }\n",
    "    }, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_modality_gap(train_loader.dataset.tensors[0], train_loader.dataset.tensors[1], SSAE)\n",
    "get_modality_gap(train_loader.dataset.tensors[0], train_loader.dataset.tensors[1], ASAE)\n",
    "\n",
    "get_contrastive_loss(train_loader.dataset.tensors[0], train_loader.dataset.tensors[1], SSAE)\n",
    "get_contrastive_loss(train_loader.dataset.tensors[0], train_loader.dataset.tensors[1], ASAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_modality_gap(I_bi_S, T_bi_S, SSAE, data_name=\"bimodal\")\n",
    "get_modality_gap(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "\n",
    "get_contrastive_loss(I_bi_S, T_bi_S, SSAE, data_name=\"bimodal\")\n",
    "get_contrastive_loss(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "\n",
    "I_ae_S, T_ae_S, B_ae_S = get_bimodal_data(SSAE, train_loader, SSAE.metrics.mu, device, eps=0.0)\n",
    "I_ae_A, T_ae_A, B_ae_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, eps=0.0)\n",
    "\n",
    "# plot_cosim_histogram(I_ae_S, T_ae_S, B_ae_S, SSAE_name, subtitle=\"AE\")\n",
    "# plot_cosim_histogram(I_ae_A, T_ae_A, B_ae_A, ASAE_name, subtitle=\"AE\")\n",
    "# fit_and_plot_pca(I_ae_S, T_ae_S, B_ae_S, SSAE_name, save_title='data_ae_pca_pc1_pc2')\n",
    "# fit_and_plot_pca(I_ae_A, T_ae_A, B_ae_A, ASAE_name, save_title='data_ae_pca_pc1_pc2')\n",
    "get_modality_gap(I_ae_S, T_ae_S, SSAE, data_name=\"AE\")\n",
    "get_modality_gap(I_ae_A, T_ae_A, ASAE, data_name=\"AE\")\n",
    "get_contrastive_loss(I_ae_S, T_ae_S, SSAE, data_name=\"AE\")\n",
    "get_contrastive_loss(I_ae_A, T_ae_A, ASAE, data_name=\"AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SSAE metrics:\")\n",
    "print(SSAE.metrics)\n",
    "print(\"ASAE metrics:\")\n",
    "print(ASAE.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_uni_S, T_uni_S, B_uni_S = get_bimodal_data(SSAE, train_loader, SSAE.metrics.mu, device, complement=True)\n",
    "I_uni_A, T_uni_A, B_uni_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True)\n",
    "get_modality_gap(I_uni_S, T_uni_S, SSAE, data_name=\"unimodal\")\n",
    "get_modality_gap(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "\n",
    "get_contrastive_loss(I_uni_S, T_uni_S, SSAE, data_name=\"unimodal\")\n",
    "get_contrastive_loss(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_bridge_S, T_bridge_S, B_bridge_S = get_bimodal_data(SSAE, train_loader, SSAE.metrics.mu, device, complement=False, use_E_B=True, tau=0.05)\n",
    "I_bridge_A, T_bridge_A, B_bridge_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=False, use_E_B=True, tau=0.05)\n",
    "get_modality_gap(I_bridge_S, T_bridge_S, SSAE, data_name=\"bridge\")\n",
    "get_modality_gap(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "\n",
    "get_contrastive_loss(I_bridge_S, T_bridge_S, SSAE, data_name=\"bridge\")\n",
    "get_contrastive_loss(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_bridge_C_S, T_bridge_C_S, B_bridge_C_S = get_bimodal_data(SSAE, train_loader, SSAE.metrics.mu, device, complement=True, use_E_B=True, tau=0.31)\n",
    "I_bridge_C_A, T_bridge_C_A, B_bridge_C_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True, use_E_B=True, tau=0.31)\n",
    "get_modality_gap(I_bridge_C_S, T_bridge_C_S, SSAE, data_name=\"bridge_C\")\n",
    "get_modality_gap(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "\n",
    "get_contrastive_loss(I_bridge_C_S, T_bridge_C_S, SSAE, data_name=\"bridge_C\")\n",
    "get_contrastive_loss(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SSAE.metrics)\n",
    "print(ASAE.metrics)\n",
    "\n",
    "# torch.save(SSAE.metrics, f\"./figures/{SSAE_name.replace('.pt', '')}/metrics.pt\")\n",
    "# torch.save(ASAE.metrics, f\"./figures/{ASAE_name.replace('.pt', '')}/metrics.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = None\n",
    "best_bi_acc = 0\n",
    "for i in range(10):\n",
    "    ASAE, ASAE_name = __train(beta=5e-4, force_retrain=True, save_quand_meme=True) # Aligned SAE\n",
    "    ASAE.metrics = measure_everything(ASAE, train_loader, device, return_sqr=True)\n",
    "    ASAE_bridge = {\n",
    "        \"bridge_sigma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False).cpu().detach(),\n",
    "        # \"bridge_sigma_null_C\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=True, null_D=False).cpu().detach(),\n",
    "        # \"bridge_sigma_null_D\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=True).cpu().detach(),\n",
    "        \"bridge_sigma_null\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=True, null_D=True).cpu().detach(),\n",
    "    }\n",
    "    _prune_bridge(ASAE_bridge[\"bridge_sigma\"], ASAE_bridge[\"bridge_sigma_null\"])\n",
    "    get_bridge_norms(ASAE_bridge[\"bridge_sigma\"], ASAE.metrics.mu, ASAE.metrics.E, ASAE_name, ASAE)\n",
    "\n",
    "    I_bi_A, T_bi_A, B_bi_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device)\n",
    "    I_uni_A, T_uni_A, B_uni_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True)\n",
    "    I_bridge_A, T_bridge_A, B_bridge_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=False, use_E_B=True)\n",
    "    I_bridge_C_A, T_bridge_C_A, B_bridge_C_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True, use_E_B=True)\n",
    "\n",
    "    # get_modality_gap(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    # get_modality_gap(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    # get_modality_gap(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    # get_modality_gap(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    get_contrastive_loss(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    get_contrastive_loss(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    get_contrastive_loss(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    get_contrastive_loss(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    print(ASAE.metrics)\n",
    "    bi_acc = ASAE.metrics.contrastive_loss_bimodal['accuracy']\n",
    "    uni_acc = ASAE.metrics.contrastive_loss_unimodal['accuracy']\n",
    "    bridge_acc = ASAE.metrics.contrastive_loss_bridge['accuracy']\n",
    "    bridge_C_acc = ASAE.metrics.contrastive_loss_bridge_C['accuracy']\n",
    "    print(f\"Iteration {i+1} - Bimodal Acc: {bi_acc:.4f}, Unimodal Acc: {uni_acc:.4f}, Bridge Acc: {bridge_acc:.4f}, Bridge C Acc: {bridge_C_acc:.4f}\")\n",
    "    if bi_acc > best_bi_acc:\n",
    "        best_bi_acc = bi_acc\n",
    "        best = ASAE\n",
    "        print(f\"New best model found with Bimodal Acc: {best_bi_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sae, m in zip(all_saes, all_metrics):\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchTopK, MP\n",
    "all_metrics = []\n",
    "all_saes = []\n",
    "for useTopK in [False]:#, False]:\n",
    "    print(f\"Training with useTopK={useTopK}\")\n",
    "    top_k = 50\n",
    "    expansion = 64\n",
    "    lr = 1e-4\n",
    "    epochs = 25\n",
    "    ASAE, ASAE_name, logs = __train(beta=0e-4, force_retrain=True, save_quand_meme=True, UseTOPK=useTopK, top_k=top_k, expansion_factor=expansion, epochs=epochs, lr=lr) # Aligned SAE\n",
    "    ASAE.metrics = measure_everything(ASAE, train_loader, device, return_sqr=True)\n",
    "    print(f\"Proportion of energy in bimodal concepts: {ASAE.metrics.E_in_B:.4f}\")\n",
    "    ASAE_bridge = {\n",
    "        \"bridge_sigma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False).cpu().detach(),\n",
    "        \"bridge_gamma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "    }\n",
    "    \n",
    "    get_sparse_reconstruction_metrics(ASAE, train_loader)\n",
    "    get_C_metrics(ASAE, train_loader, top_k=top_k)\n",
    "\n",
    "    # SSAE.metrics._add_more(get_stability_beta(train_loader, beta=0e-4), save=True)\n",
    "    # ASAE.metrics._add_more(get_stability_beta(train_loader, beta=5e-4), save=True)\n",
    "\n",
    "    get_D_structure_metrics(ASAE)\n",
    "    # get_Z_structure_metrics(ASAE, train_loader)\n",
    "    \n",
    "    get_bridge_norms(ASAE_bridge[\"bridge_sigma\"], ASAE.metrics.mu, ASAE.metrics.E, ASAE_name, ASAE)\n",
    "    print(\"Got bridge norms for ASAE\")\n",
    "    plot_bridge_mass_vs_eps(ASAE_bridge[\"bridge_gamma\"], f\"rzegzeg\", f\"bridge_mass_vs_eps_gamma\", ASAE_name, ASAE.metrics.mu, ASAE.metrics.E, ASAE, weight_type=\"gamma\", skip_plot=True)\n",
    "    get_rho(ASAE)\n",
    "    data_classifiability(ASAE, ASAE_name, eps=0.05, skip_plot=True)\n",
    "    \n",
    "    I_bi_A, T_bi_A, B_bi_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device)\n",
    "    I_uni_A, T_uni_A, B_uni_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True)\n",
    "    I_bridge_A, T_bridge_A, B_bridge_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=False, use_E_B=True)\n",
    "    I_bridge_C_A, T_bridge_C_A, B_bridge_C_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True, use_E_B=True)\n",
    "    print(\"Got bimodal data for ASAE\")\n",
    "    get_modality_gap(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    # get_modality_gap(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    # get_modality_gap(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    # get_modality_gap(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    get_contrastive_loss(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    get_contrastive_loss(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    get_contrastive_loss(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    get_contrastive_loss(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    print(ASAE.metrics)\n",
    "    all_metrics.append(ASAE.metrics)\n",
    "    all_saes.append(ASAE)\n",
    "    bi_acc = ASAE.metrics.contrastive_loss_bimodal['accuracy']\n",
    "    # uni_acc = ASAE.metrics.contrastive_loss_unimodal['accuracy']\n",
    "    # bridge_acc = ASAE.metrics.contrastive_loss_bridge['accuracy']\n",
    "    # bridge_C_acc = ASAE.metrics.contrastive_loss_bridge_C['accuracy']\n",
    "    # print(f\"Iteration {i+1} - Bimodal Acc: {bi_acc:.4f}, Unimodal Acc: {uni_acc:.4f}, Bridge Acc: {bridge_acc:.4f}, Bridge C Acc: {bridge_C_acc:.4f}\")\n",
    "\n",
    "print(all_metrics)\n",
    "all_metrics_architecture = all_metrics\n",
    "all_saes_architecture = all_saes\n",
    "os.makedirs(\"./temporary_save\", exist_ok=True)\n",
    "torch.save(all_metrics_architecture, f\"./temporary_save/all_metrics_architecture.pt\")\n",
    "torch.save(all_saes_architecture, f\"./temporary_save/all_saes_architecture.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TopK :\n",
    "\n",
    "print(f\"Training with TopK\")\n",
    "nb_concepts = 512 * 8\n",
    "top_k = 20\n",
    "d_model = 512\n",
    "\n",
    "sae = overcomplete.sae.TopKSAE(d_model, nb_concepts=nb_concepts, top_k=top_k, device=device)\n",
    "# copy_dict_weights = sae.dictionary._weights.clone().detach()\n",
    "# sae.encoder.final_block[0].weight.data.copy_(copy_dict_weights)\n",
    "alpha = 1e-3  # Dead features loss penalty\n",
    "\n",
    "def _criterion(x, x_hat, pre_codes, codes, dictionary):\n",
    "    # here we directly use the thresholds of the model to control the sparsity\n",
    "    loss = (x - x_hat).square().mean()\n",
    "\n",
    "    is_dead = ((codes > 0).sum(dim=0) == 0).float().detach()\n",
    "    # we push the pre_codes (before relu) towards the positive orthant\n",
    "    reanim_loss = (pre_codes * is_dead[None, :]).mean()\n",
    "\n",
    "    loss -= reanim_loss * alpha\n",
    "\n",
    "    return loss\n",
    "criterion_1 = _criterion\n",
    "\n",
    "sae.to(device)\n",
    "sae.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(sae.parameters(), lr=5e-4)\n",
    "criterion_2 = lambda *args, **kwargs: losses.alignment_penalty(*args, **kwargs, penalty=0, alignment_metric='cosim')\n",
    "criterion = lambda *args, **kwargs: criterion_1(*args, **kwargs) + criterion_2(*args, **kwargs)\n",
    "\n",
    "scheduler=None\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=5e-4, total_steps=5 * steps_per_epoch,\n",
    ")\n",
    "\n",
    "alpha_name = str(alpha).replace('.', '')\n",
    "beta_name = str(0).replace('.', '')\n",
    "\n",
    "CENTER_DATASET = False if 'CENTER_DATASET' not in locals() else CENTER_DATASET\n",
    "sae_name = f\"{DATASET}_{\"TopK\"}_centered_{CENTER_DATASET}_{8}_L0_{top_k}_alpha\" + alpha_name + \"beta\" + beta_name + \".pt\"\n",
    "print(f\"Model name: {sae_name}\")\n",
    "\n",
    "logs = train.train_multimodal_sae(\n",
    "    sae, train_loader, criterion, optimizer, scheduler=scheduler, nb_epochs=5, device=device,\n",
    "    monitoring=1, verbose=False,\n",
    "    checkpoint_path=\"./checkpoints/\",\n",
    "    checkpoint_interval=5, checkpoint_name=sae_name,\n",
    ")\n",
    "ASAE = sae\n",
    "ASAE_name = sae_name\n",
    "\n",
    "ASAE.metrics = measure_everything(ASAE, train_loader, device, return_sqr=True)\n",
    "# ASAE = best_\n",
    "ASAE_bridge = {\n",
    "    \"bridge_sigma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False).cpu().detach(),\n",
    "    \"bridge_gamma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "}\n",
    "\n",
    "get_sparse_reconstruction_metrics(ASAE, train_loader)\n",
    "get_C_metrics(ASAE, train_loader, top_k=top_k)\n",
    "\n",
    "# SSAE.metrics._add_more(get_stability_beta(train_loader, beta=0e-4), save=True)\n",
    "# ASAE.metrics._add_more(get_stability_beta(train_loader, beta=5e-4), save=True)\n",
    "\n",
    "get_D_structure_metrics(ASAE)\n",
    "get_Z_structure_metrics(ASAE, train_loader)\n",
    "\n",
    "get_bridge_norms(ASAE_bridge[\"bridge_sigma\"], ASAE.metrics.mu, ASAE.metrics.E, ASAE_name, ASAE)\n",
    "print(\"Got bridge norms for ASAE\")\n",
    "plot_bridge_mass_vs_eps(ASAE_bridge[\"bridge_gamma\"], f\"rzegzeg\", f\"bridge_mass_vs_eps_gamma\", ASAE_name, ASAE.metrics.mu, ASAE.metrics.E, ASAE, weight_type=\"gamma\", skip_plot=True)\n",
    "get_rho(ASAE)\n",
    "data_classifiability(ASAE, ASAE_name, eps=0.05, skip_plot=True)\n",
    "    \n",
    "I_bi_A, T_bi_A, B_bi_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device)\n",
    "I_uni_A, T_uni_A, B_uni_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True)\n",
    "I_bridge_A, T_bridge_A, B_bridge_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=False, use_E_B=True)\n",
    "I_bridge_C_A, T_bridge_C_A, B_bridge_C_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True, use_E_B=True)\n",
    "print(\"Got bimodal data for ASAE\")\n",
    "get_modality_gap(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "# get_modality_gap(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "# get_modality_gap(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "# get_modality_gap(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "get_contrastive_loss(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "get_contrastive_loss(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "get_contrastive_loss(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "get_contrastive_loss(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "print(ASAE.metrics)\n",
    "all_metrics.append(ASAE.metrics)\n",
    "all_saes.append(ASAE)\n",
    "bi_acc = ASAE.metrics.contrastive_loss_bimodal['accuracy']\n",
    "# uni_acc = ASAE.metrics.contrastive_loss_unimodal['accuracy']\n",
    "# bridge_acc = ASAE.metrics.contrastive_loss_bridge['accuracy']\n",
    "# bridge_C_acc = ASAE.metrics.contrastive_loss_bridge_C['accuracy']\n",
    "# print(f\"Iteration {i+1} - Bimodal Acc: {bi_acc:.4f}, Unimodal Acc: {uni_acc:.4f}, Bridge Acc: {bridge_acc:.4f}, Bridge C Acc: {bridge_C_acc:.4f}\")\n",
    "\n",
    "print(all_metrics)\n",
    "all_metrics_architecture = all_metrics\n",
    "all_saes_architecture = all_saes\n",
    "os.makedirs(\"./temporary_save\", exist_ok=True)\n",
    "torch.save(all_metrics_architecture, f\"./temporary_save/all_metrics_architecture.pt\")\n",
    "torch.save(all_saes_architecture, f\"./temporary_save/all_saes_architecture.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JumpReLU :\n",
    "\n",
    "print(f\"Training with JumpReLU\")\n",
    "nb_concepts = 512 * 8\n",
    "top_k = 20\n",
    "d_model = 512\n",
    "\n",
    "def _criterion(x, x_hat, pre_codes, codes, dictionary):\n",
    "    # here we directly use the thresholds of the model to control the sparsity\n",
    "    loss = (x - x_hat).square().mean()\n",
    "\n",
    "    sparsity = (codes > 0).float().mean().detach()\n",
    "    if sparsity > desired_sparsity:\n",
    "      # if we are not sparse enough, increase the thresholds levels\n",
    "      loss -= sae.thresholds.sum()\n",
    "      \n",
    "    is_dead = ((codes > 0).sum(dim=0) == 0).float().detach()\n",
    "    # we push the pre_codes (before relu) towards the positive orthant\n",
    "    reanim_loss = (pre_codes * is_dead[None, :]).mean()\n",
    "\n",
    "    loss -= reanim_loss * 1e-3\n",
    "\n",
    "    return loss\n",
    "\n",
    "sae = overcomplete.sae.JumpSAE(d_model, nb_concepts=nb_concepts, device=device)\n",
    "alpha = 0.0\n",
    "criterion_1 = lambda *args, **kwargs: _criterion(*args, **kwargs)\n",
    "\n",
    "desired_sparsity = top_k / nb_concepts\n",
    "\n",
    "sae.to(device)\n",
    "sae.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(sae.parameters(), lr=5e-4)\n",
    "criterion_2 = lambda *args, **kwargs: losses.alignment_penalty(*args, **kwargs, penalty=0, alignment_metric='cosim')\n",
    "criterion = lambda *args, **kwargs: criterion_1(*args, **kwargs) + criterion_2(*args, **kwargs)\n",
    "\n",
    "scheduler=None\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=5e-4, total_steps=5 * steps_per_epoch,\n",
    ")\n",
    "\n",
    "alpha_name = str(alpha).replace('.', '')\n",
    "beta_name = str(0).replace('.', '')\n",
    "\n",
    "CENTER_DATASET = False if 'CENTER_DATASET' not in locals() else CENTER_DATASET\n",
    "sae_name = f\"{DATASET}_{\"JumpReLU\"}_centered_{CENTER_DATASET}_{8}_L0_{top_k}_alpha\" + alpha_name + \"beta\" + beta_name + \".pt\"\n",
    "print(f\"Model name: {sae_name}\")\n",
    "\n",
    "logs = train.train_multimodal_sae(\n",
    "    sae, train_loader, criterion, optimizer, scheduler=scheduler, nb_epochs=5, device=device,\n",
    "    monitoring=1, verbose=False,\n",
    "    checkpoint_path=\"./checkpoints/\",\n",
    "    checkpoint_interval=5, checkpoint_name=sae_name,\n",
    ")\n",
    "ASAE = sae\n",
    "ASAE_name = sae_name\n",
    "\n",
    "ASAE.metrics = measure_everything(ASAE, train_loader, device, return_sqr=True)\n",
    "# ASAE = best_\n",
    "ASAE_bridge = {\n",
    "    \"bridge_sigma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False).cpu().detach(),\n",
    "    \"bridge_gamma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "}\n",
    "\n",
    "get_sparse_reconstruction_metrics(ASAE, train_loader)\n",
    "get_C_metrics(ASAE, train_loader, top_k=50)\n",
    "\n",
    "# SSAE.metrics._add_more(get_stability_beta(train_loader, beta=0e-4), save=True)\n",
    "# ASAE.metrics._add_more(get_stability_beta(train_loader, beta=5e-4), save=True)\n",
    "\n",
    "get_D_structure_metrics(ASAE)\n",
    "get_Z_structure_metrics(ASAE, train_loader)\n",
    "\n",
    "get_bridge_norms(ASAE_bridge[\"bridge_sigma\"], ASAE.metrics.mu, ASAE.metrics.E, ASAE_name, ASAE)\n",
    "print(\"Got bridge norms for ASAE\")\n",
    "plot_bridge_mass_vs_eps(ASAE_bridge[\"bridge_gamma\"], f\"rzegzeg\", f\"bridge_mass_vs_eps_gamma\", ASAE_name, ASAE.metrics.mu, ASAE.metrics.E, ASAE, weight_type=\"gamma\", skip_plot=True)\n",
    "get_rho(ASAE)\n",
    "data_classifiability(ASAE, ASAE_name, eps=0.05, skip_plot=True)\n",
    "\n",
    "I_bi_A, T_bi_A, B_bi_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device)\n",
    "I_uni_A, T_uni_A, B_uni_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True)\n",
    "I_bridge_A, T_bridge_A, B_bridge_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=False, use_E_B=True)\n",
    "I_bridge_C_A, T_bridge_C_A, B_bridge_C_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True, use_E_B=True)\n",
    "print(\"Got bimodal data for ASAE\")\n",
    "get_modality_gap(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "# get_modality_gap(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "# get_modality_gap(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "# get_modality_gap(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "get_contrastive_loss(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "get_contrastive_loss(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "get_contrastive_loss(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "get_contrastive_loss(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "print(ASAE.metrics)\n",
    "all_metrics.append(ASAE.metrics)\n",
    "all_saes.append(ASAE)\n",
    "bi_acc = ASAE.metrics.contrastive_loss_bimodal['accuracy']\n",
    "# uni_acc = ASAE.metrics.contrastive_loss_unimodal['accuracy']\n",
    "# bridge_acc = ASAE.metrics.contrastive_loss_bridge['accuracy']\n",
    "# bridge_C_acc = ASAE.metrics.contrastive_loss_bridge_C['accuracy']\n",
    "# print(f\"Iteration {i+1} - Bimodal Acc: {bi_acc:.4f}, Unimodal Acc: {uni_acc:.4f}, Bridge Acc: {bridge_acc:.4f}, Bridge C Acc: {bridge_C_acc:.4f}\")\n",
    "\n",
    "print(all_metrics)\n",
    "all_metrics_architecture = all_metrics\n",
    "all_saes_architecture = all_saes\n",
    "os.makedirs(\"./temporary_save\", exist_ok=True)\n",
    "torch.save(all_metrics_architecture, f\"./temporary_save/all_metrics_architecture.pt\")\n",
    "torch.save(all_saes_architecture, f\"./temporary_save/all_saes_architecture.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4e-4, L_align\n",
    "best_ = None\n",
    "best_bi_acc_ = 0\n",
    "best_record = []\n",
    "best_times = []\n",
    "all_metrics = []\n",
    "all_saes = []\n",
    "i = 0\n",
    "for _ in range(10):\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        print(f\"Iteration {i+1} - Training ASAE with beta=2e-4\")\n",
    "        print(f\"Current best Bimodal Acc: {best_bi_acc_:.4f}. Corresponding Unimodal Acc: {best_.metrics.contrastive_loss_unimodal['accuracy']:.4f}, Bridge Acc: {best_.metrics.contrastive_loss_bridge['accuracy']:.4f}, Bridge C Acc: {best_.metrics.contrastive_loss_bridge_C['accuracy']:.4f}\")\n",
    "        print(f\"Recorded best Bimodal Accs: {best_record}, at iterations: {best_times}\")\n",
    "    ASAE, ASAE_name = __train(beta=4e-4, force_retrain=True) # Aligned SAE\n",
    "    ASAE.metrics = measure_everything(ASAE, train_loader, device, return_sqr=True)\n",
    "    # ASAE = best_\n",
    "    ASAE_bridge = {\n",
    "        \"bridge_sigma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False).cpu().detach(),\n",
    "        \"bridge_gamma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "    }\n",
    "    get_bridge_norms(ASAE_bridge[\"bridge_sigma\"], ASAE.metrics.mu, ASAE.metrics.E, ASAE_name, ASAE)\n",
    "    print(\"Got bridge norms for ASAE\")\n",
    "    plot_bridge_mass_vs_eps(ASAE_bridge[\"bridge_gamma\"], f\"rzegzeg\", f\"bridge_mass_vs_eps_gamma\", ASAE_name, ASAE.metrics.mu, ASAE.metrics.E, ASAE, weight_type=\"gamma\", skip_plot=True)\n",
    "    get_rho(ASAE)\n",
    "    data_classifiability(ASAE, ASAE_name, eps=0.05, skip_plot=True)\n",
    "    \n",
    "    I_bi_A, T_bi_A, B_bi_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device)\n",
    "    I_uni_A, T_uni_A, B_uni_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True)\n",
    "    I_bridge_A, T_bridge_A, B_bridge_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=False, use_E_B=True)\n",
    "    I_bridge_C_A, T_bridge_C_A, B_bridge_C_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True, use_E_B=True)\n",
    "    print(\"Got bimodal data for ASAE\")\n",
    "    get_modality_gap(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    # get_modality_gap(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    # get_modality_gap(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    # get_modality_gap(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    get_contrastive_loss(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    get_contrastive_loss(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    get_contrastive_loss(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    get_contrastive_loss(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    print(ASAE.metrics)\n",
    "    all_metrics.append(ASAE.metrics)\n",
    "    all_saes.append(ASAE)\n",
    "    bi_acc = ASAE.metrics.contrastive_loss_bimodal['accuracy']\n",
    "    # uni_acc = ASAE.metrics.contrastive_loss_unimodal['accuracy']\n",
    "    # bridge_acc = ASAE.metrics.contrastive_loss_bridge['accuracy']\n",
    "    # bridge_C_acc = ASAE.metrics.contrastive_loss_bridge_C['accuracy']\n",
    "    # print(f\"Iteration {i+1} - Bimodal Acc: {bi_acc:.4f}, Unimodal Acc: {uni_acc:.4f}, Bridge Acc: {bridge_acc:.4f}, Bridge C Acc: {bridge_C_acc:.4f}\")\n",
    "    if bi_acc > best_bi_acc_:\n",
    "        best_bi_acc_ = bi_acc\n",
    "        best_ = ASAE\n",
    "        print(f\"New best model found with Bimodal Acc: {best_bi_acc_:.4f}\")\n",
    "        checkpoint = {\n",
    "            'model_state_dict': best_.state_dict(),\n",
    "            'logs': None\n",
    "        }\n",
    "\n",
    "        # check that checkpoint_path exists, otherwise create it\n",
    "        checkpoint_path = f\"./checkpoints/\"\n",
    "        checkpoint_name = ASAE_name.replace('.pt', '_best.pt')\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            os.makedirs(checkpoint_path)\n",
    "        torch.save(checkpoint, f\"{checkpoint_path}/{checkpoint_name}\")\n",
    "        best_record.append(best_bi_acc_)\n",
    "        best_times.append(i)\n",
    "\n",
    "print(all_metrics)\n",
    "all_metrics_L_align = all_metrics\n",
    "all_saes_L_align = all_saes\n",
    "os.makedirs(\"./temporary_save\", exist_ok=True)\n",
    "torch.save(all_metrics_L_align, f\"./temporary_save/all_metrics_L_align.pt\")\n",
    "torch.save(all_saes_L_align, f\"./temporary_save/all_saes_L_align.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_L_align = torch.load(f\"./temporary_save/all_metrics_L_align.pt\")\n",
    "for i, m in enumerate(metrics_L_align):\n",
    "    print(f\"\\nMetrics {i+1}:\")\n",
    "    print(f\"% of E in bimodal: {m.E_in_B:.4f}\")\n",
    "    print(f\"rho: {m.rho:.4f}\")\n",
    "    print(f\"p_acc: {m.data_cassifiability[\"feature_probe\"]:.3f}\")\n",
    "    print(f\"delta_acc bimodal: {m.contrastive_loss_bimodal['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4e-4 L_align'\n",
    "\n",
    "best_ = None\n",
    "best_bi_acc_ = 0\n",
    "best_record = []\n",
    "best_times = []\n",
    "all_metrics = []\n",
    "all_saes = []\n",
    "i = 0\n",
    "for _ in range(10):\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        print(f\"Iteration {i+1} - Training ASAE with beta=2e-4\")\n",
    "        print(f\"Current best Bimodal Acc: {best_bi_acc_:.4f}. Corresponding Unimodal Acc: {best_.metrics.contrastive_loss_unimodal['accuracy']:.4f}, Bridge Acc: {best_.metrics.contrastive_loss_bridge['accuracy']:.4f}, Bridge C Acc: {best_.metrics.contrastive_loss_bridge_C['accuracy']:.4f}\")\n",
    "        print(f\"Recorded best Bimodal Accs: {best_record}, at iterations: {best_times}\")\n",
    "    ASAE, ASAE_name = __train(beta=4e-4, force_retrain=True, criterion_2_fct=losses.alignment_penalty_prime) # Aligned SAE\n",
    "    ASAE.metrics = measure_everything(ASAE, train_loader, device, return_sqr=True)\n",
    "    # ASAE = best_\n",
    "    ASAE_bridge = {\n",
    "        \"bridge_sigma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False).cpu().detach(),\n",
    "        \"bridge_gamma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "    }\n",
    "    get_bridge_norms(ASAE_bridge[\"bridge_sigma\"], ASAE.metrics.mu, ASAE.metrics.E, ASAE_name, ASAE)\n",
    "    print(\"Got bridge norms for ASAE\")\n",
    "    plot_bridge_mass_vs_eps(ASAE_bridge[\"bridge_gamma\"], f\"rzegzeg\", f\"bridge_mass_vs_eps_gamma\", ASAE_name, ASAE.metrics.mu, ASAE.metrics.E, ASAE, weight_type=\"gamma\", skip_plot=True)\n",
    "    get_rho(ASAE)\n",
    "    data_classifiability(ASAE, ASAE_name, eps=0.05, skip_plot=True)\n",
    "    \n",
    "    I_bi_A, T_bi_A, B_bi_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device)\n",
    "    I_uni_A, T_uni_A, B_uni_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True)\n",
    "    I_bridge_A, T_bridge_A, B_bridge_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=False, use_E_B=True)\n",
    "    I_bridge_C_A, T_bridge_C_A, B_bridge_C_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True, use_E_B=True)\n",
    "    print(\"Got bimodal data for ASAE\")\n",
    "    get_modality_gap(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    # get_modality_gap(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    # get_modality_gap(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    # get_modality_gap(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    get_contrastive_loss(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    get_contrastive_loss(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    get_contrastive_loss(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    get_contrastive_loss(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    print(ASAE.metrics)\n",
    "    all_metrics.append(ASAE.metrics)\n",
    "    all_saes.append(ASAE)\n",
    "    bi_acc = ASAE.metrics.contrastive_loss_bimodal['accuracy']\n",
    "    # uni_acc = ASAE.metrics.contrastive_loss_unimodal['accuracy']\n",
    "    # bridge_acc = ASAE.metrics.contrastive_loss_bridge['accuracy']\n",
    "    # bridge_C_acc = ASAE.metrics.contrastive_loss_bridge_C['accuracy']\n",
    "    # print(f\"Iteration {i+1} - Bimodal Acc: {bi_acc:.4f}, Unimodal Acc: {uni_acc:.4f}, Bridge Acc: {bridge_acc:.4f}, Bridge C Acc: {bridge_C_acc:.4f}\")\n",
    "    if bi_acc > best_bi_acc_:\n",
    "        best_bi_acc_ = bi_acc\n",
    "        best_ = ASAE\n",
    "        print(f\"New best model found with Bimodal Acc: {best_bi_acc_:.4f}\")\n",
    "        checkpoint = {\n",
    "            'model_state_dict': best_.state_dict(),\n",
    "            'logs': None\n",
    "        }\n",
    "\n",
    "        # check that checkpoint_path exists, otherwise create it\n",
    "        checkpoint_path = f\"./checkpoints/\"\n",
    "        checkpoint_name = ASAE_name.replace('.pt', '_best.pt')\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            os.makedirs(checkpoint_path)\n",
    "        torch.save(checkpoint, f\"{checkpoint_path}/{checkpoint_name}\")\n",
    "        best_record.append(best_bi_acc_)\n",
    "        best_times.append(i)\n",
    "\n",
    "print(all_metrics)\n",
    "all_metrics_L_align_prime = all_metrics\n",
    "all_saes_L_align_prime = all_saes\n",
    "torch.save(all_metrics_L_align_prime, f\"./temporary_save/all_metrics_L_align_prime.pt\")\n",
    "torch.save(all_saes_L_align_prime, f\"./temporary_save/all_saes_L_align_prime.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_L_align_prime = torch.load(f\"./temporary_save/all_metrics_L_align_prime.pt\")\n",
    "for i, m in enumerate(metrics_L_align):\n",
    "    print(f\"\\nMetrics {i+1}:\")\n",
    "    print(f\"% of E in bimodal: {m.E_in_B:.4f}\")\n",
    "    print(f\"rho: {m.rho:.4f}\")\n",
    "    print(f\"p_acc: {m.data_cassifiability[\"feature_probe\"]:.3f}\")\n",
    "    print(f\"delta_acc bimodal: {m.contrastive_loss_bimodal['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ = None\n",
    "best_bi_acc_ = 0\n",
    "best_record = []\n",
    "best_times = []\n",
    "all_metrics = []\n",
    "all_saes = []\n",
    "i = 0\n",
    "import importlib\n",
    "import losses\n",
    "importlib.reload(losses)\n",
    "for _ in range(10):\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        print(f\"Iteration {i+1} - Training ASAE with beta=2e-4\")\n",
    "        print(f\"Current best Bimodal Acc: {best_bi_acc_:.4f}. Corresponding Unimodal Acc: {best_.metrics.contrastive_loss_unimodal['accuracy']:.4f}, Bridge Acc: {best_.metrics.contrastive_loss_bridge['accuracy']:.4f}, Bridge C Acc: {best_.metrics.contrastive_loss_bridge_C['accuracy']:.4f}\")\n",
    "        print(f\"Recorded best Bimodal Accs: {best_record}, at iterations: {best_times}\")\n",
    "    beta = 2e-4\n",
    "    ASAE, ASAE_name = __train(beta=beta, force_retrain=True, criterion_2_fct=losses.alignment_penalty_distribution) # Aligned SAE\n",
    "    ASAE.metrics = measure_everything(ASAE, train_loader, device, return_sqr=True)\n",
    "    print(f\"ASAE metrics: {ASAE.metrics}\")\n",
    "    # ASAE = best_\n",
    "    ASAE_bridge = {\n",
    "        \"bridge_sigma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False).cpu().detach(),\n",
    "        \"bridge_gamma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "    }\n",
    "    get_bridge_norms(ASAE_bridge[\"bridge_sigma\"], ASAE.metrics.mu, ASAE.metrics.E, ASAE_name, ASAE)\n",
    "    print(\"Got bridge norms for ASAE\")\n",
    "    plot_bridge_mass_vs_eps(ASAE_bridge[\"bridge_gamma\"], f\"rzegzeg\", f\"bridge_mass_vs_eps_gamma\", ASAE_name, ASAE.metrics.mu, ASAE.metrics.E, ASAE, weight_type=\"gamma\", skip_plot=True)\n",
    "    get_rho(ASAE)\n",
    "    data_classifiability(ASAE, ASAE_name, eps=0.05, skip_plot=True)\n",
    "    \n",
    "    I_bi_A, T_bi_A, B_bi_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device)\n",
    "    I_uni_A, T_uni_A, B_uni_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True)\n",
    "    I_bridge_A, T_bridge_A, B_bridge_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=False, use_E_B=True)\n",
    "    I_bridge_C_A, T_bridge_C_A, B_bridge_C_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True, use_E_B=True)\n",
    "    print(\"Got bimodal data for ASAE\")\n",
    "    get_modality_gap(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    # get_modality_gap(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    # get_modality_gap(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    # get_modality_gap(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    get_contrastive_loss(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    get_contrastive_loss(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    get_contrastive_loss(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    get_contrastive_loss(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    print(ASAE.metrics)\n",
    "    all_metrics.append(ASAE.metrics)\n",
    "    all_saes.append(ASAE)\n",
    "    bi_acc = ASAE.metrics.contrastive_loss_bimodal['accuracy']\n",
    "    # uni_acc = ASAE.metrics.contrastive_loss_unimodal['accuracy']\n",
    "    # bridge_acc = ASAE.metrics.contrastive_loss_bridge['accuracy']\n",
    "    # bridge_C_acc = ASAE.metrics.contrastive_loss_bridge_C['accuracy']\n",
    "    # print(f\"Iteration {i+1} - Bimodal Acc: {bi_acc:.4f}, Unimodal Acc: {uni_acc:.4f}, Bridge Acc: {bridge_acc:.4f}, Bridge C Acc: {bridge_C_acc:.4f}\")\n",
    "    if bi_acc > best_bi_acc_:\n",
    "        best_bi_acc_ = bi_acc\n",
    "        best_ = ASAE\n",
    "        print(f\"New best model found with Bimodal Acc: {best_bi_acc_:.4f}\")\n",
    "        checkpoint = {\n",
    "            'model_state_dict': best_.state_dict(),\n",
    "            'logs': None\n",
    "        }\n",
    "\n",
    "        # check that checkpoint_path exists, otherwise create it\n",
    "        checkpoint_path = f\"./checkpoints/\"\n",
    "        checkpoint_name = ASAE_name.replace('.pt', '_best.pt')\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            os.makedirs(checkpoint_path)\n",
    "        torch.save(checkpoint, f\"{checkpoint_path}/{checkpoint_name}\")\n",
    "        best_record.append(best_bi_acc_)\n",
    "        best_times.append(i)\n",
    "\n",
    "print(all_metrics)\n",
    "all_metrics_L_align_dist = all_metrics\n",
    "all_saes_L_align_dist = all_saes\n",
    "torch.save(all_metrics_L_align_dist, f\"./temporary_save/all_metrics_L_align_dist.pt\")\n",
    "torch.save(all_saes_L_align_dist, f\"./temporary_save/all_saes_L_align_dist.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ = None\n",
    "best_bi_acc_ = 0\n",
    "best_record = []\n",
    "best_times = []\n",
    "all_metrics = []\n",
    "all_saes = []\n",
    "i = 0\n",
    "import importlib\n",
    "import losses\n",
    "losses = importlib.reload(losses)\n",
    "for _ in range(10):\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        print(f\"Iteration {i+1} - Training ASAE with beta=2e-4\")\n",
    "        print(f\"Current best Bimodal Acc: {best_bi_acc_:.4f}. Corresponding Unimodal Acc: {best_.metrics.contrastive_loss_unimodal['accuracy']:.4f}, Bridge Acc: {best_.metrics.contrastive_loss_bridge['accuracy']:.4f}, Bridge C Acc: {best_.metrics.contrastive_loss_bridge_C['accuracy']:.4f}\")\n",
    "        print(f\"Recorded best Bimodal Accs: {best_record}, at iterations: {best_times}\")\n",
    "    ASAE, ASAE_name = __train(beta=4e-4, force_retrain=True, criterion_2_fct=losses.alignment_penalty_distribution_prime) # Aligned SAE\n",
    "    ASAE.metrics = measure_everything(ASAE, train_loader, device, return_sqr=True)\n",
    "    # ASAE = best_\n",
    "    ASAE_bridge = {\n",
    "        \"bridge_sigma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False).cpu().detach(),\n",
    "        \"bridge_gamma\" : measure_bridge_sigma(ASAE, train_loader, ASAE.metrics.E, ASAE.metrics.E_Img, ASAE.metrics.E_Txt, device, center=False, normalize=False, null_C=False, null_D=False, weight_type=\"OT\").cpu().detach(),\n",
    "    }\n",
    "    get_bridge_norms(ASAE_bridge[\"bridge_sigma\"], ASAE.metrics.mu, ASAE.metrics.E, ASAE_name, ASAE)\n",
    "    print(\"Got bridge norms for ASAE\")\n",
    "    plot_bridge_mass_vs_eps(ASAE_bridge[\"bridge_gamma\"], f\"rzegzeg\", f\"bridge_mass_vs_eps_gamma\", ASAE_name, ASAE.metrics.mu, ASAE.metrics.E, ASAE, weight_type=\"gamma\", skip_plot=True)\n",
    "    get_rho(ASAE)\n",
    "    data_classifiability(ASAE, ASAE_name, eps=0.05, skip_plot=True)\n",
    "    \n",
    "    I_bi_A, T_bi_A, B_bi_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device)\n",
    "    I_uni_A, T_uni_A, B_uni_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True)\n",
    "    I_bridge_A, T_bridge_A, B_bridge_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=False, use_E_B=True)\n",
    "    I_bridge_C_A, T_bridge_C_A, B_bridge_C_A = get_bimodal_data(ASAE, train_loader, ASAE.metrics.mu, device, complement=True, use_E_B=True)\n",
    "    print(\"Got bimodal data for ASAE\")\n",
    "    get_modality_gap(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    # get_modality_gap(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    # get_modality_gap(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    # get_modality_gap(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    get_contrastive_loss(I_bi_A, T_bi_A, ASAE, data_name=\"bimodal\")\n",
    "    get_contrastive_loss(I_uni_A, T_uni_A, ASAE, data_name=\"unimodal\")\n",
    "    get_contrastive_loss(I_bridge_A, T_bridge_A, ASAE, data_name=\"bridge\")\n",
    "    get_contrastive_loss(I_bridge_C_A, T_bridge_C_A, ASAE, data_name=\"bridge_C\")\n",
    "    print(ASAE.metrics)\n",
    "    all_metrics.append(ASAE.metrics)\n",
    "    all_saes.append(ASAE)\n",
    "    bi_acc = ASAE.metrics.contrastive_loss_bimodal['accuracy']\n",
    "    # uni_acc = ASAE.metrics.contrastive_loss_unimodal['accuracy']\n",
    "    # bridge_acc = ASAE.metrics.contrastive_loss_bridge['accuracy']\n",
    "    # bridge_C_acc = ASAE.metrics.contrastive_loss_bridge_C['accuracy']\n",
    "    # print(f\"Iteration {i+1} - Bimodal Acc: {bi_acc:.4f}, Unimodal Acc: {uni_acc:.4f}, Bridge Acc: {bridge_acc:.4f}, Bridge C Acc: {bridge_C_acc:.4f}\")\n",
    "    if bi_acc > best_bi_acc_:\n",
    "        best_bi_acc_ = bi_acc\n",
    "        best_ = ASAE\n",
    "        print(f\"New best model found with Bimodal Acc: {best_bi_acc_:.4f}\")\n",
    "        checkpoint = {\n",
    "            'model_state_dict': best_.state_dict(),\n",
    "            'logs': None\n",
    "        }\n",
    "\n",
    "        # check that checkpoint_path exists, otherwise create it\n",
    "        checkpoint_path = f\"./checkpoints/\"\n",
    "        checkpoint_name = ASAE_name.replace('.pt', '_best.pt')\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            os.makedirs(checkpoint_path)\n",
    "        torch.save(checkpoint, f\"{checkpoint_path}/{checkpoint_name}\")\n",
    "        best_record.append(best_bi_acc_)\n",
    "        best_times.append(i)\n",
    "\n",
    "print(all_metrics)\n",
    "all_metrics_L_align_dist = all_metrics\n",
    "all_saes_L_align_dist = all_saes\n",
    "torch.save(all_metrics_L_align_dist, f\"./temporary_save/all_metrics_L_align_dist.pt\")\n",
    "torch.save(all_saes_L_align_dist, f\"./temporary_save/all_saes_L_align_dist.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rename delta_acc to Delta recall. Rename acc to recall everywhere. Use Zero shot acc, never acc. Only use acc for feature as probes setups.\n",
    "\n",
    "- 3D LR projection : say \"we find that concepts are neatly organized in latent space, clustered by modality\".\n",
    "\n",
    "- More models ! OpenClip, eva clip, clipa, siglip, various sizes, try them all !\n",
    "    - measure recall@k on unmodified embeddings to check if it's consistent with literature so if our embeddings are properly extracted.\n",
    "    - do the shit anyway"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
